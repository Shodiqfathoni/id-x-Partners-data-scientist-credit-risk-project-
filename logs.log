2024-06-23 09:49:37,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-23 09:49:37,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-23 09:49:37,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-23 09:49:37,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-23 09:49:38,313:INFO:PyCaret ClassificationExperiment
2024-06-23 09:49:38,313:INFO:Logging name: clf-default-name
2024-06-23 09:49:38,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-23 09:49:38,313:INFO:version 3.3.2
2024-06-23 09:49:38,313:INFO:Initializing setup()
2024-06-23 09:49:38,313:INFO:self.USI: 4bb2
2024-06-23 09:49:38,313:INFO:self._variable_keys: {'html_param', 'memory', 'y_train', 'X_test', 'target_param', 'X_train', 'exp_id', '_ml_usecase', 'fold_generator', 'y', '_available_plots', 'idx', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_name_log', 'USI', 'fix_imbalance', 'fold_shuffle_param', 'y_test', 'data', 'logging_param', 'log_plots_param', 'gpu_param', 'fold_groups_param', 'is_multiclass', 'seed', 'pipeline', 'X'}
2024-06-23 09:49:38,313:INFO:Checking environment
2024-06-23 09:49:38,313:INFO:python_version: 3.11.7
2024-06-23 09:49:38,313:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-23 09:49:38,313:INFO:machine: AMD64
2024-06-23 09:49:38,313:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-23 09:49:38,329:INFO:Memory: svmem(total=12756160512, available=4798246912, percent=62.4, used=7957913600, free=4798246912)
2024-06-23 09:49:38,329:INFO:Physical Core: 2
2024-06-23 09:49:38,345:INFO:Logical Core: 4
2024-06-23 09:49:38,345:INFO:Checking libraries
2024-06-23 09:49:38,345:INFO:System:
2024-06-23 09:49:38,345:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-23 09:49:38,345:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-23 09:49:38,345:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-23 09:49:38,345:INFO:PyCaret required dependencies:
2024-06-23 09:49:38,376:INFO:                 pip: 24.0
2024-06-23 09:49:38,376:INFO:          setuptools: 69.5.1
2024-06-23 09:49:38,376:INFO:             pycaret: 3.3.2
2024-06-23 09:49:38,376:INFO:             IPython: 8.24.0
2024-06-23 09:49:38,376:INFO:          ipywidgets: 8.1.3
2024-06-23 09:49:38,376:INFO:                tqdm: 4.66.4
2024-06-23 09:49:38,376:INFO:               numpy: 1.26.4
2024-06-23 09:49:38,376:INFO:              pandas: 2.1.4
2024-06-23 09:49:38,376:INFO:              jinja2: 3.1.4
2024-06-23 09:49:38,376:INFO:               scipy: 1.11.4
2024-06-23 09:49:38,376:INFO:              joblib: 1.3.2
2024-06-23 09:49:38,376:INFO:             sklearn: 1.4.2
2024-06-23 09:49:38,376:INFO:                pyod: 2.0.1
2024-06-23 09:49:38,376:INFO:            imblearn: 0.12.3
2024-06-23 09:49:38,376:INFO:   category_encoders: 2.6.3
2024-06-23 09:49:38,376:INFO:            lightgbm: 4.4.0
2024-06-23 09:49:38,376:INFO:               numba: 0.60.0
2024-06-23 09:49:38,376:INFO:            requests: 2.32.3
2024-06-23 09:49:38,376:INFO:          matplotlib: 3.7.5
2024-06-23 09:49:38,376:INFO:          scikitplot: 0.3.7
2024-06-23 09:49:38,376:INFO:         yellowbrick: 1.5
2024-06-23 09:49:38,376:INFO:              plotly: 5.22.0
2024-06-23 09:49:38,376:INFO:    plotly-resampler: Not installed
2024-06-23 09:49:38,376:INFO:             kaleido: 0.2.1
2024-06-23 09:49:38,376:INFO:           schemdraw: 0.15
2024-06-23 09:49:38,376:INFO:         statsmodels: 0.14.2
2024-06-23 09:49:38,376:INFO:              sktime: 0.26.0
2024-06-23 09:49:38,376:INFO:               tbats: 1.1.3
2024-06-23 09:49:38,376:INFO:            pmdarima: 2.0.4
2024-06-23 09:49:38,376:INFO:              psutil: 5.9.8
2024-06-23 09:49:38,376:INFO:          markupsafe: 2.1.5
2024-06-23 09:49:38,376:INFO:             pickle5: Not installed
2024-06-23 09:49:38,376:INFO:         cloudpickle: 3.0.0
2024-06-23 09:49:38,376:INFO:         deprecation: 2.1.0
2024-06-23 09:49:38,376:INFO:              xxhash: 3.4.1
2024-06-23 09:49:38,376:INFO:           wurlitzer: Not installed
2024-06-23 09:49:38,376:INFO:PyCaret optional dependencies:
2024-06-23 09:49:38,414:INFO:                shap: Not installed
2024-06-23 09:49:38,414:INFO:           interpret: Not installed
2024-06-23 09:49:38,414:INFO:                umap: Not installed
2024-06-23 09:49:38,414:INFO:     ydata_profiling: Not installed
2024-06-23 09:49:38,414:INFO:  explainerdashboard: Not installed
2024-06-23 09:49:38,414:INFO:             autoviz: Not installed
2024-06-23 09:49:38,414:INFO:           fairlearn: Not installed
2024-06-23 09:49:38,414:INFO:          deepchecks: Not installed
2024-06-23 09:49:38,414:INFO:             xgboost: Not installed
2024-06-23 09:49:38,414:INFO:            catboost: Not installed
2024-06-23 09:49:38,414:INFO:              kmodes: Not installed
2024-06-23 09:49:38,414:INFO:             mlxtend: Not installed
2024-06-23 09:49:38,414:INFO:       statsforecast: Not installed
2024-06-23 09:49:38,414:INFO:        tune_sklearn: Not installed
2024-06-23 09:49:38,414:INFO:                 ray: Not installed
2024-06-23 09:49:38,414:INFO:            hyperopt: Not installed
2024-06-23 09:49:38,414:INFO:              optuna: Not installed
2024-06-23 09:49:38,414:INFO:               skopt: Not installed
2024-06-23 09:49:38,414:INFO:              mlflow: Not installed
2024-06-23 09:49:38,414:INFO:              gradio: Not installed
2024-06-23 09:49:38,414:INFO:             fastapi: Not installed
2024-06-23 09:49:38,414:INFO:             uvicorn: Not installed
2024-06-23 09:49:38,414:INFO:              m2cgen: Not installed
2024-06-23 09:49:38,414:INFO:           evidently: Not installed
2024-06-23 09:49:38,414:INFO:               fugue: Not installed
2024-06-23 09:49:38,414:INFO:           streamlit: Not installed
2024-06-23 09:49:38,414:INFO:             prophet: Not installed
2024-06-23 09:49:38,414:INFO:None
2024-06-23 09:49:38,414:INFO:Set up data.
2024-06-23 09:49:38,545:INFO:Set up folding strategy.
2024-06-23 09:49:38,545:INFO:Set up train/test split.
2024-06-23 09:49:38,577:INFO:Set up index.
2024-06-23 09:49:38,577:INFO:Assigning column types.
2024-06-23 09:49:38,592:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-23 09:49:38,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-23 09:49:38,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-23 09:49:38,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-23 09:49:38,746:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-23 09:49:38,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-23 09:49:38,846:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-23 09:49:38,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-23 09:49:38,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:38,962:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-23 09:49:39,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:39,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:39,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:39,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:39,147:INFO:Preparing preprocessing pipeline...
2024-06-23 09:49:39,147:INFO:Set up label encoding.
2024-06-23 09:49:39,147:INFO:Set up simple imputation.
2024-06-23 09:49:39,163:INFO:Set up encoding of ordinal features.
2024-06-23 09:49:39,163:INFO:Set up encoding of categorical features.
2024-06-23 09:49:39,163:INFO:Set up imbalanced handling.
2024-06-23 09:49:40,119:INFO:Finished creating preprocessing pipeline.
2024-06-23 09:49:40,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'duration', 'campaign',
                                             'pdays'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_val...
                                                                    'month',
                                                                    'day_of_week',
                                                                    'previous',
                                                                    'poutcome'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-06-23 09:49:40,150:INFO:Creating final display dataframe.
2024-06-23 09:49:42,426:INFO:Setup _display_container:                     Description             Value
0                    Session id              3521
1                        Target                 y
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape       (32950, 16)
5        Transformed data shape       (50819, 65)
6   Transformed train set shape       (40934, 65)
7    Transformed test set shape        (9885, 65)
8              Numeric features                 4
9          Categorical features                11
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              4bb2
2024-06-23 09:49:42,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:42,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:42,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:42,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-23 09:49:42,689:INFO:setup() successfully completed in 4.38s...............
2024-06-23 09:49:42,704:INFO:Initializing compare_models()
2024-06-23 09:49:42,704:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-23 09:49:42,704:INFO:Checking exceptions
2024-06-23 09:49:42,726:INFO:Preparing display monitor
2024-06-23 09:49:42,776:INFO:Initializing Logistic Regression
2024-06-23 09:49:42,776:INFO:Total runtime is 0.0 minutes
2024-06-23 09:49:42,782:INFO:SubProcess create_model() called ==================================
2024-06-23 09:49:42,783:INFO:Initializing create_model()
2024-06-23 09:49:42,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:49:42,784:INFO:Checking exceptions
2024-06-23 09:49:42,784:INFO:Importing libraries
2024-06-23 09:49:42,784:INFO:Copying training dataset
2024-06-23 09:49:42,808:INFO:Defining folds
2024-06-23 09:49:42,808:INFO:Declaring metric variables
2024-06-23 09:49:42,817:INFO:Importing untrained model
2024-06-23 09:49:42,821:INFO:Logistic Regression Imported successfully
2024-06-23 09:49:42,834:INFO:Starting cross validation
2024-06-23 09:49:42,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:50:25,144:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:25,144:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:25,404:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,415:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:25,437:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,447:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,477:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,477:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,498:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:25,609:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,730:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,783:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,821:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,855:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:25,895:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:39,802:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:39,854:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:40,007:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,017:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:40,037:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,056:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,078:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,090:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,098:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:40,128:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,211:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,252:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,290:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,293:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,334:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:40,364:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:48,752:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:48,885:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:48,905:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:48,932:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:49,538:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-23 09:50:49,632:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:49,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:49,675:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:49,715:INFO:Calculating mean and std
2024-06-23 09:50:49,716:INFO:Creating metrics dataframe
2024-06-23 09:50:49,716:INFO:Uploading results into container
2024-06-23 09:50:49,716:INFO:Uploading model into container now
2024-06-23 09:50:49,716:INFO:_master_model_container: 1
2024-06-23 09:50:49,716:INFO:_display_container: 2
2024-06-23 09:50:49,716:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3521, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-23 09:50:49,716:INFO:create_model() successfully completed......................................
2024-06-23 09:50:49,818:INFO:SubProcess create_model() end ==================================
2024-06-23 09:50:49,818:INFO:Creating metrics dataframe
2024-06-23 09:50:49,818:INFO:Initializing K Neighbors Classifier
2024-06-23 09:50:49,818:INFO:Total runtime is 1.1173696517944336 minutes
2024-06-23 09:50:49,833:INFO:SubProcess create_model() called ==================================
2024-06-23 09:50:49,833:INFO:Initializing create_model()
2024-06-23 09:50:49,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:50:49,833:INFO:Checking exceptions
2024-06-23 09:50:49,833:INFO:Importing libraries
2024-06-23 09:50:49,833:INFO:Copying training dataset
2024-06-23 09:50:49,854:INFO:Defining folds
2024-06-23 09:50:49,875:INFO:Declaring metric variables
2024-06-23 09:50:49,883:INFO:Importing untrained model
2024-06-23 09:50:49,883:INFO:K Neighbors Classifier Imported successfully
2024-06-23 09:50:49,919:INFO:Starting cross validation
2024-06-23 09:50:49,932:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:50:55,455:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,497:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,559:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,589:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,639:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,680:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,690:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,755:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,782:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,802:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,823:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:50:55,863:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,297:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,348:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,387:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,388:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,422:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,455:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,462:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,503:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,543:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,665:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,708:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:01,746:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,745:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,765:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,787:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,820:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,847:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,859:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:04,900:INFO:Calculating mean and std
2024-06-23 09:51:04,900:INFO:Creating metrics dataframe
2024-06-23 09:51:04,905:INFO:Uploading results into container
2024-06-23 09:51:04,906:INFO:Uploading model into container now
2024-06-23 09:51:04,907:INFO:_master_model_container: 2
2024-06-23 09:51:04,907:INFO:_display_container: 2
2024-06-23 09:51:04,908:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-06-23 09:51:04,908:INFO:create_model() successfully completed......................................
2024-06-23 09:51:05,009:INFO:SubProcess create_model() end ==================================
2024-06-23 09:51:05,009:INFO:Creating metrics dataframe
2024-06-23 09:51:05,017:INFO:Initializing Naive Bayes
2024-06-23 09:51:05,017:INFO:Total runtime is 1.3706772089004517 minutes
2024-06-23 09:51:05,021:INFO:SubProcess create_model() called ==================================
2024-06-23 09:51:05,021:INFO:Initializing create_model()
2024-06-23 09:51:05,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:51:05,021:INFO:Checking exceptions
2024-06-23 09:51:05,021:INFO:Importing libraries
2024-06-23 09:51:05,021:INFO:Copying training dataset
2024-06-23 09:51:05,046:INFO:Defining folds
2024-06-23 09:51:05,046:INFO:Declaring metric variables
2024-06-23 09:51:05,051:INFO:Importing untrained model
2024-06-23 09:51:05,062:INFO:Naive Bayes Imported successfully
2024-06-23 09:51:05,080:INFO:Starting cross validation
2024-06-23 09:51:05,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:51:07,098:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,190:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,201:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,201:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,206:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,241:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,248:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,254:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,281:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,291:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:07,291:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,222:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,258:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,298:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,379:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,390:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,399:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,423:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,429:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,439:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,460:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,472:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:09,480:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,676:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,707:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,727:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,801:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,819:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,832:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:10,874:INFO:Calculating mean and std
2024-06-23 09:51:10,874:INFO:Creating metrics dataframe
2024-06-23 09:51:10,874:INFO:Uploading results into container
2024-06-23 09:51:10,874:INFO:Uploading model into container now
2024-06-23 09:51:10,874:INFO:_master_model_container: 3
2024-06-23 09:51:10,874:INFO:_display_container: 2
2024-06-23 09:51:10,874:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-06-23 09:51:10,874:INFO:create_model() successfully completed......................................
2024-06-23 09:51:10,973:INFO:SubProcess create_model() end ==================================
2024-06-23 09:51:10,973:INFO:Creating metrics dataframe
2024-06-23 09:51:10,992:INFO:Initializing Decision Tree Classifier
2024-06-23 09:51:10,992:INFO:Total runtime is 1.470263151327769 minutes
2024-06-23 09:51:10,992:INFO:SubProcess create_model() called ==================================
2024-06-23 09:51:10,992:INFO:Initializing create_model()
2024-06-23 09:51:10,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:51:10,992:INFO:Checking exceptions
2024-06-23 09:51:10,992:INFO:Importing libraries
2024-06-23 09:51:10,992:INFO:Copying training dataset
2024-06-23 09:51:11,006:INFO:Defining folds
2024-06-23 09:51:11,006:INFO:Declaring metric variables
2024-06-23 09:51:11,006:INFO:Importing untrained model
2024-06-23 09:51:11,025:INFO:Decision Tree Classifier Imported successfully
2024-06-23 09:51:11,031:INFO:Starting cross validation
2024-06-23 09:51:11,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:51:14,301:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,331:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,343:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,344:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,351:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,372:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,401:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,421:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,421:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:14,423:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,663:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,692:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,704:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,704:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,735:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,755:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,763:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,776:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,776:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,796:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,825:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:17,867:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:19,970:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:19,981:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:19,991:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:20,013:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:20,021:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:20,031:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:20,072:INFO:Calculating mean and std
2024-06-23 09:51:20,072:INFO:Creating metrics dataframe
2024-06-23 09:51:20,082:INFO:Uploading results into container
2024-06-23 09:51:20,084:INFO:Uploading model into container now
2024-06-23 09:51:20,084:INFO:_master_model_container: 4
2024-06-23 09:51:20,084:INFO:_display_container: 2
2024-06-23 09:51:20,084:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3521, splitter='best')
2024-06-23 09:51:20,084:INFO:create_model() successfully completed......................................
2024-06-23 09:51:20,168:INFO:SubProcess create_model() end ==================================
2024-06-23 09:51:20,168:INFO:Creating metrics dataframe
2024-06-23 09:51:20,184:INFO:Initializing SVM - Linear Kernel
2024-06-23 09:51:20,184:INFO:Total runtime is 1.6234616239865622 minutes
2024-06-23 09:51:20,184:INFO:SubProcess create_model() called ==================================
2024-06-23 09:51:20,184:INFO:Initializing create_model()
2024-06-23 09:51:20,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:51:20,184:INFO:Checking exceptions
2024-06-23 09:51:20,184:INFO:Importing libraries
2024-06-23 09:51:20,184:INFO:Copying training dataset
2024-06-23 09:51:20,213:INFO:Defining folds
2024-06-23 09:51:20,213:INFO:Declaring metric variables
2024-06-23 09:51:20,220:INFO:Importing untrained model
2024-06-23 09:51:20,233:INFO:SVM - Linear Kernel Imported successfully
2024-06-23 09:51:20,247:INFO:Starting cross validation
2024-06-23 09:51:20,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:51:25,894:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:25,955:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:25,994:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,237:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,267:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,316:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,687:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,751:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,795:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,799:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,848:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:26,900:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:31,832:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:31,865:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:31,913:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:32,249:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:32,288:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:32,331:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:32,472:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:32,513:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:32,553:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:33,432:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:33,464:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:33,496:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,437:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,464:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,478:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,488:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,498:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,519:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:36,549:INFO:Calculating mean and std
2024-06-23 09:51:36,549:INFO:Creating metrics dataframe
2024-06-23 09:51:36,549:INFO:Uploading results into container
2024-06-23 09:51:36,549:INFO:Uploading model into container now
2024-06-23 09:51:36,549:INFO:_master_model_container: 5
2024-06-23 09:51:36,549:INFO:_display_container: 2
2024-06-23 09:51:36,549:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3521, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-06-23 09:51:36,557:INFO:create_model() successfully completed......................................
2024-06-23 09:51:36,648:INFO:SubProcess create_model() end ==================================
2024-06-23 09:51:36,648:INFO:Creating metrics dataframe
2024-06-23 09:51:36,648:INFO:Initializing Ridge Classifier
2024-06-23 09:51:36,648:INFO:Total runtime is 1.8978668928146365 minutes
2024-06-23 09:51:36,665:INFO:SubProcess create_model() called ==================================
2024-06-23 09:51:36,665:INFO:Initializing create_model()
2024-06-23 09:51:36,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:51:36,665:INFO:Checking exceptions
2024-06-23 09:51:36,665:INFO:Importing libraries
2024-06-23 09:51:36,665:INFO:Copying training dataset
2024-06-23 09:51:36,687:INFO:Defining folds
2024-06-23 09:51:36,688:INFO:Declaring metric variables
2024-06-23 09:51:36,694:INFO:Importing untrained model
2024-06-23 09:51:36,704:INFO:Ridge Classifier Imported successfully
2024-06-23 09:51:36,723:INFO:Starting cross validation
2024-06-23 09:51:36,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:51:38,672:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,723:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,765:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,766:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,774:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,782:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,816:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,822:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,855:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:38,866:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,834:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,884:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,904:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,924:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,935:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,935:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,973:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,986:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:40,986:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:41,026:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:41,026:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,300:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,306:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,327:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,337:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,351:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,357:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:42,401:INFO:Calculating mean and std
2024-06-23 09:51:42,401:INFO:Creating metrics dataframe
2024-06-23 09:51:42,401:INFO:Uploading results into container
2024-06-23 09:51:42,401:INFO:Uploading model into container now
2024-06-23 09:51:42,401:INFO:_master_model_container: 6
2024-06-23 09:51:42,401:INFO:_display_container: 2
2024-06-23 09:51:42,401:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3521, solver='auto',
                tol=0.0001)
2024-06-23 09:51:42,401:INFO:create_model() successfully completed......................................
2024-06-23 09:51:42,500:INFO:SubProcess create_model() end ==================================
2024-06-23 09:51:42,515:INFO:Creating metrics dataframe
2024-06-23 09:51:42,523:INFO:Initializing Random Forest Classifier
2024-06-23 09:51:42,523:INFO:Total runtime is 1.9957852999369305 minutes
2024-06-23 09:51:42,523:INFO:SubProcess create_model() called ==================================
2024-06-23 09:51:42,534:INFO:Initializing create_model()
2024-06-23 09:51:42,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:51:42,534:INFO:Checking exceptions
2024-06-23 09:51:42,534:INFO:Importing libraries
2024-06-23 09:51:42,534:INFO:Copying training dataset
2024-06-23 09:51:42,534:INFO:Defining folds
2024-06-23 09:51:42,534:INFO:Declaring metric variables
2024-06-23 09:51:42,552:INFO:Importing untrained model
2024-06-23 09:51:42,552:INFO:Random Forest Classifier Imported successfully
2024-06-23 09:51:42,585:INFO:Starting cross validation
2024-06-23 09:51:42,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:51:58,642:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,694:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,722:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,773:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,819:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,844:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,849:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,856:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:51:58,889:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,104:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,148:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,166:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,219:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,257:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,278:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,278:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,331:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,369:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,527:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,563:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:15,600:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,473:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,504:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,532:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,705:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,731:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,764:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:23,803:INFO:Calculating mean and std
2024-06-23 09:52:23,805:INFO:Creating metrics dataframe
2024-06-23 09:52:23,805:INFO:Uploading results into container
2024-06-23 09:52:23,805:INFO:Uploading model into container now
2024-06-23 09:52:23,805:INFO:_master_model_container: 7
2024-06-23 09:52:23,805:INFO:_display_container: 2
2024-06-23 09:52:23,805:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3521, verbose=0,
                       warm_start=False)
2024-06-23 09:52:23,805:INFO:create_model() successfully completed......................................
2024-06-23 09:52:23,931:INFO:SubProcess create_model() end ==================================
2024-06-23 09:52:23,931:INFO:Creating metrics dataframe
2024-06-23 09:52:23,947:INFO:Initializing Quadratic Discriminant Analysis
2024-06-23 09:52:23,947:INFO:Total runtime is 2.686186758677165 minutes
2024-06-23 09:52:23,947:INFO:SubProcess create_model() called ==================================
2024-06-23 09:52:23,947:INFO:Initializing create_model()
2024-06-23 09:52:23,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:52:23,947:INFO:Checking exceptions
2024-06-23 09:52:23,947:INFO:Importing libraries
2024-06-23 09:52:23,947:INFO:Copying training dataset
2024-06-23 09:52:23,964:INFO:Defining folds
2024-06-23 09:52:23,964:INFO:Declaring metric variables
2024-06-23 09:52:23,992:INFO:Importing untrained model
2024-06-23 09:52:24,001:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-23 09:52:24,014:INFO:Starting cross validation
2024-06-23 09:52:24,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:52:26,259:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:26,300:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:26,348:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:26,409:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:27,086:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,094:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,127:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,137:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,137:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,167:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,184:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,185:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,188:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,219:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:27,227:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:29,396:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:29,459:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:29,593:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:29,623:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:30,247:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,269:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,279:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,306:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,310:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,328:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,342:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,350:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,350:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,381:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:30,431:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:31,885:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:31,927:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-23 09:52:32,291:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:32,314:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:32,324:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:32,334:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:32,355:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:32,385:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:32,426:INFO:Calculating mean and std
2024-06-23 09:52:32,426:INFO:Creating metrics dataframe
2024-06-23 09:52:32,452:INFO:Uploading results into container
2024-06-23 09:52:32,452:INFO:Uploading model into container now
2024-06-23 09:52:32,452:INFO:_master_model_container: 8
2024-06-23 09:52:32,452:INFO:_display_container: 2
2024-06-23 09:52:32,452:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-06-23 09:52:32,452:INFO:create_model() successfully completed......................................
2024-06-23 09:52:32,551:INFO:SubProcess create_model() end ==================================
2024-06-23 09:52:32,551:INFO:Creating metrics dataframe
2024-06-23 09:52:32,551:INFO:Initializing Ada Boost Classifier
2024-06-23 09:52:32,551:INFO:Total runtime is 2.8295810699462893 minutes
2024-06-23 09:52:32,567:INFO:SubProcess create_model() called ==================================
2024-06-23 09:52:32,567:INFO:Initializing create_model()
2024-06-23 09:52:32,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:52:32,567:INFO:Checking exceptions
2024-06-23 09:52:32,567:INFO:Importing libraries
2024-06-23 09:52:32,567:INFO:Copying training dataset
2024-06-23 09:52:32,596:INFO:Defining folds
2024-06-23 09:52:32,597:INFO:Declaring metric variables
2024-06-23 09:52:32,609:INFO:Importing untrained model
2024-06-23 09:52:32,609:INFO:Ada Boost Classifier Imported successfully
2024-06-23 09:52:32,627:INFO:Starting cross validation
2024-06-23 09:52:32,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:52:34,319:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:34,327:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:34,335:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:34,360:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:42,562:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,573:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,603:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,611:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,613:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,637:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,644:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,644:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,654:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,687:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,694:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:42,734:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:44,405:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:44,421:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:44,438:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:44,471:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:52,474:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,500:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,510:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,520:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,541:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,551:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,559:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,590:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,592:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,683:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,732:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:52,774:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:53,712:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:53,774:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-23 09:52:58,842:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:58,851:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:58,862:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:58,872:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:58,882:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:58,892:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:52:58,933:INFO:Calculating mean and std
2024-06-23 09:52:58,933:INFO:Creating metrics dataframe
2024-06-23 09:52:58,933:INFO:Uploading results into container
2024-06-23 09:52:58,933:INFO:Uploading model into container now
2024-06-23 09:52:58,933:INFO:_master_model_container: 9
2024-06-23 09:52:58,933:INFO:_display_container: 2
2024-06-23 09:52:58,933:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3521)
2024-06-23 09:52:58,942:INFO:create_model() successfully completed......................................
2024-06-23 09:52:59,029:INFO:SubProcess create_model() end ==================================
2024-06-23 09:52:59,029:INFO:Creating metrics dataframe
2024-06-23 09:52:59,042:INFO:Initializing Gradient Boosting Classifier
2024-06-23 09:52:59,042:INFO:Total runtime is 3.271103366216024 minutes
2024-06-23 09:52:59,042:INFO:SubProcess create_model() called ==================================
2024-06-23 09:52:59,042:INFO:Initializing create_model()
2024-06-23 09:52:59,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:52:59,058:INFO:Checking exceptions
2024-06-23 09:52:59,058:INFO:Importing libraries
2024-06-23 09:52:59,058:INFO:Copying training dataset
2024-06-23 09:52:59,061:INFO:Defining folds
2024-06-23 09:52:59,061:INFO:Declaring metric variables
2024-06-23 09:52:59,076:INFO:Importing untrained model
2024-06-23 09:52:59,086:INFO:Gradient Boosting Classifier Imported successfully
2024-06-23 09:52:59,096:INFO:Starting cross validation
2024-06-23 09:52:59,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:53:32,524:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,526:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,565:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,570:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,604:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,629:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,671:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,750:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,753:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,790:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,792:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:53:32,823:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,619:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,665:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,705:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,838:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,857:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,883:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,901:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,920:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,949:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:05,982:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:06,021:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:06,062:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,511:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,531:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,556:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,646:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,665:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,678:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:27,719:INFO:Calculating mean and std
2024-06-23 09:54:27,719:INFO:Creating metrics dataframe
2024-06-23 09:54:27,728:INFO:Uploading results into container
2024-06-23 09:54:27,728:INFO:Uploading model into container now
2024-06-23 09:54:27,728:INFO:_master_model_container: 10
2024-06-23 09:54:27,728:INFO:_display_container: 2
2024-06-23 09:54:27,728:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3521, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-23 09:54:27,728:INFO:create_model() successfully completed......................................
2024-06-23 09:54:27,822:INFO:SubProcess create_model() end ==================================
2024-06-23 09:54:27,822:INFO:Creating metrics dataframe
2024-06-23 09:54:27,842:INFO:Initializing Linear Discriminant Analysis
2024-06-23 09:54:27,842:INFO:Total runtime is 4.75110323826472 minutes
2024-06-23 09:54:27,849:INFO:SubProcess create_model() called ==================================
2024-06-23 09:54:27,849:INFO:Initializing create_model()
2024-06-23 09:54:27,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:54:27,849:INFO:Checking exceptions
2024-06-23 09:54:27,849:INFO:Importing libraries
2024-06-23 09:54:27,849:INFO:Copying training dataset
2024-06-23 09:54:27,865:INFO:Defining folds
2024-06-23 09:54:27,865:INFO:Declaring metric variables
2024-06-23 09:54:27,869:INFO:Importing untrained model
2024-06-23 09:54:27,909:INFO:Linear Discriminant Analysis Imported successfully
2024-06-23 09:54:27,929:INFO:Starting cross validation
2024-06-23 09:54:27,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:54:31,064:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,094:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,094:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,128:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,135:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,135:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,141:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,185:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,185:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,185:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,195:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:31,241:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,390:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,408:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,429:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,447:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,469:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,480:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,491:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,500:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,531:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,551:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,581:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:34,592:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,411:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,426:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,443:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,452:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,462:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,476:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:36,525:INFO:Calculating mean and std
2024-06-23 09:54:36,525:INFO:Creating metrics dataframe
2024-06-23 09:54:36,525:INFO:Uploading results into container
2024-06-23 09:54:36,525:INFO:Uploading model into container now
2024-06-23 09:54:36,525:INFO:_master_model_container: 11
2024-06-23 09:54:36,525:INFO:_display_container: 2
2024-06-23 09:54:36,525:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-23 09:54:36,525:INFO:create_model() successfully completed......................................
2024-06-23 09:54:36,626:INFO:SubProcess create_model() end ==================================
2024-06-23 09:54:36,630:INFO:Creating metrics dataframe
2024-06-23 09:54:36,642:INFO:Initializing Extra Trees Classifier
2024-06-23 09:54:36,642:INFO:Total runtime is 4.897772705554962 minutes
2024-06-23 09:54:36,642:INFO:SubProcess create_model() called ==================================
2024-06-23 09:54:36,642:INFO:Initializing create_model()
2024-06-23 09:54:36,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:54:36,642:INFO:Checking exceptions
2024-06-23 09:54:36,642:INFO:Importing libraries
2024-06-23 09:54:36,642:INFO:Copying training dataset
2024-06-23 09:54:36,662:INFO:Defining folds
2024-06-23 09:54:36,662:INFO:Declaring metric variables
2024-06-23 09:54:36,681:INFO:Importing untrained model
2024-06-23 09:54:36,681:INFO:Extra Trees Classifier Imported successfully
2024-06-23 09:54:36,703:INFO:Starting cross validation
2024-06-23 09:54:36,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:54:54,548:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,551:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,583:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,593:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,624:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,634:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,808:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,870:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,941:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,941:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:54,981:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:54:55,031:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,775:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,814:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,866:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,925:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,947:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:12,958:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:13,021:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:13,096:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:13,121:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:13,162:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:13,201:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:21,874:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:21,906:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:21,935:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:22,140:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:22,157:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:22,180:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:22,216:INFO:Calculating mean and std
2024-06-23 09:55:22,216:INFO:Creating metrics dataframe
2024-06-23 09:55:22,216:INFO:Uploading results into container
2024-06-23 09:55:22,224:INFO:Uploading model into container now
2024-06-23 09:55:22,224:INFO:_master_model_container: 12
2024-06-23 09:55:22,224:INFO:_display_container: 2
2024-06-23 09:55:22,228:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3521, verbose=0,
                     warm_start=False)
2024-06-23 09:55:22,229:INFO:create_model() successfully completed......................................
2024-06-23 09:55:22,324:INFO:SubProcess create_model() end ==================================
2024-06-23 09:55:22,324:INFO:Creating metrics dataframe
2024-06-23 09:55:22,340:INFO:Initializing Light Gradient Boosting Machine
2024-06-23 09:55:22,340:INFO:Total runtime is 5.659406916300456 minutes
2024-06-23 09:55:22,340:INFO:SubProcess create_model() called ==================================
2024-06-23 09:55:22,340:INFO:Initializing create_model()
2024-06-23 09:55:22,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:55:22,340:INFO:Checking exceptions
2024-06-23 09:55:22,340:INFO:Importing libraries
2024-06-23 09:55:22,340:INFO:Copying training dataset
2024-06-23 09:55:22,365:INFO:Defining folds
2024-06-23 09:55:22,365:INFO:Declaring metric variables
2024-06-23 09:55:22,371:INFO:Importing untrained model
2024-06-23 09:55:22,379:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-23 09:55:22,397:INFO:Starting cross validation
2024-06-23 09:55:22,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:55:27,457:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:27,477:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:27,495:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:27,518:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:27,528:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:27,559:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:27,976:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:28,016:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:28,026:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:28,058:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:28,068:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:28,108:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:32,607:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:32,645:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:32,685:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:32,782:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:32,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:32,873:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:33,108:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:33,148:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:33,189:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:33,354:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:33,398:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:33,446:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:35,856:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:35,899:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:35,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:36,097:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:36,140:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:36,178:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:36,210:INFO:Calculating mean and std
2024-06-23 09:55:36,213:INFO:Creating metrics dataframe
2024-06-23 09:55:36,229:INFO:Uploading results into container
2024-06-23 09:55:36,230:INFO:Uploading model into container now
2024-06-23 09:55:36,231:INFO:_master_model_container: 13
2024-06-23 09:55:36,231:INFO:_display_container: 2
2024-06-23 09:55:36,232:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-23 09:55:36,234:INFO:create_model() successfully completed......................................
2024-06-23 09:55:36,312:INFO:SubProcess create_model() end ==================================
2024-06-23 09:55:36,327:INFO:Creating metrics dataframe
2024-06-23 09:55:36,333:INFO:Initializing Dummy Classifier
2024-06-23 09:55:36,333:INFO:Total runtime is 5.892613057295481 minutes
2024-06-23 09:55:36,345:INFO:SubProcess create_model() called ==================================
2024-06-23 09:55:36,345:INFO:Initializing create_model()
2024-06-23 09:55:36,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F2EE29B710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:55:36,345:INFO:Checking exceptions
2024-06-23 09:55:36,345:INFO:Importing libraries
2024-06-23 09:55:36,345:INFO:Copying training dataset
2024-06-23 09:55:36,374:INFO:Defining folds
2024-06-23 09:55:36,375:INFO:Declaring metric variables
2024-06-23 09:55:36,383:INFO:Importing untrained model
2024-06-23 09:55:36,389:INFO:Dummy Classifier Imported successfully
2024-06-23 09:55:36,406:INFO:Starting cross validation
2024-06-23 09:55:36,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-23 09:55:38,305:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,305:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,330:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,336:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,345:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,357:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,367:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:38,367:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,375:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:38,385:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,396:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:38,398:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,398:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:38,413:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:38,419:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,321:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,369:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,371:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,371:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,389:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,397:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:40,416:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,422:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,435:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,448:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:40,450:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:40,460:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:40,464:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,464:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:40,480:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,783:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,801:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,805:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,826:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:41,831:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,836:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,849:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-23 09:55:41,857:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:41,901:INFO:Calculating mean and std
2024-06-23 09:55:41,901:INFO:Creating metrics dataframe
2024-06-23 09:55:41,915:INFO:Uploading results into container
2024-06-23 09:55:41,917:INFO:Uploading model into container now
2024-06-23 09:55:41,918:INFO:_master_model_container: 14
2024-06-23 09:55:41,920:INFO:_display_container: 2
2024-06-23 09:55:41,920:INFO:DummyClassifier(constant=None, random_state=3521, strategy='prior')
2024-06-23 09:55:41,920:INFO:create_model() successfully completed......................................
2024-06-23 09:55:42,014:INFO:SubProcess create_model() end ==================================
2024-06-23 09:55:42,014:INFO:Creating metrics dataframe
2024-06-23 09:55:42,035:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-23 09:55:42,050:INFO:Initializing create_model()
2024-06-23 09:55:42,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-23 09:55:42,050:INFO:Checking exceptions
2024-06-23 09:55:42,050:INFO:Importing libraries
2024-06-23 09:55:42,050:INFO:Copying training dataset
2024-06-23 09:55:42,090:INFO:Defining folds
2024-06-23 09:55:42,090:INFO:Declaring metric variables
2024-06-23 09:55:42,090:INFO:Importing untrained model
2024-06-23 09:55:42,090:INFO:Declaring custom model
2024-06-23 09:55:42,092:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-23 09:55:42,101:INFO:Cross validation set to False
2024-06-23 09:55:42,101:INFO:Fitting Model
2024-06-23 09:55:43,067:INFO:[LightGBM] [Info] Number of positive: 20467, number of negative: 20467
2024-06-23 09:55:43,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028729 seconds.
2024-06-23 09:55:43,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 09:55:43,114:INFO:[LightGBM] [Info] Total Bins 14650
2024-06-23 09:55:43,114:INFO:[LightGBM] [Info] Number of data points in the train set: 40934, number of used features: 62
2024-06-23 09:55:43,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 09:55:44,078:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-23 09:55:44,078:INFO:create_model() successfully completed......................................
2024-06-23 09:55:44,282:INFO:_master_model_container: 14
2024-06-23 09:55:44,282:INFO:_display_container: 2
2024-06-23 09:55:44,283:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-23 09:55:44,284:INFO:compare_models() successfully completed......................................
2024-06-23 09:55:44,315:INFO:Initializing plot_model()
2024-06-23 09:55:44,315:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-23 09:55:44,315:INFO:Checking exceptions
2024-06-23 09:55:44,333:INFO:Preloading libraries
2024-06-23 09:55:44,401:INFO:Copying training dataset
2024-06-23 09:55:44,434:INFO:Plot type: confusion_matrix
2024-06-23 09:55:45,316:INFO:Fitting Model
2024-06-23 09:55:45,316:INFO:Scoring test/hold-out set
2024-06-23 09:55:45,701:INFO:Visual Rendered Successfully
2024-06-23 09:55:45,817:INFO:plot_model() successfully completed......................................
2024-06-23 09:55:45,836:INFO:Initializing plot_model()
2024-06-23 09:55:45,836:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-23 09:55:45,836:INFO:Checking exceptions
2024-06-23 09:55:45,856:INFO:Preloading libraries
2024-06-23 09:55:45,872:INFO:Copying training dataset
2024-06-23 09:55:45,872:INFO:Plot type: auc
2024-06-23 09:55:46,249:INFO:Fitting Model
2024-06-23 09:55:46,249:INFO:Scoring test/hold-out set
2024-06-23 09:55:46,677:INFO:Visual Rendered Successfully
2024-06-23 09:55:46,777:INFO:plot_model() successfully completed......................................
2024-06-23 09:55:46,935:INFO:Initializing evaluate_model()
2024-06-23 09:55:46,935:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 09:55:47,073:INFO:Initializing plot_model()
2024-06-23 09:55:47,073:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 09:55:47,073:INFO:Checking exceptions
2024-06-23 09:55:47,098:INFO:Preloading libraries
2024-06-23 09:55:47,117:INFO:Copying training dataset
2024-06-23 09:55:47,117:INFO:Plot type: pipeline
2024-06-23 09:55:47,610:INFO:Visual Rendered Successfully
2024-06-23 09:55:47,694:INFO:plot_model() successfully completed......................................
2024-06-23 09:55:47,734:INFO:Initializing predict_model()
2024-06-23 09:55:47,734:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F2EE214E00>)
2024-06-23 09:55:47,734:INFO:Checking exceptions
2024-06-23 09:55:47,734:INFO:Preloading libraries
2024-06-23 09:55:48,116:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:48,263:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:55:48,332:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-23 09:56:10,803:INFO:Initializing interpret_model()
2024-06-23 09:56:10,803:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2024-06-23 09:56:10,804:INFO:Checking exceptions
2024-06-23 09:56:10,804:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-06-23 09:57:08,482:INFO:Initializing interpret_model()
2024-06-23 09:57:08,482:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2024-06-23 09:57:08,482:INFO:Checking exceptions
2024-06-23 09:57:08,483:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-06-23 09:59:49,634:INFO:Initializing interpret_model()
2024-06-23 09:59:49,634:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2024-06-23 09:59:49,634:INFO:Checking exceptions
2024-06-23 09:59:49,634:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-06-23 10:00:03,396:INFO:Initializing plot_model()
2024-06-23 10:00:03,397:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:00:03,397:INFO:Checking exceptions
2024-06-23 10:00:03,408:INFO:Preloading libraries
2024-06-23 10:00:03,433:INFO:Copying training dataset
2024-06-23 10:00:03,433:INFO:Plot type: confusion_matrix
2024-06-23 10:00:04,285:INFO:Fitting Model
2024-06-23 10:00:04,285:INFO:Scoring test/hold-out set
2024-06-23 10:00:04,618:INFO:Visual Rendered Successfully
2024-06-23 10:00:04,752:INFO:plot_model() successfully completed......................................
2024-06-23 10:00:08,817:INFO:Initializing plot_model()
2024-06-23 10:00:08,818:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:00:08,818:INFO:Checking exceptions
2024-06-23 10:00:08,832:INFO:Preloading libraries
2024-06-23 10:00:08,847:INFO:Copying training dataset
2024-06-23 10:00:08,847:INFO:Plot type: threshold
2024-06-23 10:00:09,218:INFO:Fitting Model
2024-06-23 10:00:09,386:INFO:[LightGBM] [Info] Number of positive: 18401, number of negative: 18439
2024-06-23 10:00:09,405:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012600 seconds.
2024-06-23 10:00:09,405:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:09,405:INFO:[LightGBM] [Info] Total Bins 14622
2024-06-23 10:00:09,413:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:09,415:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499484 -> initscore=-0.002063
2024-06-23 10:00:09,415:INFO:[LightGBM] [Info] Start training from score -0.002063
2024-06-23 10:00:10,413:INFO:[LightGBM] [Info] Number of positive: 18436, number of negative: 18404
2024-06-23 10:00:10,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014744 seconds.
2024-06-23 10:00:10,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:10,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:10,428:INFO:[LightGBM] [Info] Total Bins 14622
2024-06-23 10:00:10,444:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:10,444:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500434 -> initscore=0.001737
2024-06-23 10:00:10,444:INFO:[LightGBM] [Info] Start training from score 0.001737
2024-06-23 10:00:11,465:INFO:[LightGBM] [Info] Number of positive: 18331, number of negative: 18509
2024-06-23 10:00:11,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017657 seconds.
2024-06-23 10:00:11,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:11,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:11,496:INFO:[LightGBM] [Info] Total Bins 14613
2024-06-23 10:00:11,496:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:11,496:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497584 -> initscore=-0.009663
2024-06-23 10:00:11,496:INFO:[LightGBM] [Info] Start training from score -0.009663
2024-06-23 10:00:12,465:INFO:[LightGBM] [Info] Number of positive: 18398, number of negative: 18442
2024-06-23 10:00:12,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015635 seconds.
2024-06-23 10:00:12,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:12,497:INFO:[LightGBM] [Info] Total Bins 14618
2024-06-23 10:00:12,497:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:12,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499403 -> initscore=-0.002389
2024-06-23 10:00:12,497:INFO:[LightGBM] [Info] Start training from score -0.002389
2024-06-23 10:00:13,556:INFO:[LightGBM] [Info] Number of positive: 18438, number of negative: 18402
2024-06-23 10:00:13,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015254 seconds.
2024-06-23 10:00:13,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:13,578:INFO:[LightGBM] [Info] Total Bins 14616
2024-06-23 10:00:13,587:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:13,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500489 -> initscore=0.001954
2024-06-23 10:00:13,587:INFO:[LightGBM] [Info] Start training from score 0.001954
2024-06-23 10:00:14,613:INFO:[LightGBM] [Info] Number of positive: 18446, number of negative: 18394
2024-06-23 10:00:14,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011183 seconds.
2024-06-23 10:00:14,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:14,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:14,633:INFO:[LightGBM] [Info] Total Bins 14598
2024-06-23 10:00:14,641:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:14,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500706 -> initscore=0.002823
2024-06-23 10:00:14,643:INFO:[LightGBM] [Info] Start training from score 0.002823
2024-06-23 10:00:15,657:INFO:[LightGBM] [Info] Number of positive: 18387, number of negative: 18453
2024-06-23 10:00:15,687:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013263 seconds.
2024-06-23 10:00:15,687:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:15,687:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:15,727:INFO:[LightGBM] [Info] Total Bins 14605
2024-06-23 10:00:15,728:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:15,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499104 -> initscore=-0.003583
2024-06-23 10:00:15,757:INFO:[LightGBM] [Info] Start training from score -0.003583
2024-06-23 10:00:16,774:INFO:[LightGBM] [Info] Number of positive: 18472, number of negative: 18368
2024-06-23 10:00:16,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011831 seconds.
2024-06-23 10:00:16,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:16,805:INFO:[LightGBM] [Info] Total Bins 14598
2024-06-23 10:00:16,805:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:16,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501412 -> initscore=0.005646
2024-06-23 10:00:16,805:INFO:[LightGBM] [Info] Start training from score 0.005646
2024-06-23 10:00:17,923:INFO:[LightGBM] [Info] Number of positive: 18413, number of negative: 18427
2024-06-23 10:00:17,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010930 seconds.
2024-06-23 10:00:17,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:17,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:17,944:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:17,944:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:17,944:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499810 -> initscore=-0.000760
2024-06-23 10:00:17,944:INFO:[LightGBM] [Info] Start training from score -0.000760
2024-06-23 10:00:18,923:INFO:[LightGBM] [Info] Number of positive: 18408, number of negative: 18432
2024-06-23 10:00:18,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014500 seconds.
2024-06-23 10:00:18,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:18,945:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:18,953:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:18,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499674 -> initscore=-0.001303
2024-06-23 10:00:18,955:INFO:[LightGBM] [Info] Start training from score -0.001303
2024-06-23 10:00:20,055:INFO:[LightGBM] [Info] Number of positive: 18393, number of negative: 18447
2024-06-23 10:00:20,086:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013406 seconds.
2024-06-23 10:00:20,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:20,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:20,086:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:20,086:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:20,086:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499267 -> initscore=-0.002932
2024-06-23 10:00:20,086:INFO:[LightGBM] [Info] Start training from score -0.002932
2024-06-23 10:00:21,120:INFO:[LightGBM] [Info] Number of positive: 18415, number of negative: 18425
2024-06-23 10:00:21,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013445 seconds.
2024-06-23 10:00:21,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:21,151:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:21,151:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:21,151:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499864 -> initscore=-0.000543
2024-06-23 10:00:21,151:INFO:[LightGBM] [Info] Start training from score -0.000543
2024-06-23 10:00:22,203:INFO:[LightGBM] [Info] Number of positive: 18425, number of negative: 18415
2024-06-23 10:00:22,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019585 seconds.
2024-06-23 10:00:22,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:22,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:22,241:INFO:[LightGBM] [Info] Total Bins 14614
2024-06-23 10:00:22,243:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:22,243:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500136 -> initscore=0.000543
2024-06-23 10:00:22,243:INFO:[LightGBM] [Info] Start training from score 0.000543
2024-06-23 10:00:23,294:INFO:[LightGBM] [Info] Number of positive: 18403, number of negative: 18437
2024-06-23 10:00:23,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014549 seconds.
2024-06-23 10:00:23,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:23,324:INFO:[LightGBM] [Info] Total Bins 14617
2024-06-23 10:00:23,324:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:23,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499539 -> initscore=-0.001846
2024-06-23 10:00:23,324:INFO:[LightGBM] [Info] Start training from score -0.001846
2024-06-23 10:00:24,326:INFO:[LightGBM] [Info] Number of positive: 18379, number of negative: 18461
2024-06-23 10:00:24,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015965 seconds.
2024-06-23 10:00:24,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:24,356:INFO:[LightGBM] [Info] Total Bins 14613
2024-06-23 10:00:24,356:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:24,356:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498887 -> initscore=-0.004452
2024-06-23 10:00:24,356:INFO:[LightGBM] [Info] Start training from score -0.004452
2024-06-23 10:00:25,373:INFO:[LightGBM] [Info] Number of positive: 18386, number of negative: 18454
2024-06-23 10:00:25,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018520 seconds.
2024-06-23 10:00:25,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:25,404:INFO:[LightGBM] [Info] Total Bins 14616
2024-06-23 10:00:25,406:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:25,406:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499077 -> initscore=-0.003692
2024-06-23 10:00:25,406:INFO:[LightGBM] [Info] Start training from score -0.003692
2024-06-23 10:00:26,492:INFO:[LightGBM] [Info] Number of positive: 18410, number of negative: 18430
2024-06-23 10:00:26,522:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013524 seconds.
2024-06-23 10:00:26,522:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:26,522:INFO:[LightGBM] [Info] Total Bins 14622
2024-06-23 10:00:26,522:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:26,522:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499729 -> initscore=-0.001086
2024-06-23 10:00:26,522:INFO:[LightGBM] [Info] Start training from score -0.001086
2024-06-23 10:00:27,637:INFO:[LightGBM] [Info] Number of positive: 18414, number of negative: 18426
2024-06-23 10:00:27,680:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023665 seconds.
2024-06-23 10:00:27,682:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:27,682:INFO:[LightGBM] [Info] Total Bins 14610
2024-06-23 10:00:27,682:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:27,682:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499837 -> initscore=-0.000651
2024-06-23 10:00:27,682:INFO:[LightGBM] [Info] Start training from score -0.000651
2024-06-23 10:00:28,827:INFO:[LightGBM] [Info] Number of positive: 18400, number of negative: 18440
2024-06-23 10:00:28,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018591 seconds.
2024-06-23 10:00:28,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:28,864:INFO:[LightGBM] [Info] Total Bins 14615
2024-06-23 10:00:28,864:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:28,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499457 -> initscore=-0.002172
2024-06-23 10:00:28,864:INFO:[LightGBM] [Info] Start training from score -0.002172
2024-06-23 10:00:29,936:INFO:[LightGBM] [Info] Number of positive: 18453, number of negative: 18387
2024-06-23 10:00:29,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017833 seconds.
2024-06-23 10:00:29,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:29,966:INFO:[LightGBM] [Info] Total Bins 14620
2024-06-23 10:00:29,966:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:29,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500896 -> initscore=0.003583
2024-06-23 10:00:29,966:INFO:[LightGBM] [Info] Start training from score 0.003583
2024-06-23 10:00:31,063:INFO:[LightGBM] [Info] Number of positive: 18379, number of negative: 18461
2024-06-23 10:00:31,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017342 seconds.
2024-06-23 10:00:31,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:31,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:31,095:INFO:[LightGBM] [Info] Total Bins 14623
2024-06-23 10:00:31,095:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:31,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498887 -> initscore=-0.004452
2024-06-23 10:00:31,095:INFO:[LightGBM] [Info] Start training from score -0.004452
2024-06-23 10:00:32,129:INFO:[LightGBM] [Info] Number of positive: 18404, number of negative: 18436
2024-06-23 10:00:32,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012844 seconds.
2024-06-23 10:00:32,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:32,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:32,157:INFO:[LightGBM] [Info] Total Bins 14617
2024-06-23 10:00:32,159:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:32,161:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499566 -> initscore=-0.001737
2024-06-23 10:00:32,161:INFO:[LightGBM] [Info] Start training from score -0.001737
2024-06-23 10:00:33,223:INFO:[LightGBM] [Info] Number of positive: 18432, number of negative: 18408
2024-06-23 10:00:33,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014545 seconds.
2024-06-23 10:00:33,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:33,254:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:33,254:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:33,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500326 -> initscore=0.001303
2024-06-23 10:00:33,254:INFO:[LightGBM] [Info] Start training from score 0.001303
2024-06-23 10:00:34,346:INFO:[LightGBM] [Info] Number of positive: 18441, number of negative: 18399
2024-06-23 10:00:34,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017974 seconds.
2024-06-23 10:00:34,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:34,376:INFO:[LightGBM] [Info] Total Bins 14616
2024-06-23 10:00:34,379:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:34,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500570 -> initscore=0.002280
2024-06-23 10:00:34,379:INFO:[LightGBM] [Info] Start training from score 0.002280
2024-06-23 10:00:35,487:INFO:[LightGBM] [Info] Number of positive: 18430, number of negative: 18410
2024-06-23 10:00:35,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017516 seconds.
2024-06-23 10:00:35,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:35,517:INFO:[LightGBM] [Info] Total Bins 14598
2024-06-23 10:00:35,520:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:35,520:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500271 -> initscore=0.001086
2024-06-23 10:00:35,520:INFO:[LightGBM] [Info] Start training from score 0.001086
2024-06-23 10:00:36,650:INFO:[LightGBM] [Info] Number of positive: 18391, number of negative: 18449
2024-06-23 10:00:36,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014752 seconds.
2024-06-23 10:00:36,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:36,679:INFO:[LightGBM] [Info] Total Bins 14618
2024-06-23 10:00:36,681:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:36,681:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499213 -> initscore=-0.003149
2024-06-23 10:00:36,681:INFO:[LightGBM] [Info] Start training from score -0.003149
2024-06-23 10:00:37,834:INFO:[LightGBM] [Info] Number of positive: 18397, number of negative: 18443
2024-06-23 10:00:37,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019834 seconds.
2024-06-23 10:00:37,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:37,866:INFO:[LightGBM] [Info] Total Bins 14598
2024-06-23 10:00:37,866:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:37,866:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499376 -> initscore=-0.002497
2024-06-23 10:00:37,866:INFO:[LightGBM] [Info] Start training from score -0.002497
2024-06-23 10:00:38,991:INFO:[LightGBM] [Info] Number of positive: 18374, number of negative: 18466
2024-06-23 10:00:39,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016917 seconds.
2024-06-23 10:00:39,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:39,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:39,021:INFO:[LightGBM] [Info] Total Bins 14602
2024-06-23 10:00:39,029:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:39,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498751 -> initscore=-0.004995
2024-06-23 10:00:39,031:INFO:[LightGBM] [Info] Start training from score -0.004995
2024-06-23 10:00:40,181:INFO:[LightGBM] [Info] Number of positive: 18417, number of negative: 18423
2024-06-23 10:00:40,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023903 seconds.
2024-06-23 10:00:40,227:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:40,227:INFO:[LightGBM] [Info] Total Bins 14595
2024-06-23 10:00:40,230:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:40,232:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499919 -> initscore=-0.000326
2024-06-23 10:00:40,232:INFO:[LightGBM] [Info] Start training from score -0.000326
2024-06-23 10:00:41,742:INFO:[LightGBM] [Info] Number of positive: 18428, number of negative: 18412
2024-06-23 10:00:41,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014467 seconds.
2024-06-23 10:00:41,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:41,772:INFO:[LightGBM] [Info] Total Bins 14599
2024-06-23 10:00:41,772:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:41,772:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500217 -> initscore=0.000869
2024-06-23 10:00:41,780:INFO:[LightGBM] [Info] Start training from score 0.000869
2024-06-23 10:00:43,107:INFO:[LightGBM] [Info] Number of positive: 18441, number of negative: 18399
2024-06-23 10:00:43,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016439 seconds.
2024-06-23 10:00:43,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:43,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:43,138:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:43,140:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:43,141:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500570 -> initscore=0.002280
2024-06-23 10:00:43,142:INFO:[LightGBM] [Info] Start training from score 0.002280
2024-06-23 10:00:44,186:INFO:[LightGBM] [Info] Number of positive: 18409, number of negative: 18431
2024-06-23 10:00:44,218:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015480 seconds.
2024-06-23 10:00:44,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:44,218:INFO:[LightGBM] [Info] Total Bins 14620
2024-06-23 10:00:44,218:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:44,218:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499701 -> initscore=-0.001194
2024-06-23 10:00:44,218:INFO:[LightGBM] [Info] Start training from score -0.001194
2024-06-23 10:00:45,348:INFO:[LightGBM] [Info] Number of positive: 18414, number of negative: 18426
2024-06-23 10:00:45,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014341 seconds.
2024-06-23 10:00:45,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:45,378:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:45,378:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:45,390:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499837 -> initscore=-0.000651
2024-06-23 10:00:45,390:INFO:[LightGBM] [Info] Start training from score -0.000651
2024-06-23 10:00:46,616:INFO:[LightGBM] [Info] Number of positive: 18396, number of negative: 18444
2024-06-23 10:00:46,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013555 seconds.
2024-06-23 10:00:46,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:46,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:46,650:INFO:[LightGBM] [Info] Total Bins 14618
2024-06-23 10:00:46,650:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:46,655:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499349 -> initscore=-0.002606
2024-06-23 10:00:46,655:INFO:[LightGBM] [Info] Start training from score -0.002606
2024-06-23 10:00:47,780:INFO:[LightGBM] [Info] Number of positive: 18456, number of negative: 18384
2024-06-23 10:00:47,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014175 seconds.
2024-06-23 10:00:47,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:47,811:INFO:[LightGBM] [Info] Total Bins 14616
2024-06-23 10:00:47,811:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:47,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500977 -> initscore=0.003909
2024-06-23 10:00:47,811:INFO:[LightGBM] [Info] Start training from score 0.003909
2024-06-23 10:00:49,114:INFO:[LightGBM] [Info] Number of positive: 18402, number of negative: 18438
2024-06-23 10:00:49,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015782 seconds.
2024-06-23 10:00:49,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:49,129:INFO:[LightGBM] [Info] Total Bins 14601
2024-06-23 10:00:49,129:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:49,145:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499511 -> initscore=-0.001954
2024-06-23 10:00:49,145:INFO:[LightGBM] [Info] Start training from score -0.001954
2024-06-23 10:00:50,419:INFO:[LightGBM] [Info] Number of positive: 18405, number of negative: 18435
2024-06-23 10:00:50,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023615 seconds.
2024-06-23 10:00:50,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:50,453:INFO:[LightGBM] [Info] Total Bins 14613
2024-06-23 10:00:50,453:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:50,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499593 -> initscore=-0.001629
2024-06-23 10:00:50,453:INFO:[LightGBM] [Info] Start training from score -0.001629
2024-06-23 10:00:51,801:INFO:[LightGBM] [Info] Number of positive: 18449, number of negative: 18391
2024-06-23 10:00:51,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013961 seconds.
2024-06-23 10:00:51,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:51,821:INFO:[LightGBM] [Info] Total Bins 14613
2024-06-23 10:00:51,821:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:51,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500787 -> initscore=0.003149
2024-06-23 10:00:51,829:INFO:[LightGBM] [Info] Start training from score 0.003149
2024-06-23 10:00:52,985:INFO:[LightGBM] [Info] Number of positive: 18405, number of negative: 18435
2024-06-23 10:00:53,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014568 seconds.
2024-06-23 10:00:53,028:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:53,028:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:53,028:INFO:[LightGBM] [Info] Total Bins 14604
2024-06-23 10:00:53,028:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:53,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499593 -> initscore=-0.001629
2024-06-23 10:00:53,036:INFO:[LightGBM] [Info] Start training from score -0.001629
2024-06-23 10:00:54,114:INFO:[LightGBM] [Info] Number of positive: 18431, number of negative: 18409
2024-06-23 10:00:54,145:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013680 seconds.
2024-06-23 10:00:54,145:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:54,145:INFO:[LightGBM] [Info] Total Bins 14625
2024-06-23 10:00:54,145:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:54,145:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500299 -> initscore=0.001194
2024-06-23 10:00:54,145:INFO:[LightGBM] [Info] Start training from score 0.001194
2024-06-23 10:00:55,604:INFO:[LightGBM] [Info] Number of positive: 18422, number of negative: 18418
2024-06-23 10:00:55,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013893 seconds.
2024-06-23 10:00:55,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:55,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:55,633:INFO:[LightGBM] [Info] Total Bins 14617
2024-06-23 10:00:55,637:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:55,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500054 -> initscore=0.000217
2024-06-23 10:00:55,639:INFO:[LightGBM] [Info] Start training from score 0.000217
2024-06-23 10:00:56,741:INFO:[LightGBM] [Info] Number of positive: 18502, number of negative: 18338
2024-06-23 10:00:56,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015500 seconds.
2024-06-23 10:00:56,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:56,767:INFO:[LightGBM] [Info] Total Bins 14619
2024-06-23 10:00:56,769:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:56,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502226 -> initscore=0.008903
2024-06-23 10:00:56,769:INFO:[LightGBM] [Info] Start training from score 0.008903
2024-06-23 10:00:57,951:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18419
2024-06-23 10:00:57,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021486 seconds.
2024-06-23 10:00:57,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:00:57,969:INFO:[LightGBM] [Info] Total Bins 14600
2024-06-23 10:00:57,986:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:57,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500027 -> initscore=0.000109
2024-06-23 10:00:57,988:INFO:[LightGBM] [Info] Start training from score 0.000109
2024-06-23 10:00:59,270:INFO:[LightGBM] [Info] Number of positive: 18416, number of negative: 18424
2024-06-23 10:00:59,318:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014933 seconds.
2024-06-23 10:00:59,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:00:59,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:00:59,318:INFO:[LightGBM] [Info] Total Bins 14621
2024-06-23 10:00:59,320:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:00:59,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499891 -> initscore=-0.000434
2024-06-23 10:00:59,323:INFO:[LightGBM] [Info] Start training from score -0.000434
2024-06-23 10:01:00,665:INFO:[LightGBM] [Info] Number of positive: 18398, number of negative: 18442
2024-06-23 10:01:00,694:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016050 seconds.
2024-06-23 10:01:00,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:01:00,695:INFO:[LightGBM] [Info] Total Bins 14611
2024-06-23 10:01:00,697:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:01:00,699:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499403 -> initscore=-0.002389
2024-06-23 10:01:00,699:INFO:[LightGBM] [Info] Start training from score -0.002389
2024-06-23 10:01:02,062:INFO:[LightGBM] [Info] Number of positive: 18437, number of negative: 18403
2024-06-23 10:01:02,097:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023476 seconds.
2024-06-23 10:01:02,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:01:02,098:INFO:[LightGBM] [Info] Total Bins 14602
2024-06-23 10:01:02,100:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:01:02,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500461 -> initscore=0.001846
2024-06-23 10:01:02,102:INFO:[LightGBM] [Info] Start training from score 0.001846
2024-06-23 10:01:03,321:INFO:[LightGBM] [Info] Number of positive: 18406, number of negative: 18434
2024-06-23 10:01:03,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013739 seconds.
2024-06-23 10:01:03,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:01:03,352:INFO:[LightGBM] [Info] Total Bins 14593
2024-06-23 10:01:03,355:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:01:03,356:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499620 -> initscore=-0.001520
2024-06-23 10:01:03,356:INFO:[LightGBM] [Info] Start training from score -0.001520
2024-06-23 10:01:04,572:INFO:[LightGBM] [Info] Number of positive: 18432, number of negative: 18408
2024-06-23 10:01:04,615:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016522 seconds.
2024-06-23 10:01:04,615:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:01:04,615:INFO:[LightGBM] [Info] Total Bins 14620
2024-06-23 10:01:04,617:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:01:04,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500326 -> initscore=0.001303
2024-06-23 10:01:04,618:INFO:[LightGBM] [Info] Start training from score 0.001303
2024-06-23 10:01:05,807:INFO:[LightGBM] [Info] Number of positive: 18409, number of negative: 18431
2024-06-23 10:01:05,845:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016147 seconds.
2024-06-23 10:01:05,845:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:01:05,846:INFO:[LightGBM] [Info] Total Bins 14625
2024-06-23 10:01:05,847:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:01:05,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499701 -> initscore=-0.001194
2024-06-23 10:01:05,849:INFO:[LightGBM] [Info] Start training from score -0.001194
2024-06-23 10:01:07,022:INFO:[LightGBM] [Info] Number of positive: 18375, number of negative: 18465
2024-06-23 10:01:07,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017555 seconds.
2024-06-23 10:01:07,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:01:07,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:01:07,058:INFO:[LightGBM] [Info] Total Bins 14624
2024-06-23 10:01:07,060:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:01:07,061:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498779 -> initscore=-0.004886
2024-06-23 10:01:07,062:INFO:[LightGBM] [Info] Start training from score -0.004886
2024-06-23 10:01:09,923:INFO:Scoring test/hold-out set
2024-06-23 10:01:10,531:INFO:Visual Rendered Successfully
2024-06-23 10:01:10,664:INFO:plot_model() successfully completed......................................
2024-06-23 10:01:10,675:INFO:Initializing evaluate_model()
2024-06-23 10:01:10,675:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:01:10,724:INFO:Initializing plot_model()
2024-06-23 10:01:10,725:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:10,725:INFO:Checking exceptions
2024-06-23 10:01:10,736:INFO:Preloading libraries
2024-06-23 10:01:10,758:INFO:Copying training dataset
2024-06-23 10:01:10,758:INFO:Plot type: pipeline
2024-06-23 10:01:11,018:INFO:Visual Rendered Successfully
2024-06-23 10:01:11,122:INFO:plot_model() successfully completed......................................
2024-06-23 10:01:11,150:INFO:Initializing plot_model()
2024-06-23 10:01:11,151:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:11,151:INFO:Checking exceptions
2024-06-23 10:01:11,164:INFO:Preloading libraries
2024-06-23 10:01:11,258:INFO:Copying training dataset
2024-06-23 10:01:11,259:INFO:Plot type: feature
2024-06-23 10:01:11,259:WARNING:No coef_ found. Trying feature_importances_
2024-06-23 10:01:11,600:INFO:Visual Rendered Successfully
2024-06-23 10:01:11,701:INFO:plot_model() successfully completed......................................
2024-06-23 10:01:19,636:INFO:Initializing plot_model()
2024-06-23 10:01:19,636:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:19,636:INFO:Checking exceptions
2024-06-23 10:01:19,651:INFO:Preloading libraries
2024-06-23 10:01:19,669:INFO:Copying training dataset
2024-06-23 10:01:19,670:INFO:Plot type: parameter
2024-06-23 10:01:19,679:INFO:Visual Rendered Successfully
2024-06-23 10:01:19,839:INFO:plot_model() successfully completed......................................
2024-06-23 10:01:26,747:INFO:Initializing plot_model()
2024-06-23 10:01:26,747:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:26,747:INFO:Checking exceptions
2024-06-23 10:01:40,128:INFO:Initializing plot_model()
2024-06-23 10:01:40,128:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:40,128:INFO:Checking exceptions
2024-06-23 10:01:40,140:INFO:Preloading libraries
2024-06-23 10:01:40,167:INFO:Copying training dataset
2024-06-23 10:01:40,167:INFO:Plot type: feature
2024-06-23 10:01:40,168:WARNING:No coef_ found. Trying feature_importances_
2024-06-23 10:01:40,532:INFO:Visual Rendered Successfully
2024-06-23 10:01:40,686:INFO:plot_model() successfully completed......................................
2024-06-23 10:01:47,167:INFO:Initializing plot_model()
2024-06-23 10:01:47,167:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:47,168:INFO:Checking exceptions
2024-06-23 10:01:47,181:INFO:Preloading libraries
2024-06-23 10:01:47,198:INFO:Copying training dataset
2024-06-23 10:01:47,198:INFO:Plot type: feature_all
2024-06-23 10:01:47,362:WARNING:No coef_ found. Trying feature_importances_
2024-06-23 10:01:48,076:INFO:Visual Rendered Successfully
2024-06-23 10:01:48,178:INFO:plot_model() successfully completed......................................
2024-06-23 10:01:59,574:INFO:Initializing plot_model()
2024-06-23 10:01:59,574:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=manifold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:01:59,574:INFO:Checking exceptions
2024-06-23 10:01:59,586:INFO:Preloading libraries
2024-06-23 10:01:59,605:INFO:Copying training dataset
2024-06-23 10:01:59,605:INFO:Plot type: manifold
2024-06-23 10:02:00,028:INFO:Fitting & Transforming Model
2024-06-23 10:03:46,836:INFO:Initializing evaluate_model()
2024-06-23 10:03:46,836:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:03:46,873:INFO:Initializing plot_model()
2024-06-23 10:03:46,874:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:03:46,874:INFO:Checking exceptions
2024-06-23 10:03:46,886:INFO:Preloading libraries
2024-06-23 10:03:46,910:INFO:Copying training dataset
2024-06-23 10:03:46,910:INFO:Plot type: pipeline
2024-06-23 10:03:47,413:INFO:Visual Rendered Successfully
2024-06-23 10:03:47,646:INFO:plot_model() successfully completed......................................
2024-06-23 10:03:47,694:INFO:Initializing evaluate_model()
2024-06-23 10:03:47,694:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:03:47,751:INFO:Initializing plot_model()
2024-06-23 10:03:47,753:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:03:47,753:INFO:Checking exceptions
2024-06-23 10:03:47,770:INFO:Preloading libraries
2024-06-23 10:03:47,844:INFO:Copying training dataset
2024-06-23 10:03:47,844:INFO:Plot type: pipeline
2024-06-23 10:03:48,432:INFO:Visual Rendered Successfully
2024-06-23 10:03:48,668:INFO:plot_model() successfully completed......................................
2024-06-23 10:03:48,745:INFO:Initializing plot_model()
2024-06-23 10:03:48,745:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:03:48,745:INFO:Checking exceptions
2024-06-23 10:03:48,770:INFO:Preloading libraries
2024-06-23 10:03:48,795:INFO:Copying training dataset
2024-06-23 10:03:48,795:INFO:Plot type: rfe
2024-06-23 10:03:49,615:INFO:Fitting Model
2024-06-23 10:03:49,912:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:49,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021641 seconds.
2024-06-23 10:03:49,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:03:49,961:INFO:[LightGBM] [Info] Total Bins 14647
2024-06-23 10:03:49,969:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:03:49,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:03:51,515:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:51,565:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024793 seconds.
2024-06-23 10:03:51,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:03:51,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:03:51,565:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:03:51,569:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:03:51,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:03:53,074:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:53,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025481 seconds.
2024-06-23 10:03:53,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:03:53,118:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:03:53,118:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:03:53,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:03:54,664:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:54,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022388 seconds.
2024-06-23 10:03:54,715:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:03:54,717:INFO:[LightGBM] [Info] Total Bins 14383
2024-06-23 10:03:54,719:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:03:54,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:03:56,063:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:56,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020934 seconds.
2024-06-23 10:03:56,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:03:56,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:03:56,105:INFO:[LightGBM] [Info] Total Bins 14128
2024-06-23 10:03:56,105:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:03:56,105:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:03:57,457:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:57,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021328 seconds.
2024-06-23 10:03:57,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:03:57,498:INFO:[LightGBM] [Info] Total Bins 14085
2024-06-23 10:03:57,498:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:03:57,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:03:59,167:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:03:59,208:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024164 seconds.
2024-06-23 10:03:59,208:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:03:59,210:INFO:[LightGBM] [Info] Total Bins 14072
2024-06-23 10:03:59,210:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:03:59,210:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:00,593:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:00,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019542 seconds.
2024-06-23 10:04:00,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:00,631:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:04:00,631:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:04:00,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:02,080:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:02,120:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024637 seconds.
2024-06-23 10:04:02,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:02,120:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:04:02,120:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:04:02,120:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:03,639:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:03,690:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036082 seconds.
2024-06-23 10:04:03,690:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:03,698:INFO:[LightGBM] [Info] Total Bins 13783
2024-06-23 10:04:03,700:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:04:03,701:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:04,948:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:04,998:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025211 seconds.
2024-06-23 10:04:04,998:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:04,998:INFO:[LightGBM] [Info] Total Bins 13528
2024-06-23 10:04:04,998:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:04:05,002:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:06,233:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:06,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017236 seconds.
2024-06-23 10:04:06,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:06,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:06,274:INFO:[LightGBM] [Info] Total Bins 13422
2024-06-23 10:04:06,282:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:04:06,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:07,502:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:07,541:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019585 seconds.
2024-06-23 10:04:07,541:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:07,542:INFO:[LightGBM] [Info] Total Bins 13260
2024-06-23 10:04:07,544:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:04:07,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:09,025:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:09,067:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016168 seconds.
2024-06-23 10:04:09,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:09,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:09,068:INFO:[LightGBM] [Info] Total Bins 13005
2024-06-23 10:04:09,069:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:04:09,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:12,933:INFO:Initializing plot_model()
2024-06-23 10:04:12,933:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:04:12,935:INFO:Checking exceptions
2024-06-23 10:04:12,950:INFO:Preloading libraries
2024-06-23 10:04:12,970:INFO:Copying training dataset
2024-06-23 10:04:12,970:INFO:Plot type: learning
2024-06-23 10:04:13,628:INFO:Fitting Model
2024-06-23 10:04:15,771:INFO:Initializing evaluate_model()
2024-06-23 10:04:15,771:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:04:15,807:INFO:Initializing plot_model()
2024-06-23 10:04:15,807:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:04:15,808:INFO:Checking exceptions
2024-06-23 10:04:15,816:INFO:Preloading libraries
2024-06-23 10:04:15,829:INFO:Copying training dataset
2024-06-23 10:04:15,829:INFO:Plot type: pipeline
2024-06-23 10:04:16,304:INFO:Visual Rendered Successfully
2024-06-23 10:04:16,580:INFO:plot_model() successfully completed......................................
2024-06-23 10:04:16,624:INFO:Initializing evaluate_model()
2024-06-23 10:04:16,624:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:04:16,667:INFO:Initializing plot_model()
2024-06-23 10:04:16,667:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:04:16,667:INFO:Checking exceptions
2024-06-23 10:04:16,686:INFO:Preloading libraries
2024-06-23 10:04:16,703:INFO:Copying training dataset
2024-06-23 10:04:16,703:INFO:Plot type: pipeline
2024-06-23 10:04:17,147:INFO:Visual Rendered Successfully
2024-06-23 10:04:17,394:INFO:plot_model() successfully completed......................................
2024-06-23 10:04:17,487:INFO:Initializing evaluate_model()
2024-06-23 10:04:17,487:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:04:17,584:INFO:Initializing plot_model()
2024-06-23 10:04:17,587:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:04:17,587:INFO:Checking exceptions
2024-06-23 10:04:17,597:INFO:Preloading libraries
2024-06-23 10:04:17,668:INFO:Copying training dataset
2024-06-23 10:04:17,668:INFO:Plot type: pipeline
2024-06-23 10:04:18,279:INFO:Visual Rendered Successfully
2024-06-23 10:04:18,544:INFO:plot_model() successfully completed......................................
2024-06-23 10:04:18,595:INFO:Initializing plot_model()
2024-06-23 10:04:18,595:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:04:18,595:INFO:Checking exceptions
2024-06-23 10:04:18,609:INFO:Preloading libraries
2024-06-23 10:04:18,654:INFO:Copying training dataset
2024-06-23 10:04:18,654:INFO:Plot type: rfe
2024-06-23 10:04:19,336:INFO:Fitting Model
2024-06-23 10:04:19,705:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:19,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031493 seconds.
2024-06-23 10:04:19,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:19,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:19,777:INFO:[LightGBM] [Info] Total Bins 14647
2024-06-23 10:04:19,778:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:04:19,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:21,239:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:21,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019304 seconds.
2024-06-23 10:04:21,280:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:21,280:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:21,280:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:04:21,280:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:04:21,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:22,536:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:22,587:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025709 seconds.
2024-06-23 10:04:22,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:22,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:22,587:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:04:22,587:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:04:22,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:24,061:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:24,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022413 seconds.
2024-06-23 10:04:24,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:24,101:INFO:[LightGBM] [Info] Total Bins 14383
2024-06-23 10:04:24,103:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:04:24,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:25,429:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:25,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025218 seconds.
2024-06-23 10:04:25,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:25,469:INFO:[LightGBM] [Info] Total Bins 14128
2024-06-23 10:04:25,469:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:04:25,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:26,758:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:26,798:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023982 seconds.
2024-06-23 10:04:26,798:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:26,798:INFO:[LightGBM] [Info] Total Bins 14085
2024-06-23 10:04:26,807:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:04:26,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:28,291:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:28,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020359 seconds.
2024-06-23 10:04:28,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:28,333:INFO:[LightGBM] [Info] Total Bins 14072
2024-06-23 10:04:28,333:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:04:28,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:29,659:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:29,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032096 seconds.
2024-06-23 10:04:29,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:29,710:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:04:29,710:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:04:29,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:30,986:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:31,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020525 seconds.
2024-06-23 10:04:31,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:31,027:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:04:31,028:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:04:31,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:32,330:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:32,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018157 seconds.
2024-06-23 10:04:32,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:32,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:32,368:INFO:[LightGBM] [Info] Total Bins 13783
2024-06-23 10:04:32,368:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:04:32,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:33,629:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:33,670:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019466 seconds.
2024-06-23 10:04:33,670:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:33,670:INFO:[LightGBM] [Info] Total Bins 13528
2024-06-23 10:04:33,672:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:04:33,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:34,919:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:34,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019379 seconds.
2024-06-23 10:04:34,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:34,961:INFO:[LightGBM] [Info] Total Bins 13422
2024-06-23 10:04:34,967:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:04:34,969:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:36,217:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:36,258:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020580 seconds.
2024-06-23 10:04:36,258:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:36,265:INFO:[LightGBM] [Info] Total Bins 13260
2024-06-23 10:04:36,267:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:04:36,267:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:37,573:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:37,614:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024132 seconds.
2024-06-23 10:04:37,614:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:37,614:INFO:[LightGBM] [Info] Total Bins 13005
2024-06-23 10:04:37,622:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:04:37,624:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:38,820:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:38,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027089 seconds.
2024-06-23 10:04:38,870:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:38,878:INFO:[LightGBM] [Info] Total Bins 12750
2024-06-23 10:04:38,880:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:04:38,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:40,107:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:40,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021446 seconds.
2024-06-23 10:04:40,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:40,144:INFO:[LightGBM] [Info] Total Bins 12495
2024-06-23 10:04:40,146:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:04:40,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:41,631:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:41,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016239 seconds.
2024-06-23 10:04:41,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:41,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:41,664:INFO:[LightGBM] [Info] Total Bins 12240
2024-06-23 10:04:41,664:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:04:41,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:43,076:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:43,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037375 seconds.
2024-06-23 10:04:43,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:43,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:43,170:INFO:[LightGBM] [Info] Total Bins 11985
2024-06-23 10:04:43,170:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:04:43,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:44,517:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:44,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014600 seconds.
2024-06-23 10:04:44,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:44,557:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:44,557:INFO:[LightGBM] [Info] Total Bins 11730
2024-06-23 10:04:44,557:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:04:44,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:45,948:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:45,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017589 seconds.
2024-06-23 10:04:45,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:45,985:INFO:[LightGBM] [Info] Total Bins 11475
2024-06-23 10:04:45,986:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:04:45,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:47,103:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:47,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015894 seconds.
2024-06-23 10:04:47,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:47,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:47,147:INFO:[LightGBM] [Info] Total Bins 11220
2024-06-23 10:04:47,149:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:04:47,151:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:48,284:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:48,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017494 seconds.
2024-06-23 10:04:48,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:48,324:INFO:[LightGBM] [Info] Total Bins 10965
2024-06-23 10:04:48,324:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:04:48,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:49,503:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:49,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020305 seconds.
2024-06-23 10:04:49,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:49,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:49,547:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:04:49,548:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:04:49,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:50,782:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:50,800:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013030 seconds.
2024-06-23 10:04:50,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:50,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:50,800:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:04:50,800:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:04:50,800:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:51,974:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:52,009:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018292 seconds.
2024-06-23 10:04:52,009:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:52,010:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:04:52,011:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:04:52,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:53,147:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:53,183:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017257 seconds.
2024-06-23 10:04:53,183:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:53,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:53,184:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:04:53,185:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:04:53,186:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:54,182:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:54,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014262 seconds.
2024-06-23 10:04:54,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:54,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:54,217:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:04:54,217:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:04:54,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:55,243:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:55,267:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013331 seconds.
2024-06-23 10:04:55,267:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:55,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:55,267:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:04:55,267:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:04:55,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:56,282:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:56,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015395 seconds.
2024-06-23 10:04:56,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:56,313:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:04:56,313:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:04:56,313:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:57,341:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:57,372:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018199 seconds.
2024-06-23 10:04:57,372:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:04:57,372:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:04:57,372:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:04:57,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:58,543:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:58,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013047 seconds.
2024-06-23 10:04:58,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:58,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:58,569:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:04:58,570:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:04:58,570:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:04:59,941:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:04:59,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015819 seconds.
2024-06-23 10:04:59,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:04:59,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:04:59,973:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:04:59,974:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:04:59,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:01,296:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:01,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010596 seconds.
2024-06-23 10:05:01,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:01,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:01,324:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:05:01,324:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:05:01,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:02,760:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:02,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011355 seconds.
2024-06-23 10:05:02,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:02,785:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:02,785:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:05:02,786:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:05:02,787:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:03,950:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:03,974:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010140 seconds.
2024-06-23 10:05:03,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:03,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:03,975:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:05:03,975:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:05:03,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:05,426:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:05,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017017 seconds.
2024-06-23 10:05:05,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:05,463:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:05,463:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:05:05,464:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:05:05,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:06,823:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:06,862:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016404 seconds.
2024-06-23 10:05:06,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:06,863:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:05:06,864:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:05:06,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:09,180:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:09,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013491 seconds.
2024-06-23 10:05:09,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:09,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:09,208:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:05:09,208:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:05:09,209:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:10,496:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:10,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017066 seconds.
2024-06-23 10:05:10,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:10,526:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:05:10,526:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:05:10,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:11,855:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:11,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016999 seconds.
2024-06-23 10:05:11,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:11,885:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:05:11,886:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:05:11,887:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:13,151:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:13,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013006 seconds.
2024-06-23 10:05:13,178:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:13,178:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:13,178:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:05:13,179:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:05:13,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:14,313:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:14,335:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010656 seconds.
2024-06-23 10:05:14,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:14,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:14,337:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:05:14,337:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:05:14,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:15,432:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:15,456:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012086 seconds.
2024-06-23 10:05:15,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:15,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:15,457:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:05:15,458:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:05:15,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:16,682:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:16,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018843 seconds.
2024-06-23 10:05:16,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:16,712:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:05:16,713:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:05:16,714:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:17,905:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:17,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009915 seconds.
2024-06-23 10:05:17,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:17,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:17,928:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:05:17,929:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:05:17,930:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:19,004:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:19,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008344 seconds.
2024-06-23 10:05:19,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:19,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:19,024:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:05:19,025:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:05:19,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:20,105:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:20,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011827 seconds.
2024-06-23 10:05:20,125:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:20,125:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:05:20,126:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:05:20,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:21,223:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:21,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012120 seconds.
2024-06-23 10:05:21,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:21,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:21,246:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:05:21,247:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:05:21,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:22,204:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:22,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007951 seconds.
2024-06-23 10:05:22,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:22,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:22,225:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:05:22,225:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:05:22,226:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:23,159:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:23,181:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007250 seconds.
2024-06-23 10:05:23,181:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:23,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:23,182:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:05:23,183:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:05:23,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:24,137:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:24,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005820 seconds.
2024-06-23 10:05:24,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:24,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:24,155:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:05:24,155:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:05:24,156:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:25,151:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:25,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007168 seconds.
2024-06-23 10:05:25,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:25,164:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:05:25,165:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:05:25,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:26,112:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:26,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005559 seconds.
2024-06-23 10:05:26,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:26,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:26,126:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:05:26,126:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:05:26,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:27,008:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:27,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012262 seconds.
2024-06-23 10:05:27,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:27,028:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:05:27,028:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:05:27,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:27,891:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:27,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006475 seconds.
2024-06-23 10:05:27,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:27,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:27,910:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:05:27,911:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:05:27,914:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:28,699:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:28,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004026 seconds.
2024-06-23 10:05:28,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:28,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:28,711:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:05:28,711:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:05:28,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:29,412:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:29,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003066 seconds.
2024-06-23 10:05:29,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:29,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:29,422:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:05:29,423:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:05:29,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:30,087:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:30,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.
2024-06-23 10:05:30,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:30,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:30,098:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:05:30,098:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:05:30,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:30,775:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:30,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005065 seconds.
2024-06-23 10:05:30,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:30,780:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:05:30,780:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:05:30,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:31,403:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:31,405:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.
2024-06-23 10:05:31,405:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:31,405:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:05:31,406:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:05:31,407:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:31,984:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:31,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002014 seconds.
2024-06-23 10:05:31,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:31,987:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:05:31,988:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:05:31,989:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:32,519:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:32,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001775 seconds.
2024-06-23 10:05:32,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:32,523:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:05:32,523:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:05:32,527:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:33,093:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:33,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.
2024-06-23 10:05:33,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:33,095:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:05:33,097:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:05:33,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:33,623:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:33,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001297 seconds.
2024-06-23 10:05:33,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:33,627:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:05:33,627:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:05:33,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:34,472:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:34,534:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038460 seconds.
2024-06-23 10:05:34,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:34,538:INFO:[LightGBM] [Info] Total Bins 14621
2024-06-23 10:05:34,538:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:05:34,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:36,582:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:36,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027583 seconds.
2024-06-23 10:05:36,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:36,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:36,642:INFO:[LightGBM] [Info] Total Bins 14366
2024-06-23 10:05:36,643:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:05:36,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:38,540:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:38,598:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035011 seconds.
2024-06-23 10:05:38,598:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:38,602:INFO:[LightGBM] [Info] Total Bins 14366
2024-06-23 10:05:38,607:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:05:38,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:40,482:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:40,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024632 seconds.
2024-06-23 10:05:40,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:40,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:40,534:INFO:[LightGBM] [Info] Total Bins 14111
2024-06-23 10:05:40,534:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:05:40,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:42,308:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:42,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030929 seconds.
2024-06-23 10:05:42,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:42,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:42,369:INFO:[LightGBM] [Info] Total Bins 14103
2024-06-23 10:05:42,371:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:05:42,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:44,162:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:44,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023192 seconds.
2024-06-23 10:05:44,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:44,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:44,216:INFO:[LightGBM] [Info] Total Bins 14103
2024-06-23 10:05:44,216:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:05:44,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:46,051:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:46,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030351 seconds.
2024-06-23 10:05:46,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:46,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:46,110:INFO:[LightGBM] [Info] Total Bins 14091
2024-06-23 10:05:46,114:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:05:46,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:47,885:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:47,939:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029638 seconds.
2024-06-23 10:05:47,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:47,943:INFO:[LightGBM] [Info] Total Bins 14059
2024-06-23 10:05:47,947:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:05:47,951:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:49,793:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:49,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021860 seconds.
2024-06-23 10:05:49,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:49,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:49,843:INFO:[LightGBM] [Info] Total Bins 13804
2024-06-23 10:05:49,848:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:05:49,848:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:51,588:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:51,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027009 seconds.
2024-06-23 10:05:51,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:51,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:51,646:INFO:[LightGBM] [Info] Total Bins 13704
2024-06-23 10:05:51,646:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:05:51,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:53,395:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:53,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021077 seconds.
2024-06-23 10:05:53,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:05:53,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:05:53,452:INFO:[LightGBM] [Info] Total Bins 13449
2024-06-23 10:05:53,453:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:05:53,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:55,239:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:55,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035126 seconds.
2024-06-23 10:05:55,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:55,298:INFO:[LightGBM] [Info] Total Bins 13194
2024-06-23 10:05:55,301:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:05:55,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:57,077:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:57,127:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024392 seconds.
2024-06-23 10:05:57,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:57,127:INFO:[LightGBM] [Info] Total Bins 13155
2024-06-23 10:05:57,127:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:05:57,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:05:58,921:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:05:58,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028730 seconds.
2024-06-23 10:05:58,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:05:58,974:INFO:[LightGBM] [Info] Total Bins 12900
2024-06-23 10:05:58,976:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:05:58,979:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:00,943:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:00,983:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022783 seconds.
2024-06-23 10:06:00,983:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:00,983:INFO:[LightGBM] [Info] Total Bins 12645
2024-06-23 10:06:00,983:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:06:00,986:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:02,364:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:02,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020239 seconds.
2024-06-23 10:06:02,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:02,396:INFO:[LightGBM] [Info] Total Bins 12390
2024-06-23 10:06:02,396:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:06:02,403:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:03,817:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:03,839:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013701 seconds.
2024-06-23 10:06:03,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:03,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:03,848:INFO:[LightGBM] [Info] Total Bins 12135
2024-06-23 10:06:03,848:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:06:03,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:05,035:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:05,075:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022269 seconds.
2024-06-23 10:06:05,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:05,075:INFO:[LightGBM] [Info] Total Bins 11880
2024-06-23 10:06:05,077:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:06:05,077:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:06,284:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:06,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012413 seconds.
2024-06-23 10:06:06,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:06,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:06,314:INFO:[LightGBM] [Info] Total Bins 11625
2024-06-23 10:06:06,315:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:06:06,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:07,486:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:07,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024076 seconds.
2024-06-23 10:06:07,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:07,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:07,537:INFO:[LightGBM] [Info] Total Bins 11370
2024-06-23 10:06:07,539:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:06:07,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:08,600:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:08,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014901 seconds.
2024-06-23 10:06:08,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:08,627:INFO:[LightGBM] [Info] Total Bins 11115
2024-06-23 10:06:08,627:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:06:08,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:09,873:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:09,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019586 seconds.
2024-06-23 10:06:09,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:09,910:INFO:[LightGBM] [Info] Total Bins 10960
2024-06-23 10:06:09,910:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:06:09,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:11,156:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:11,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019400 seconds.
2024-06-23 10:06:11,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:11,192:INFO:[LightGBM] [Info] Total Bins 10705
2024-06-23 10:06:11,194:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:06:11,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:12,380:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:12,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011945 seconds.
2024-06-23 10:06:12,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:12,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:12,402:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:06:12,402:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:06:12,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:13,491:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:13,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020421 seconds.
2024-06-23 10:06:13,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:13,527:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:06:13,528:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:06:13,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:14,721:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:14,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016063 seconds.
2024-06-23 10:06:14,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:14,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:14,751:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:06:14,751:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:06:14,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:15,787:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:15,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022398 seconds.
2024-06-23 10:06:15,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:15,828:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:06:15,828:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:06:15,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:16,871:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:16,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013983 seconds.
2024-06-23 10:06:16,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:16,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:16,900:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:06:16,902:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:06:16,902:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:17,867:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:17,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010838 seconds.
2024-06-23 10:06:17,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:17,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:17,895:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:06:17,897:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:06:17,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:18,806:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:18,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015442 seconds.
2024-06-23 10:06:18,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:18,828:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:06:18,828:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:06:18,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:19,862:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:19,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011408 seconds.
2024-06-23 10:06:19,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:19,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:19,883:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:06:19,883:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:06:19,883:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:20,924:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:20,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018323 seconds.
2024-06-23 10:06:20,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:20,955:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:06:20,955:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:06:20,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:21,948:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:21,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007663 seconds.
2024-06-23 10:06:21,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:21,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:21,958:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:06:21,958:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:06:21,969:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:22,585:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:22,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007086 seconds.
2024-06-23 10:06:22,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:22,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:22,596:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:06:22,596:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:06:22,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:23,332:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:23,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012279 seconds.
2024-06-23 10:06:23,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:23,347:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:06:23,347:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:06:23,352:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:24,209:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:24,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008391 seconds.
2024-06-23 10:06:24,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:24,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:24,219:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:06:24,219:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:06:24,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:24,867:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:24,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005691 seconds.
2024-06-23 10:06:24,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:24,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:24,877:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:06:24,877:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:06:24,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:25,455:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:25,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005481 seconds.
2024-06-23 10:06:25,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:25,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:25,465:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:06:25,465:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:06:25,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:26,033:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:26,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006306 seconds.
2024-06-23 10:06:26,053:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:26,053:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:26,053:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:06:26,053:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:06:26,053:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:26,658:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:26,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005195 seconds.
2024-06-23 10:06:26,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:26,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:26,670:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:06:26,670:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:06:26,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:27,217:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:27,227:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005058 seconds.
2024-06-23 10:06:27,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:27,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:27,227:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:06:27,227:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:06:27,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:27,752:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:27,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006381 seconds.
2024-06-23 10:06:27,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:27,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:27,762:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:06:27,762:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:06:27,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:28,289:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:28,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004976 seconds.
2024-06-23 10:06:28,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:28,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:28,299:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:06:28,299:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:06:28,299:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:28,805:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:28,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005840 seconds.
2024-06-23 10:06:28,813:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:28,815:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:06:28,815:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:06:28,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:29,332:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:29,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004211 seconds.
2024-06-23 10:06:29,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:29,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:29,342:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:06:29,342:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:06:29,342:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:29,824:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:29,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006760 seconds.
2024-06-23 10:06:29,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:29,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:29,836:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:06:29,836:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:06:29,836:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:30,323:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:30,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003909 seconds.
2024-06-23 10:06:30,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:30,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:30,333:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:06:30,333:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:06:30,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:30,870:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:30,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003805 seconds.
2024-06-23 10:06:30,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:30,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:30,880:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:06:30,880:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:06:30,880:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:31,344:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:31,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004697 seconds.
2024-06-23 10:06:31,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:31,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:31,355:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:06:31,355:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:06:31,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:31,780:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:31,790:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003366 seconds.
2024-06-23 10:06:31,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:31,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:31,790:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:06:31,790:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:06:31,790:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:32,214:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:32,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004619 seconds.
2024-06-23 10:06:32,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:32,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:32,224:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:06:32,224:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:06:32,224:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:32,670:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:32,680:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006551 seconds.
2024-06-23 10:06:32,680:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:32,680:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:06:32,680:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:06:32,680:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:33,136:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:33,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003765 seconds.
2024-06-23 10:06:33,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:33,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:33,146:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:06:33,146:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:06:33,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:33,532:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:33,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003390 seconds.
2024-06-23 10:06:33,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:33,542:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:06:33,542:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:06:33,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:33,935:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:33,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002926 seconds.
2024-06-23 10:06:33,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:33,945:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:06:33,945:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:06:33,945:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:34,326:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:34,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.
2024-06-23 10:06:34,328:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:34,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:34,328:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:06:34,328:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:06:34,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:34,671:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:34,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004406 seconds.
2024-06-23 10:06:34,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:34,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:34,681:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:06:34,681:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:06:34,681:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:35,014:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:35,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.
2024-06-23 10:06:35,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:35,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:35,022:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:06:35,022:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:06:35,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:35,347:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:35,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.
2024-06-23 10:06:35,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:35,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:35,355:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:06:35,355:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:06:35,355:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:35,627:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:35,629:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001059 seconds.
2024-06-23 10:06:35,629:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:35,629:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:35,629:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:06:35,629:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:06:35,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:35,964:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:35,972:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004776 seconds.
2024-06-23 10:06:35,972:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:35,972:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:06:35,974:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:06:35,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:36,328:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:36,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.
2024-06-23 10:06:36,328:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:36,328:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:36,328:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:06:36,328:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:06:36,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:36,602:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:36,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-06-23 10:06:36,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:36,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:36,602:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:06:36,602:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:06:36,602:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:36,893:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:36,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-06-23 10:06:36,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:36,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:36,893:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:06:36,893:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:06:36,895:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:37,339:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:37,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016978 seconds.
2024-06-23 10:06:37,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:37,369:INFO:[LightGBM] [Info] Total Bins 14600
2024-06-23 10:06:37,369:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:06:37,369:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:38,338:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:38,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013900 seconds.
2024-06-23 10:06:38,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:38,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:38,360:INFO:[LightGBM] [Info] Total Bins 14345
2024-06-23 10:06:38,368:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:06:38,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:39,276:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:39,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011285 seconds.
2024-06-23 10:06:39,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:39,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:39,299:INFO:[LightGBM] [Info] Total Bins 14345
2024-06-23 10:06:39,299:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:06:39,299:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:40,209:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:40,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014587 seconds.
2024-06-23 10:06:40,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:40,240:INFO:[LightGBM] [Info] Total Bins 14333
2024-06-23 10:06:40,240:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:06:40,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:41,138:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:41,166:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014610 seconds.
2024-06-23 10:06:41,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:41,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:41,168:INFO:[LightGBM] [Info] Total Bins 14304
2024-06-23 10:06:41,168:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:06:41,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:42,062:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:42,090:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014258 seconds.
2024-06-23 10:06:42,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:42,092:INFO:[LightGBM] [Info] Total Bins 14304
2024-06-23 10:06:42,092:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:06:42,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:43,051:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:43,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010968 seconds.
2024-06-23 10:06:43,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:43,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:43,071:INFO:[LightGBM] [Info] Total Bins 14049
2024-06-23 10:06:43,071:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:06:43,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:44,107:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:44,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014452 seconds.
2024-06-23 10:06:44,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:44,135:INFO:[LightGBM] [Info] Total Bins 14040
2024-06-23 10:06:44,135:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:06:44,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:45,079:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:45,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015510 seconds.
2024-06-23 10:06:45,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:45,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:45,115:INFO:[LightGBM] [Info] Total Bins 13785
2024-06-23 10:06:45,115:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:06:45,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:45,987:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:46,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013510 seconds.
2024-06-23 10:06:46,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:46,011:INFO:[LightGBM] [Info] Total Bins 13749
2024-06-23 10:06:46,011:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:06:46,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:46,887:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:46,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011753 seconds.
2024-06-23 10:06:46,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:46,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:46,911:INFO:[LightGBM] [Info] Total Bins 13494
2024-06-23 10:06:46,911:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:06:46,911:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:47,827:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:47,850:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015785 seconds.
2024-06-23 10:06:47,850:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:47,850:INFO:[LightGBM] [Info] Total Bins 13409
2024-06-23 10:06:47,850:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:06:47,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:48,755:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:48,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009380 seconds.
2024-06-23 10:06:48,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:48,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:48,775:INFO:[LightGBM] [Info] Total Bins 13154
2024-06-23 10:06:48,779:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:06:48,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:49,711:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:49,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013190 seconds.
2024-06-23 10:06:49,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:49,743:INFO:[LightGBM] [Info] Total Bins 12899
2024-06-23 10:06:49,743:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:06:49,747:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:50,759:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:50,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009947 seconds.
2024-06-23 10:06:50,779:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:50,779:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:50,779:INFO:[LightGBM] [Info] Total Bins 12644
2024-06-23 10:06:50,779:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:06:50,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:51,975:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:52,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016274 seconds.
2024-06-23 10:06:52,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:52,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:52,007:INFO:[LightGBM] [Info] Total Bins 12389
2024-06-23 10:06:52,011:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:06:52,011:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:53,027:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:53,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009838 seconds.
2024-06-23 10:06:53,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:53,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:53,051:INFO:[LightGBM] [Info] Total Bins 12134
2024-06-23 10:06:53,051:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:06:53,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:53,955:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:53,983:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013143 seconds.
2024-06-23 10:06:53,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:53,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:53,983:INFO:[LightGBM] [Info] Total Bins 11879
2024-06-23 10:06:53,987:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:06:53,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:54,843:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:54,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013115 seconds.
2024-06-23 10:06:54,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:54,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:54,871:INFO:[LightGBM] [Info] Total Bins 11624
2024-06-23 10:06:54,871:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:06:54,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:55,711:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:55,743:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012495 seconds.
2024-06-23 10:06:55,743:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:55,743:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:55,743:INFO:[LightGBM] [Info] Total Bins 11469
2024-06-23 10:06:55,747:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:06:55,747:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:56,583:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:56,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012082 seconds.
2024-06-23 10:06:56,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:06:56,607:INFO:[LightGBM] [Info] Total Bins 11214
2024-06-23 10:06:56,607:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:06:56,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:57,443:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:57,467:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010346 seconds.
2024-06-23 10:06:57,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:57,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:57,467:INFO:[LightGBM] [Info] Total Bins 10959
2024-06-23 10:06:57,471:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:06:57,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:58,271:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:58,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009627 seconds.
2024-06-23 10:06:58,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:58,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:58,299:INFO:[LightGBM] [Info] Total Bins 10704
2024-06-23 10:06:58,299:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:06:58,299:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:06:59,255:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:06:59,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023717 seconds.
2024-06-23 10:06:59,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:06:59,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:06:59,295:INFO:[LightGBM] [Info] Total Bins 10449
2024-06-23 10:06:59,299:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:06:59,299:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:00,219:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:00,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012877 seconds.
2024-06-23 10:07:00,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:00,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:00,243:INFO:[LightGBM] [Info] Total Bins 10194
2024-06-23 10:07:00,247:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:07:00,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:01,047:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:01,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013711 seconds.
2024-06-23 10:07:01,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:01,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:01,075:INFO:[LightGBM] [Info] Total Bins 9939
2024-06-23 10:07:01,075:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:07:01,075:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:01,995:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:02,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009070 seconds.
2024-06-23 10:07:02,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:02,019:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:02,019:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:07:02,019:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:07:02,019:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:02,803:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:02,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012376 seconds.
2024-06-23 10:07:02,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:02,827:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:07:02,827:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:07:02,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:03,659:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:03,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009004 seconds.
2024-06-23 10:07:03,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:03,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:03,683:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:07:03,687:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:07:03,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:04,407:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:04,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010187 seconds.
2024-06-23 10:07:04,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:04,427:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:07:04,427:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:07:04,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:05,203:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:05,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009847 seconds.
2024-06-23 10:07:05,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:05,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:05,223:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:07:05,223:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:07:05,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:06,039:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:06,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008379 seconds.
2024-06-23 10:07:06,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:06,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:06,055:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:07:06,059:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:07:06,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:06,747:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:06,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007083 seconds.
2024-06-23 10:07:06,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:06,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:06,767:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:07:06,767:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:07:06,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:07,591:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:07,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011386 seconds.
2024-06-23 10:07:07,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:07,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:07,615:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:07:07,615:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:07:07,615:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:08,527:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:08,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008904 seconds.
2024-06-23 10:07:08,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:08,543:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:07:08,543:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:07:08,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:09,239:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:09,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009745 seconds.
2024-06-23 10:07:09,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:09,259:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:07:09,259:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:07:09,259:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:09,943:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:09,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006877 seconds.
2024-06-23 10:07:09,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:09,959:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:09,959:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:07:09,963:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:07:09,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:10,591:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:10,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006809 seconds.
2024-06-23 10:07:10,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:10,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:10,603:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:07:10,603:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:07:10,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:11,291:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:11,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007717 seconds.
2024-06-23 10:07:11,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:11,303:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:07:11,307:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:07:11,307:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:12,104:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:12,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005569 seconds.
2024-06-23 10:07:12,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:12,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:12,120:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:07:12,120:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:07:12,120:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:12,712:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:12,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007487 seconds.
2024-06-23 10:07:12,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:12,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:12,728:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:07:12,728:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:07:12,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:13,292:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:13,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005350 seconds.
2024-06-23 10:07:13,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:13,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:13,304:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:07:13,304:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:07:13,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:13,856:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:13,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004625 seconds.
2024-06-23 10:07:13,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:13,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:13,872:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:07:13,872:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:07:13,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:14,416:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:14,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005235 seconds.
2024-06-23 10:07:14,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:14,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:14,428:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:07:14,428:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:07:14,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:15,000:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:15,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005084 seconds.
2024-06-23 10:07:15,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:15,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:15,016:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:07:15,016:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:07:15,016:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:15,636:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:15,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006427 seconds.
2024-06-23 10:07:15,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:15,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:15,656:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:07:15,656:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:07:15,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:16,284:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:16,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003850 seconds.
2024-06-23 10:07:16,292:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:16,292:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:16,292:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:07:16,292:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:07:16,292:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:16,776:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:16,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004963 seconds.
2024-06-23 10:07:16,788:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:16,788:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:07:16,788:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:07:16,788:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:17,416:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:17,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005026 seconds.
2024-06-23 10:07:17,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:17,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:17,428:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:07:17,428:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:07:17,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:17,932:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:17,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002944 seconds.
2024-06-23 10:07:17,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:17,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:17,940:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:07:17,940:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:07:17,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:18,384:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:18,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004521 seconds.
2024-06-23 10:07:18,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:18,392:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:07:18,392:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:07:18,392:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:18,988:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:18,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003624 seconds.
2024-06-23 10:07:18,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:18,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:18,990:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:07:18,990:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:07:18,990:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:19,436:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:19,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003852 seconds.
2024-06-23 10:07:19,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:19,447:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:07:19,447:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:07:19,447:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:19,860:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:19,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002957 seconds.
2024-06-23 10:07:19,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:19,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:19,869:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:07:19,871:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:07:19,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:20,252:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:20,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005292 seconds.
2024-06-23 10:07:20,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:20,254:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:07:20,254:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:07:20,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:20,639:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:20,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002185 seconds.
2024-06-23 10:07:20,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:20,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:20,649:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:07:20,649:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:07:20,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:21,013:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:21,015:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002272 seconds.
2024-06-23 10:07:21,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:21,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:21,015:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:07:21,015:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:07:21,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:21,368:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:21,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003421 seconds.
2024-06-23 10:07:21,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:21,368:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:07:21,368:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:07:21,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:21,875:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:21,885:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.
2024-06-23 10:07:21,885:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:21,885:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:21,885:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:07:21,885:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:07:21,885:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:22,200:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:22,208:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001188 seconds.
2024-06-23 10:07:22,208:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:22,208:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:22,210:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:07:22,210:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:07:22,210:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:22,543:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:22,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.
2024-06-23 10:07:22,551:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:22,551:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:07:22,551:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:07:22,551:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:22,894:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:22,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-06-23 10:07:22,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:22,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:22,898:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:07:22,898:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:07:22,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:23,166:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:23,166:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000264 seconds.
2024-06-23 10:07:23,166:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:23,166:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:23,166:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:07:23,166:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:07:23,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:23,411:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:23,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000174 seconds.
2024-06-23 10:07:23,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:23,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:23,411:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:07:23,411:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:07:23,411:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:23,875:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:23,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019153 seconds.
2024-06-23 10:07:23,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:23,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:23,911:INFO:[LightGBM] [Info] Total Bins 14596
2024-06-23 10:07:23,915:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:07:23,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:25,000:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:25,040:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019005 seconds.
2024-06-23 10:07:25,040:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:25,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:25,040:INFO:[LightGBM] [Info] Total Bins 14341
2024-06-23 10:07:25,044:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:07:25,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:26,108:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:26,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016098 seconds.
2024-06-23 10:07:26,140:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:26,140:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:26,140:INFO:[LightGBM] [Info] Total Bins 14341
2024-06-23 10:07:26,144:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:07:26,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:27,056:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:27,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011386 seconds.
2024-06-23 10:07:27,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:27,080:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:27,084:INFO:[LightGBM] [Info] Total Bins 14086
2024-06-23 10:07:27,084:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:07:27,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:28,040:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:28,072:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020986 seconds.
2024-06-23 10:07:28,072:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:28,076:INFO:[LightGBM] [Info] Total Bins 14086
2024-06-23 10:07:28,076:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:07:28,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:29,204:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:29,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013451 seconds.
2024-06-23 10:07:29,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:29,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:29,236:INFO:[LightGBM] [Info] Total Bins 14074
2024-06-23 10:07:29,236:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:07:29,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:30,296:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:30,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015767 seconds.
2024-06-23 10:07:30,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:30,324:INFO:[LightGBM] [Info] Total Bins 14044
2024-06-23 10:07:30,324:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:07:30,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:31,296:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:31,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012944 seconds.
2024-06-23 10:07:31,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:31,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:31,324:INFO:[LightGBM] [Info] Total Bins 14035
2024-06-23 10:07:31,324:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:07:31,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:32,508:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:32,555:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014460 seconds.
2024-06-23 10:07:32,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:32,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:32,557:INFO:[LightGBM] [Info] Total Bins 13780
2024-06-23 10:07:32,561:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:07:32,562:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:33,691:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:33,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018998 seconds.
2024-06-23 10:07:33,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:33,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:33,735:INFO:[LightGBM] [Info] Total Bins 13740
2024-06-23 10:07:33,736:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:07:33,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:34,942:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:34,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017608 seconds.
2024-06-23 10:07:34,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:34,970:INFO:[LightGBM] [Info] Total Bins 13655
2024-06-23 10:07:34,974:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:07:34,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:36,096:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:36,129:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019736 seconds.
2024-06-23 10:07:36,129:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:36,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:36,129:INFO:[LightGBM] [Info] Total Bins 13400
2024-06-23 10:07:36,129:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:07:36,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:37,179:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:37,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015652 seconds.
2024-06-23 10:07:37,209:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:37,209:INFO:[LightGBM] [Info] Total Bins 13145
2024-06-23 10:07:37,209:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:07:37,213:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:38,252:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:38,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010456 seconds.
2024-06-23 10:07:38,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:38,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:38,276:INFO:[LightGBM] [Info] Total Bins 12890
2024-06-23 10:07:38,276:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:07:38,276:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:39,250:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:39,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013783 seconds.
2024-06-23 10:07:39,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:39,274:INFO:[LightGBM] [Info] Total Bins 12635
2024-06-23 10:07:39,278:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:07:39,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:40,301:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:40,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012193 seconds.
2024-06-23 10:07:40,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:40,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:40,326:INFO:[LightGBM] [Info] Total Bins 12380
2024-06-23 10:07:40,326:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:07:40,326:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:41,245:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:41,269:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013852 seconds.
2024-06-23 10:07:41,269:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:41,269:INFO:[LightGBM] [Info] Total Bins 12125
2024-06-23 10:07:41,269:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:07:41,269:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:42,242:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:42,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010571 seconds.
2024-06-23 10:07:42,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:42,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:42,268:INFO:[LightGBM] [Info] Total Bins 11972
2024-06-23 10:07:42,268:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:07:42,272:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:43,358:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:43,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012690 seconds.
2024-06-23 10:07:43,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:43,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:43,382:INFO:[LightGBM] [Info] Total Bins 11730
2024-06-23 10:07:43,383:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:07:43,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:44,237:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:44,264:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013704 seconds.
2024-06-23 10:07:44,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:44,264:INFO:[LightGBM] [Info] Total Bins 11475
2024-06-23 10:07:44,266:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:07:44,267:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:46,174:INFO:Initializing plot_model()
2024-06-23 10:07:46,174:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:07:46,174:INFO:Checking exceptions
2024-06-23 10:07:46,181:INFO:Preloading libraries
2024-06-23 10:07:46,192:INFO:Copying training dataset
2024-06-23 10:07:46,193:INFO:Plot type: rfe
2024-06-23 10:07:46,629:INFO:Fitting Model
2024-06-23 10:07:46,859:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:46,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015792 seconds.
2024-06-23 10:07:46,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:46,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:46,905:INFO:[LightGBM] [Info] Total Bins 14647
2024-06-23 10:07:46,908:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:07:46,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:48,050:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:48,080:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017251 seconds.
2024-06-23 10:07:48,080:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:48,080:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:07:48,084:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:07:48,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:49,435:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:49,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024083 seconds.
2024-06-23 10:07:49,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:49,492:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:07:49,497:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:07:49,499:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:50,725:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:50,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012430 seconds.
2024-06-23 10:07:50,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:50,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:50,755:INFO:[LightGBM] [Info] Total Bins 14383
2024-06-23 10:07:50,755:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:07:50,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:51,874:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:51,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015614 seconds.
2024-06-23 10:07:51,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:51,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:51,909:INFO:[LightGBM] [Info] Total Bins 14128
2024-06-23 10:07:51,911:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:07:51,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:52,934:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:52,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016780 seconds.
2024-06-23 10:07:52,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:52,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:52,966:INFO:[LightGBM] [Info] Total Bins 14085
2024-06-23 10:07:52,967:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:07:52,968:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:54,073:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:54,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015771 seconds.
2024-06-23 10:07:54,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:54,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:54,104:INFO:[LightGBM] [Info] Total Bins 14072
2024-06-23 10:07:54,105:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:07:54,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:55,238:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:55,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027964 seconds.
2024-06-23 10:07:55,281:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:55,281:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:07:55,281:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:07:55,281:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:56,477:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:56,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013119 seconds.
2024-06-23 10:07:56,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:56,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:56,507:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:07:56,508:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:07:56,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:57,463:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:57,492:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017170 seconds.
2024-06-23 10:07:57,492:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:57,492:INFO:[LightGBM] [Info] Total Bins 13783
2024-06-23 10:07:57,496:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:07:57,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:58,525:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:58,555:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015779 seconds.
2024-06-23 10:07:58,555:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:07:58,556:INFO:[LightGBM] [Info] Total Bins 13528
2024-06-23 10:07:58,558:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:07:58,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:07:59,623:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:07:59,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012381 seconds.
2024-06-23 10:07:59,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:07:59,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:07:59,652:INFO:[LightGBM] [Info] Total Bins 13422
2024-06-23 10:07:59,653:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:07:59,654:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:00,652:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:00,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017055 seconds.
2024-06-23 10:08:00,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:00,679:INFO:[LightGBM] [Info] Total Bins 13260
2024-06-23 10:08:00,679:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:08:00,679:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:01,735:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:01,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011220 seconds.
2024-06-23 10:08:01,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:01,759:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:01,759:INFO:[LightGBM] [Info] Total Bins 13005
2024-06-23 10:08:01,760:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:08:01,761:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:02,956:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:02,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014876 seconds.
2024-06-23 10:08:02,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:02,979:INFO:[LightGBM] [Info] Total Bins 12750
2024-06-23 10:08:02,979:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:08:02,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:03,913:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:03,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016222 seconds.
2024-06-23 10:08:03,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:03,941:INFO:[LightGBM] [Info] Total Bins 12495
2024-06-23 10:08:03,941:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:08:03,943:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:04,903:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:04,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015609 seconds.
2024-06-23 10:08:04,930:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:04,930:INFO:[LightGBM] [Info] Total Bins 12240
2024-06-23 10:08:04,930:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:08:04,930:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:05,885:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:05,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013314 seconds.
2024-06-23 10:08:05,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:05,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:05,916:INFO:[LightGBM] [Info] Total Bins 11985
2024-06-23 10:08:05,916:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:08:05,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:06,809:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:06,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013260 seconds.
2024-06-23 10:08:06,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:06,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:06,832:INFO:[LightGBM] [Info] Total Bins 11730
2024-06-23 10:08:06,832:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:08:06,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:07,731:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:07,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010783 seconds.
2024-06-23 10:08:07,757:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:07,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:07,757:INFO:[LightGBM] [Info] Total Bins 11475
2024-06-23 10:08:07,758:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:08:07,759:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:08,740:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:08,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016760 seconds.
2024-06-23 10:08:08,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:08,776:INFO:[LightGBM] [Info] Total Bins 11220
2024-06-23 10:08:08,777:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:08:08,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:09,731:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:09,753:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011041 seconds.
2024-06-23 10:08:09,754:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:09,754:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:09,754:INFO:[LightGBM] [Info] Total Bins 10965
2024-06-23 10:08:09,755:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:08:09,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:10,780:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:10,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013552 seconds.
2024-06-23 10:08:10,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:10,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:10,812:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:08:10,813:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:08:10,816:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:11,759:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:11,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011827 seconds.
2024-06-23 10:08:11,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:11,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:11,782:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:08:11,782:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:08:11,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:12,733:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:12,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016888 seconds.
2024-06-23 10:08:12,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:12,764:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:08:12,765:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:08:12,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:13,651:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:13,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009056 seconds.
2024-06-23 10:08:13,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:13,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:13,671:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:08:13,672:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:08:13,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:14,501:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:14,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014151 seconds.
2024-06-23 10:08:14,527:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:14,527:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:08:14,529:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:08:14,530:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:15,355:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:15,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008186 seconds.
2024-06-23 10:08:15,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:15,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:15,375:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:08:15,375:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:08:15,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:16,158:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:16,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015318 seconds.
2024-06-23 10:08:16,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:16,184:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:08:16,184:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:08:16,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:16,988:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:17,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010043 seconds.
2024-06-23 10:08:17,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:17,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:17,017:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:08:17,018:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:08:17,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:17,763:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:17,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009527 seconds.
2024-06-23 10:08:17,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:17,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:17,784:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:08:17,784:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:08:17,784:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:18,588:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:18,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009176 seconds.
2024-06-23 10:08:18,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:18,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:18,609:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:08:18,609:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:08:18,610:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:19,506:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:19,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008784 seconds.
2024-06-23 10:08:19,524:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:19,524:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:19,525:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:08:19,526:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:08:19,527:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:20,367:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:20,383:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008142 seconds.
2024-06-23 10:08:20,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:20,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:20,384:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:08:20,385:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:08:20,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:21,149:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:21,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012209 seconds.
2024-06-23 10:08:21,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:21,169:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:08:21,169:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:08:21,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:22,035:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:22,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011135 seconds.
2024-06-23 10:08:22,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:22,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:22,063:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:08:22,064:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:08:22,065:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:22,770:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:22,783:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006360 seconds.
2024-06-23 10:08:22,783:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:22,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:22,784:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:08:22,784:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:08:22,785:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:23,436:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:23,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007525 seconds.
2024-06-23 10:08:23,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:23,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:23,454:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:08:23,454:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:08:23,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:24,096:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:24,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008576 seconds.
2024-06-23 10:08:24,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:24,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:24,114:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:08:24,114:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:08:24,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:24,731:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:24,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011528 seconds.
2024-06-23 10:08:24,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:24,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:24,749:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:08:24,749:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:08:24,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:25,512:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:25,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008992 seconds.
2024-06-23 10:08:25,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:25,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:25,529:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:08:25,530:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:08:25,531:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:26,236:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:26,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008155 seconds.
2024-06-23 10:08:26,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:26,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:26,249:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:08:26,253:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:08:26,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:26,877:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:26,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005312 seconds.
2024-06-23 10:08:26,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:26,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:26,890:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:08:26,891:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:08:26,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:27,562:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:27,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005312 seconds.
2024-06-23 10:08:27,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:27,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:27,577:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:08:27,577:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:08:27,578:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:28,229:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:28,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006155 seconds.
2024-06-23 10:08:28,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:28,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:28,246:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:08:28,247:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:08:28,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:28,826:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:28,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004355 seconds.
2024-06-23 10:08:28,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:28,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:28,837:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:08:28,838:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:08:28,839:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:29,379:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:29,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006748 seconds.
2024-06-23 10:08:29,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:29,390:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:08:29,391:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:08:29,391:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:30,049:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:30,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010741 seconds.
2024-06-23 10:08:30,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:30,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:30,073:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:08:30,074:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:08:30,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:30,703:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:30,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011076 seconds.
2024-06-23 10:08:30,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:30,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:30,720:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:08:30,721:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:08:30,721:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:31,281:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:31,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008682 seconds.
2024-06-23 10:08:31,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:31,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:31,290:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:08:31,290:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:08:31,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:31,840:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:31,848:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004802 seconds.
2024-06-23 10:08:31,858:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:31,858:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:08:31,859:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:08:31,859:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:32,389:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:32,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003513 seconds.
2024-06-23 10:08:32,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:32,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:32,398:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:08:32,398:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:08:32,398:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:32,860:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:32,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.
2024-06-23 10:08:32,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:32,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:32,869:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:08:32,869:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:08:32,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:33,421:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:33,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004834 seconds.
2024-06-23 10:08:33,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:33,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:33,431:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:08:33,431:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:08:33,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:33,875:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:33,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002984 seconds.
2024-06-23 10:08:33,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:33,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:33,882:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:08:33,882:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:08:33,883:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:34,391:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:34,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.
2024-06-23 10:08:34,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:34,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:34,394:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:08:34,394:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:08:34,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:34,894:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:34,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.
2024-06-23 10:08:34,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:34,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:34,903:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:08:34,903:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:08:34,903:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:35,280:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:35,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.
2024-06-23 10:08:35,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:35,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:35,285:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:08:35,285:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:08:35,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:35,667:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:35,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003756 seconds.
2024-06-23 10:08:35,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:35,671:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:08:35,672:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:08:35,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:36,005:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:36,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001289 seconds.
2024-06-23 10:08:36,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:36,008:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:08:36,009:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:08:36,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:36,433:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:36,435:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.
2024-06-23 10:08:36,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:36,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:36,436:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:08:36,436:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:08:36,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:36,801:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:36,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-06-23 10:08:36,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:36,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:36,801:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:08:36,801:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:08:36,801:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:37,212:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:37,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-06-23 10:08:37,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:37,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:37,213:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:08:37,213:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:08:37,214:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:37,482:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:37,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.
2024-06-23 10:08:37,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:37,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:37,484:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:08:37,484:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:08:37,484:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:37,949:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:37,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014628 seconds.
2024-06-23 10:08:37,977:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:37,977:INFO:[LightGBM] [Info] Total Bins 14621
2024-06-23 10:08:37,978:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:08:37,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:39,087:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:39,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015851 seconds.
2024-06-23 10:08:39,125:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:39,125:INFO:[LightGBM] [Info] Total Bins 14366
2024-06-23 10:08:39,129:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:08:39,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:40,374:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:40,402:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014996 seconds.
2024-06-23 10:08:40,402:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:40,403:INFO:[LightGBM] [Info] Total Bins 14366
2024-06-23 10:08:40,404:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:08:40,405:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:41,739:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:41,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017943 seconds.
2024-06-23 10:08:41,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:41,782:INFO:[LightGBM] [Info] Total Bins 14111
2024-06-23 10:08:41,782:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:08:41,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:42,918:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:42,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013227 seconds.
2024-06-23 10:08:42,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:42,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:42,945:INFO:[LightGBM] [Info] Total Bins 14103
2024-06-23 10:08:42,945:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:08:42,947:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:43,972:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:44,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027289 seconds.
2024-06-23 10:08:44,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:44,024:INFO:[LightGBM] [Info] Total Bins 14103
2024-06-23 10:08:44,027:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:08:44,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:45,232:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:45,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019739 seconds.
2024-06-23 10:08:45,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:45,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:45,265:INFO:[LightGBM] [Info] Total Bins 14091
2024-06-23 10:08:45,266:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:08:45,267:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:46,324:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:46,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018016 seconds.
2024-06-23 10:08:46,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:46,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:46,357:INFO:[LightGBM] [Info] Total Bins 14059
2024-06-23 10:08:46,361:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:08:46,362:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:47,321:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:47,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014590 seconds.
2024-06-23 10:08:47,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:47,351:INFO:[LightGBM] [Info] Total Bins 13804
2024-06-23 10:08:47,352:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:08:47,353:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:48,474:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:48,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018710 seconds.
2024-06-23 10:08:48,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:48,510:INFO:[LightGBM] [Info] Total Bins 13704
2024-06-23 10:08:48,512:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:08:48,513:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:49,578:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:49,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014958 seconds.
2024-06-23 10:08:49,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:49,613:INFO:[LightGBM] [Info] Total Bins 13449
2024-06-23 10:08:49,613:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:08:49,614:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:50,620:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:50,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016693 seconds.
2024-06-23 10:08:50,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:50,649:INFO:[LightGBM] [Info] Total Bins 13194
2024-06-23 10:08:50,650:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:08:50,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:51,727:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:51,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020241 seconds.
2024-06-23 10:08:51,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:51,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:51,763:INFO:[LightGBM] [Info] Total Bins 13155
2024-06-23 10:08:51,764:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:08:51,765:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:52,798:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:52,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013764 seconds.
2024-06-23 10:08:52,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:52,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:52,835:INFO:[LightGBM] [Info] Total Bins 12900
2024-06-23 10:08:52,835:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:08:52,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:53,820:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:53,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011203 seconds.
2024-06-23 10:08:53,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:53,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:53,838:INFO:[LightGBM] [Info] Total Bins 12645
2024-06-23 10:08:53,838:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:08:53,846:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:54,764:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:54,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014110 seconds.
2024-06-23 10:08:54,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:54,795:INFO:[LightGBM] [Info] Total Bins 12390
2024-06-23 10:08:54,797:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:08:54,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:55,730:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:55,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010091 seconds.
2024-06-23 10:08:55,757:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:55,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:55,757:INFO:[LightGBM] [Info] Total Bins 12135
2024-06-23 10:08:55,758:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:08:55,759:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:56,653:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:56,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014890 seconds.
2024-06-23 10:08:56,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:56,678:INFO:[LightGBM] [Info] Total Bins 11880
2024-06-23 10:08:56,681:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:08:56,682:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:57,581:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:57,605:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012919 seconds.
2024-06-23 10:08:57,605:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:57,605:INFO:[LightGBM] [Info] Total Bins 11625
2024-06-23 10:08:57,606:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:08:57,606:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:58,526:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:58,552:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014148 seconds.
2024-06-23 10:08:58,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:08:58,552:INFO:[LightGBM] [Info] Total Bins 11370
2024-06-23 10:08:58,554:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:08:58,555:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:08:59,471:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:08:59,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009265 seconds.
2024-06-23 10:08:59,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:08:59,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:08:59,498:INFO:[LightGBM] [Info] Total Bins 11115
2024-06-23 10:08:59,499:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:08:59,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:00,473:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:00,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008978 seconds.
2024-06-23 10:09:00,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:00,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:00,497:INFO:[LightGBM] [Info] Total Bins 10960
2024-06-23 10:09:00,497:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:09:00,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:01,507:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:01,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011554 seconds.
2024-06-23 10:09:01,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:01,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:01,531:INFO:[LightGBM] [Info] Total Bins 10705
2024-06-23 10:09:01,534:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:09:01,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:02,347:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:02,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009959 seconds.
2024-06-23 10:09:02,368:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:02,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:02,369:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:09:02,370:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:09:02,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:03,183:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:03,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013505 seconds.
2024-06-23 10:09:03,209:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:03,210:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:09:03,211:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:09:03,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:04,056:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:04,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008484 seconds.
2024-06-23 10:09:04,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:04,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:04,076:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:09:04,077:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:09:04,078:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:04,872:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:04,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009692 seconds.
2024-06-23 10:09:04,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:04,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:04,895:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:09:04,895:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:09:04,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:05,762:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:05,784:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011881 seconds.
2024-06-23 10:09:05,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:05,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:05,784:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:09:05,784:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:09:05,784:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:06,556:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:06,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008460 seconds.
2024-06-23 10:09:06,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:06,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:06,577:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:09:06,577:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:09:06,578:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:07,342:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:07,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015288 seconds.
2024-06-23 10:09:07,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:07,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:07,379:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:09:07,380:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:09:07,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:08,180:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:08,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015381 seconds.
2024-06-23 10:09:08,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:08,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:08,221:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:09:08,223:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:09:08,224:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:09,024:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:09,040:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008998 seconds.
2024-06-23 10:09:09,040:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:09,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:09,040:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:09:09,040:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:09:09,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:09,834:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:09,855:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012349 seconds.
2024-06-23 10:09:09,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:09,855:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:09,855:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:09:09,856:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:09:09,856:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:10,644:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:10,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008410 seconds.
2024-06-23 10:09:10,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:10,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:10,666:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:09:10,666:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:09:10,667:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:11,363:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:11,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007720 seconds.
2024-06-23 10:09:11,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:11,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:11,378:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:09:11,379:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:09:11,380:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:12,048:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:12,064:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006986 seconds.
2024-06-23 10:09:12,064:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:12,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:12,065:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:09:12,065:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:09:12,066:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:12,754:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:12,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010651 seconds.
2024-06-23 10:09:12,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:12,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:12,777:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:09:12,777:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:09:12,778:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:13,473:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:13,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006929 seconds.
2024-06-23 10:09:13,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:13,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:13,489:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:09:13,489:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:09:13,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:14,178:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:14,193:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006842 seconds.
2024-06-23 10:09:14,193:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:14,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:14,195:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:09:14,195:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:09:14,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:14,989:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:15,006:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007161 seconds.
2024-06-23 10:09:15,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:15,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:15,006:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:09:15,007:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:09:15,007:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:15,741:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:15,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005573 seconds.
2024-06-23 10:09:15,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:15,758:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:15,759:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:09:15,759:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:09:15,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:16,349:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:16,365:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006708 seconds.
2024-06-23 10:09:16,365:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:16,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:16,366:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:09:16,366:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:09:16,367:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:16,939:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:16,949:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005455 seconds.
2024-06-23 10:09:16,949:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:16,949:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:16,949:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:09:16,949:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:09:16,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:17,613:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:17,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008211 seconds.
2024-06-23 10:09:17,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:17,625:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:09:17,626:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:09:17,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:18,234:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:18,244:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006951 seconds.
2024-06-23 10:09:18,244:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:18,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:18,244:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:09:18,244:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:09:18,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:18,794:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:18,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004541 seconds.
2024-06-23 10:09:18,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:18,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:18,810:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:09:18,810:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:09:18,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:19,422:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:19,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004239 seconds.
2024-06-23 10:09:19,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:19,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:19,431:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:09:19,432:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:09:19,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:19,957:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:19,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004220 seconds.
2024-06-23 10:09:19,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:19,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:19,968:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:09:19,968:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:09:19,969:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:20,459:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:20,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005312 seconds.
2024-06-23 10:09:20,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:20,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:20,470:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:09:20,471:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:09:20,472:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:20,951:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:20,960:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003629 seconds.
2024-06-23 10:09:20,960:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:20,960:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:20,960:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:09:20,961:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:09:20,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:21,492:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:21,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003674 seconds.
2024-06-23 10:09:21,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:21,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:21,506:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:09:21,506:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:09:21,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:21,979:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:21,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.
2024-06-23 10:09:21,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:21,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:21,987:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:09:21,988:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:09:21,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:22,446:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:22,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004781 seconds.
2024-06-23 10:09:22,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:22,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:22,457:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:09:22,458:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:09:22,458:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:22,876:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:22,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002815 seconds.
2024-06-23 10:09:22,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:22,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:22,883:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:09:22,883:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:09:22,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:23,276:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:23,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004331 seconds.
2024-06-23 10:09:23,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:23,283:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:09:23,283:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:09:23,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:23,699:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:23,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002315 seconds.
2024-06-23 10:09:23,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:23,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:23,708:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:09:23,708:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:09:23,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:24,099:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:24,112:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002362 seconds.
2024-06-23 10:09:24,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:24,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:24,112:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:09:24,113:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:09:24,113:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:24,526:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:24,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003519 seconds.
2024-06-23 10:09:24,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:24,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:24,535:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:09:24,535:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:09:24,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:24,908:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:24,914:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002171 seconds.
2024-06-23 10:09:24,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:24,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:24,914:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:09:24,914:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:09:24,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:25,237:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:25,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.
2024-06-23 10:09:25,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:25,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:25,240:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:09:25,240:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:09:25,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:25,555:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:25,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002421 seconds.
2024-06-23 10:09:25,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:25,559:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:09:25,560:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:09:25,560:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:25,834:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:25,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-06-23 10:09:25,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:25,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:25,836:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:09:25,837:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:09:25,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:26,127:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:26,128:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000573 seconds.
2024-06-23 10:09:26,128:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:26,129:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:09:26,129:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:09:26,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:26,393:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:26,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.
2024-06-23 10:09:26,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:26,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:26,393:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:09:26,393:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:09:26,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:26,823:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:26,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016220 seconds.
2024-06-23 10:09:26,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:26,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:26,853:INFO:[LightGBM] [Info] Total Bins 14600
2024-06-23 10:09:26,858:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:09:26,859:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:27,826:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:27,854:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018495 seconds.
2024-06-23 10:09:27,854:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:27,854:INFO:[LightGBM] [Info] Total Bins 14345
2024-06-23 10:09:27,854:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:09:27,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:28,906:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:28,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015655 seconds.
2024-06-23 10:09:28,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:28,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:28,931:INFO:[LightGBM] [Info] Total Bins 14345
2024-06-23 10:09:28,931:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:09:28,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:29,912:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:29,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021074 seconds.
2024-06-23 10:09:29,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:29,946:INFO:[LightGBM] [Info] Total Bins 14333
2024-06-23 10:09:29,947:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:09:29,949:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:30,960:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:30,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012152 seconds.
2024-06-23 10:09:30,979:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:30,979:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:30,979:INFO:[LightGBM] [Info] Total Bins 14304
2024-06-23 10:09:30,987:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:09:30,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:31,974:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:32,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016653 seconds.
2024-06-23 10:09:32,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:32,009:INFO:[LightGBM] [Info] Total Bins 14304
2024-06-23 10:09:32,011:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:09:32,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:33,027:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:33,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012075 seconds.
2024-06-23 10:09:33,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:33,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:33,056:INFO:[LightGBM] [Info] Total Bins 14049
2024-06-23 10:09:33,056:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:09:33,057:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:34,061:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:34,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019814 seconds.
2024-06-23 10:09:34,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:34,097:INFO:[LightGBM] [Info] Total Bins 14040
2024-06-23 10:09:34,098:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:09:34,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:35,100:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:35,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011268 seconds.
2024-06-23 10:09:35,124:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:35,124:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:35,124:INFO:[LightGBM] [Info] Total Bins 13785
2024-06-23 10:09:35,125:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:09:35,126:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:36,057:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:36,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018675 seconds.
2024-06-23 10:09:36,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:36,085:INFO:[LightGBM] [Info] Total Bins 13749
2024-06-23 10:09:36,085:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:09:36,085:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:37,113:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:37,134:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012745 seconds.
2024-06-23 10:09:37,134:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:37,134:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:37,142:INFO:[LightGBM] [Info] Total Bins 13494
2024-06-23 10:09:37,142:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:09:37,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:38,167:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:38,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018175 seconds.
2024-06-23 10:09:38,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:38,195:INFO:[LightGBM] [Info] Total Bins 13409
2024-06-23 10:09:38,196:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:09:38,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:39,290:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:39,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017154 seconds.
2024-06-23 10:09:39,320:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:39,321:INFO:[LightGBM] [Info] Total Bins 13154
2024-06-23 10:09:39,322:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:09:39,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:40,393:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:40,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021643 seconds.
2024-06-23 10:09:40,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:40,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:40,434:INFO:[LightGBM] [Info] Total Bins 12899
2024-06-23 10:09:40,434:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:09:40,434:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:41,387:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:41,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014394 seconds.
2024-06-23 10:09:41,415:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:41,415:INFO:[LightGBM] [Info] Total Bins 12644
2024-06-23 10:09:41,417:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:09:41,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:42,507:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:42,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013304 seconds.
2024-06-23 10:09:42,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:42,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:42,529:INFO:[LightGBM] [Info] Total Bins 12389
2024-06-23 10:09:42,529:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:09:42,529:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:43,423:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:43,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014766 seconds.
2024-06-23 10:09:43,451:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:43,451:INFO:[LightGBM] [Info] Total Bins 12134
2024-06-23 10:09:43,452:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:09:43,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:44,429:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:44,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012007 seconds.
2024-06-23 10:09:44,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:44,452:INFO:[LightGBM] [Info] Total Bins 11879
2024-06-23 10:09:44,453:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:09:44,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:45,373:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:45,401:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016155 seconds.
2024-06-23 10:09:45,401:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:45,401:INFO:[LightGBM] [Info] Total Bins 11624
2024-06-23 10:09:45,403:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:09:45,404:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:46,331:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:46,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010790 seconds.
2024-06-23 10:09:46,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:46,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:46,356:INFO:[LightGBM] [Info] Total Bins 11469
2024-06-23 10:09:46,356:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:09:46,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:47,221:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:47,241:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013363 seconds.
2024-06-23 10:09:47,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:47,241:INFO:[LightGBM] [Info] Total Bins 11214
2024-06-23 10:09:47,241:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:09:47,249:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:48,111:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:48,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013893 seconds.
2024-06-23 10:09:48,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:48,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:48,151:INFO:[LightGBM] [Info] Total Bins 10959
2024-06-23 10:09:48,152:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:09:48,153:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:49,061:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:49,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010729 seconds.
2024-06-23 10:09:49,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:49,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:49,085:INFO:[LightGBM] [Info] Total Bins 10704
2024-06-23 10:09:49,090:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:09:49,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:50,061:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:50,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013364 seconds.
2024-06-23 10:09:50,091:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:50,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:50,091:INFO:[LightGBM] [Info] Total Bins 10449
2024-06-23 10:09:50,091:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:09:50,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:51,014:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:51,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017659 seconds.
2024-06-23 10:09:51,050:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:51,051:INFO:[LightGBM] [Info] Total Bins 10194
2024-06-23 10:09:51,051:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:09:51,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:52,032:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:52,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008275 seconds.
2024-06-23 10:09:52,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:52,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:52,054:INFO:[LightGBM] [Info] Total Bins 9939
2024-06-23 10:09:52,055:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:09:52,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:52,911:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:52,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012554 seconds.
2024-06-23 10:09:52,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:52,933:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:09:52,935:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:09:52,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:53,760:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:53,781:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011044 seconds.
2024-06-23 10:09:53,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:53,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:53,782:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:09:53,784:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:09:53,784:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:54,660:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:54,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013048 seconds.
2024-06-23 10:09:54,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:54,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:54,694:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:09:54,695:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:09:54,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:55,565:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:55,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014022 seconds.
2024-06-23 10:09:55,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:55,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:55,595:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:09:55,595:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:09:55,599:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:56,563:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:56,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010331 seconds.
2024-06-23 10:09:56,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:56,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:56,583:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:09:56,588:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:09:56,589:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:57,432:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:57,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009493 seconds.
2024-06-23 10:09:57,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:57,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:57,450:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:09:57,451:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:09:57,452:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:58,365:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:58,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010363 seconds.
2024-06-23 10:09:58,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:09:58,385:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:09:58,386:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:09:58,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:09:59,223:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:09:59,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006628 seconds.
2024-06-23 10:09:59,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:09:59,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:09:59,240:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:09:59,240:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:09:59,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:00,011:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:00,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018778 seconds.
2024-06-23 10:10:00,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:00,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:00,047:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:10:00,047:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:10:00,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:00,956:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:00,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012267 seconds.
2024-06-23 10:10:00,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:00,978:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:10:00,979:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:10:00,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:01,981:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:02,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016008 seconds.
2024-06-23 10:10:02,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:02,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:02,018:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:10:02,022:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:10:02,023:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:02,873:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:02,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008113 seconds.
2024-06-23 10:10:02,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:02,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:02,888:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:10:02,888:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:10:02,888:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:03,799:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:03,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012606 seconds.
2024-06-23 10:10:03,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:03,826:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:10:03,827:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:10:03,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:04,758:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:04,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009182 seconds.
2024-06-23 10:10:04,781:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:04,781:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:04,781:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:10:04,782:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:10:04,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:05,798:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:05,815:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007866 seconds.
2024-06-23 10:10:05,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:05,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:05,816:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:10:05,817:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:10:05,817:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:06,539:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:06,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005259 seconds.
2024-06-23 10:10:06,556:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:06,556:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:06,556:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:10:06,557:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:10:06,557:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:07,150:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:07,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004908 seconds.
2024-06-23 10:10:07,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:07,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:07,162:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:10:07,163:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:10:07,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:07,828:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:07,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005584 seconds.
2024-06-23 10:10:07,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:07,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:07,841:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:10:07,841:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:10:07,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:08,396:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:08,408:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004470 seconds.
2024-06-23 10:10:08,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:08,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:08,409:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:10:08,409:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:10:08,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:08,960:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:08,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005762 seconds.
2024-06-23 10:10:08,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:08,971:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:10:08,971:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:10:08,972:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:09,538:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:09,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006109 seconds.
2024-06-23 10:10:09,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:09,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:09,550:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:10:09,550:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:10:09,550:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:10,081:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:10,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006850 seconds.
2024-06-23 10:10:10,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:10,089:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:10:10,089:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:10:10,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:10,625:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:10,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003278 seconds.
2024-06-23 10:10:10,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:10,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:10,636:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:10:10,636:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:10:10,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:11,206:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:11,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003452 seconds.
2024-06-23 10:10:11,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:11,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:11,216:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:10:11,216:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:10:11,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:11,720:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:11,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.
2024-06-23 10:10:11,730:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:11,730:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:11,731:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:10:11,731:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:10:11,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:12,386:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:12,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.
2024-06-23 10:10:12,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:12,394:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:10:12,394:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:10:12,398:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:13,007:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:13,013:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002793 seconds.
2024-06-23 10:10:13,013:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:13,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:13,014:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:10:13,014:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:10:13,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:13,429:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:13,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003862 seconds.
2024-06-23 10:10:13,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:13,436:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:10:13,436:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:10:13,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:13,956:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:13,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004074 seconds.
2024-06-23 10:10:13,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:13,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:13,965:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:10:13,965:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:10:13,965:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:14,470:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:14,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002386 seconds.
2024-06-23 10:10:14,477:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:14,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:14,478:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:10:14,478:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:10:14,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:14,914:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:14,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.
2024-06-23 10:10:14,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:14,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:14,919:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:10:14,920:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:10:14,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:15,317:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:15,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.
2024-06-23 10:10:15,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:15,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:15,321:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:10:15,322:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:10:15,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:15,698:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:15,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002427 seconds.
2024-06-23 10:10:15,702:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:15,706:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:10:15,706:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:10:15,706:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:16,108:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:16,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001754 seconds.
2024-06-23 10:10:16,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:16,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:16,113:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:10:16,114:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:10:16,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:16,445:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:16,445:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001159 seconds.
2024-06-23 10:10:16,449:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:16,449:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:10:16,449:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:10:16,449:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:16,758:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:16,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000823 seconds.
2024-06-23 10:10:16,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:16,759:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:10:16,759:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:10:16,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:17,066:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:17,068:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.
2024-06-23 10:10:17,068:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:17,068:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:10:17,068:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:10:17,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:17,370:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:17,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-06-23 10:10:17,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:17,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:17,372:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:10:17,372:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:10:17,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:17,857:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:17,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018293 seconds.
2024-06-23 10:10:17,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:17,887:INFO:[LightGBM] [Info] Total Bins 14596
2024-06-23 10:10:17,889:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:10:17,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:18,942:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:18,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018958 seconds.
2024-06-23 10:10:18,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:18,979:INFO:[LightGBM] [Info] Total Bins 14341
2024-06-23 10:10:18,979:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:10:18,979:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:19,983:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:20,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014216 seconds.
2024-06-23 10:10:20,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:20,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:20,015:INFO:[LightGBM] [Info] Total Bins 14341
2024-06-23 10:10:20,015:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:10:20,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:21,070:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:21,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017545 seconds.
2024-06-23 10:10:21,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:21,102:INFO:[LightGBM] [Info] Total Bins 14086
2024-06-23 10:10:21,104:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:10:21,105:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:22,186:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:22,218:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018467 seconds.
2024-06-23 10:10:22,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:22,219:INFO:[LightGBM] [Info] Total Bins 14086
2024-06-23 10:10:22,220:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:10:22,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:23,267:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:23,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019828 seconds.
2024-06-23 10:10:23,306:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:23,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:23,307:INFO:[LightGBM] [Info] Total Bins 14074
2024-06-23 10:10:23,309:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:10:23,310:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:24,434:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:24,469:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015850 seconds.
2024-06-23 10:10:24,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:24,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:24,470:INFO:[LightGBM] [Info] Total Bins 14044
2024-06-23 10:10:24,470:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:10:24,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:25,562:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:25,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020567 seconds.
2024-06-23 10:10:25,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:25,595:INFO:[LightGBM] [Info] Total Bins 14035
2024-06-23 10:10:25,597:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:10:25,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:26,831:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:26,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013805 seconds.
2024-06-23 10:10:26,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:26,858:INFO:[LightGBM] [Info] Total Bins 13780
2024-06-23 10:10:26,858:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:10:26,860:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:28,146:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:28,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026824 seconds.
2024-06-23 10:10:28,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:28,186:INFO:[LightGBM] [Info] Total Bins 13740
2024-06-23 10:10:28,186:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:10:28,190:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:29,326:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:29,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040926 seconds.
2024-06-23 10:10:29,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:29,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:29,389:INFO:[LightGBM] [Info] Total Bins 13655
2024-06-23 10:10:29,393:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:10:29,396:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:31,128:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:31,184:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027079 seconds.
2024-06-23 10:10:31,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:31,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:31,184:INFO:[LightGBM] [Info] Total Bins 13400
2024-06-23 10:10:31,184:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:10:31,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:32,321:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:32,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013181 seconds.
2024-06-23 10:10:32,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:32,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:32,348:INFO:[LightGBM] [Info] Total Bins 13145
2024-06-23 10:10:32,349:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:10:32,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:33,383:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:33,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028909 seconds.
2024-06-23 10:10:33,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:33,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:33,437:INFO:[LightGBM] [Info] Total Bins 12890
2024-06-23 10:10:33,439:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:10:33,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:34,790:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:34,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017188 seconds.
2024-06-23 10:10:34,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:34,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:34,826:INFO:[LightGBM] [Info] Total Bins 12635
2024-06-23 10:10:34,827:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:10:34,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:36,469:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:36,506:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019345 seconds.
2024-06-23 10:10:36,507:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:36,507:INFO:[LightGBM] [Info] Total Bins 12380
2024-06-23 10:10:36,509:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:10:36,510:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:39,250:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:39,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030527 seconds.
2024-06-23 10:10:39,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:39,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:39,315:INFO:[LightGBM] [Info] Total Bins 12125
2024-06-23 10:10:39,317:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:10:39,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:40,691:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:40,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034232 seconds.
2024-06-23 10:10:40,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:40,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:40,764:INFO:[LightGBM] [Info] Total Bins 11972
2024-06-23 10:10:40,766:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:10:40,768:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:42,428:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:42,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013020 seconds.
2024-06-23 10:10:42,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:42,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:42,454:INFO:[LightGBM] [Info] Total Bins 11730
2024-06-23 10:10:42,454:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:10:42,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:43,475:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:43,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015886 seconds.
2024-06-23 10:10:43,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:43,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:43,504:INFO:[LightGBM] [Info] Total Bins 11475
2024-06-23 10:10:43,505:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:10:43,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:44,485:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:44,508:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013641 seconds.
2024-06-23 10:10:44,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:44,509:INFO:[LightGBM] [Info] Total Bins 11220
2024-06-23 10:10:44,511:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:10:44,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:45,465:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:45,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014403 seconds.
2024-06-23 10:10:45,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:45,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:45,497:INFO:[LightGBM] [Info] Total Bins 10965
2024-06-23 10:10:45,497:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:10:45,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:46,323:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:46,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009298 seconds.
2024-06-23 10:10:46,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:46,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:46,356:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:10:46,356:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:10:46,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:47,371:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:47,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011209 seconds.
2024-06-23 10:10:47,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:47,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:47,398:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:10:47,399:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:10:47,400:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:48,223:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:48,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009372 seconds.
2024-06-23 10:10:48,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:48,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:48,243:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:10:48,243:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:10:48,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:49,074:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:49,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012136 seconds.
2024-06-23 10:10:49,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:49,094:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:10:49,094:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:10:49,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:49,895:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:49,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008954 seconds.
2024-06-23 10:10:49,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:49,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:49,914:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:10:49,915:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:10:49,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:50,673:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:50,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012256 seconds.
2024-06-23 10:10:50,696:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:50,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:50,697:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:10:50,698:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:10:50,699:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:51,491:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:51,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009773 seconds.
2024-06-23 10:10:51,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:51,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:51,512:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:10:51,513:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:10:51,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:52,274:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:52,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007685 seconds.
2024-06-23 10:10:52,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:52,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:52,294:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:10:52,294:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:10:52,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:53,064:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:53,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012671 seconds.
2024-06-23 10:10:53,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:53,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:53,093:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:10:53,094:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:10:53,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:53,946:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:53,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007526 seconds.
2024-06-23 10:10:53,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:53,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:53,963:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:10:53,963:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:10:53,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:54,717:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:54,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010563 seconds.
2024-06-23 10:10:54,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:10:54,739:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:10:54,739:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:10:54,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:55,475:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:55,491:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007303 seconds.
2024-06-23 10:10:55,492:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:55,492:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:55,492:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:10:55,492:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:10:55,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:56,237:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:56,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012124 seconds.
2024-06-23 10:10:56,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:56,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:56,262:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:10:56,262:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:10:56,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:57,000:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:57,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007746 seconds.
2024-06-23 10:10:57,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:57,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:57,016:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:10:57,017:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:10:57,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:57,749:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:57,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006409 seconds.
2024-06-23 10:10:57,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:57,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:57,763:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:10:57,764:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:10:57,765:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:58,470:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:58,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013213 seconds.
2024-06-23 10:10:58,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:58,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:58,494:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:10:58,495:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:10:58,496:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:59,283:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:59,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008316 seconds.
2024-06-23 10:10:59,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:59,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:59,300:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:10:59,300:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:10:59,301:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:10:59,961:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:10:59,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006629 seconds.
2024-06-23 10:10:59,977:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:10:59,977:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:10:59,977:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:10:59,978:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:10:59,978:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:00,633:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:00,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009822 seconds.
2024-06-23 10:11:00,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:00,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:00,651:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:11:00,652:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:11:00,653:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:01,363:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:01,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008311 seconds.
2024-06-23 10:11:01,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:01,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:01,385:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:11:01,385:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:11:01,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:02,069:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:02,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008311 seconds.
2024-06-23 10:11:02,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:02,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:02,088:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:11:02,089:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:11:02,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:02,709:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:02,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007766 seconds.
2024-06-23 10:11:02,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:02,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:02,728:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:11:02,729:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:11:02,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:03,282:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:03,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004960 seconds.
2024-06-23 10:11:03,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:03,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:03,293:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:11:03,293:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:11:03,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:03,823:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:03,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004880 seconds.
2024-06-23 10:11:03,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:03,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:03,834:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:11:03,835:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:11:03,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:04,351:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:04,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004250 seconds.
2024-06-23 10:11:04,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:04,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:04,361:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:11:04,361:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:11:04,362:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:04,885:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:04,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004004 seconds.
2024-06-23 10:11:04,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:04,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:04,897:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:11:04,898:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:11:04,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:05,437:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:05,448:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007107 seconds.
2024-06-23 10:11:05,449:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:05,449:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:11:05,449:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:11:05,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:06,006:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:06,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003843 seconds.
2024-06-23 10:11:06,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:06,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:06,016:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:11:06,017:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:11:06,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:06,471:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:06,480:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004771 seconds.
2024-06-23 10:11:06,480:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:06,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:06,480:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:11:06,481:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:11:06,481:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:06,990:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:06,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004475 seconds.
2024-06-23 10:11:06,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:06,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:07,000:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:11:07,000:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:11:07,000:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:07,469:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:07,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002958 seconds.
2024-06-23 10:11:07,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:07,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:07,476:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:11:07,476:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:11:07,477:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:07,966:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:07,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002924 seconds.
2024-06-23 10:11:07,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:07,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:07,974:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:11:07,974:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:11:07,975:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:08,419:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:08,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.
2024-06-23 10:11:08,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:08,428:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:11:08,428:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:11:08,429:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:08,898:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:08,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002247 seconds.
2024-06-23 10:11:08,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:08,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:08,903:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:11:08,904:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:11:08,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:09,281:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:09,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.
2024-06-23 10:11:09,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:09,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:09,287:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:11:09,288:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:11:09,288:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:09,659:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:09,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001785 seconds.
2024-06-23 10:11:09,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:09,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:09,664:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:11:09,664:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:11:09,665:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:10,021:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:10,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002373 seconds.
2024-06-23 10:11:10,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:10,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:10,031:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:11:10,032:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:11:10,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:10,502:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:10,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.
2024-06-23 10:11:10,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:10,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:10,506:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:11:10,507:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:11:10,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:10,895:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:10,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.
2024-06-23 10:11:10,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:10,897:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:11:10,897:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:11:10,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:11,170:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:11,171:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000738 seconds.
2024-06-23 10:11:11,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:11,172:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:11:11,172:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:11:11,172:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:11,456:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:11,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-06-23 10:11:11,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:11,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:11,458:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:11:11,458:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:11:11,458:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:11,745:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:11:11,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000916 seconds.
2024-06-23 10:11:11,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:11,746:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:11:11,747:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 1
2024-06-23 10:11:11,747:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:11:12,334:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:12,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016941 seconds.
2024-06-23 10:11:12,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:12,367:INFO:[LightGBM] [Info] Total Bins 14616
2024-06-23 10:11:12,369:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:11:12,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:12,371:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:13,422:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:13,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013869 seconds.
2024-06-23 10:11:13,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:13,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:13,451:INFO:[LightGBM] [Info] Total Bins 14361
2024-06-23 10:11:13,452:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:11:13,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:13,453:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:14,503:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:14,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019058 seconds.
2024-06-23 10:11:14,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:14,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:14,538:INFO:[LightGBM] [Info] Total Bins 14331
2024-06-23 10:11:14,545:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:11:14,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:14,547:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:15,653:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:15,677:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014961 seconds.
2024-06-23 10:11:15,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:15,677:INFO:[LightGBM] [Info] Total Bins 14076
2024-06-23 10:11:15,677:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:11:15,677:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:15,681:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:16,774:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:16,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017223 seconds.
2024-06-23 10:11:16,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:16,811:INFO:[LightGBM] [Info] Total Bins 14076
2024-06-23 10:11:16,812:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:11:16,813:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:16,814:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:17,911:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:17,936:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011740 seconds.
2024-06-23 10:11:17,936:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:17,936:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:17,936:INFO:[LightGBM] [Info] Total Bins 14076
2024-06-23 10:11:17,936:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:11:17,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:17,940:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:18,876:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:18,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015550 seconds.
2024-06-23 10:11:18,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:18,904:INFO:[LightGBM] [Info] Total Bins 14064
2024-06-23 10:11:18,906:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:11:18,907:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:18,907:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:19,899:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:19,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011767 seconds.
2024-06-23 10:11:19,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:19,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:19,924:INFO:[LightGBM] [Info] Total Bins 13809
2024-06-23 10:11:19,925:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:11:19,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:19,926:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:20,937:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:20,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019385 seconds.
2024-06-23 10:11:20,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:20,979:INFO:[LightGBM] [Info] Total Bins 13770
2024-06-23 10:11:20,981:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:11:20,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:20,981:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:22,099:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:22,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013987 seconds.
2024-06-23 10:11:22,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:22,131:INFO:[LightGBM] [Info] Total Bins 13669
2024-06-23 10:11:22,131:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:11:22,133:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:22,133:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:23,322:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:23,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022577 seconds.
2024-06-23 10:11:23,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:23,367:INFO:[LightGBM] [Info] Total Bins 13661
2024-06-23 10:11:23,369:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:11:23,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:23,370:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:24,390:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:24,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016115 seconds.
2024-06-23 10:11:24,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:24,421:INFO:[LightGBM] [Info] Total Bins 13406
2024-06-23 10:11:24,421:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:11:24,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:24,423:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:25,418:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:25,449:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019476 seconds.
2024-06-23 10:11:25,449:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:25,450:INFO:[LightGBM] [Info] Total Bins 13151
2024-06-23 10:11:25,452:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:11:25,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:25,453:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:26,475:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:26,498:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012048 seconds.
2024-06-23 10:11:26,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:26,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:26,499:INFO:[LightGBM] [Info] Total Bins 12995
2024-06-23 10:11:26,500:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:11:26,501:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:26,501:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:27,478:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:27,507:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014697 seconds.
2024-06-23 10:11:27,508:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:27,508:INFO:[LightGBM] [Info] Total Bins 12740
2024-06-23 10:11:27,510:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:11:27,511:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:27,511:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:28,482:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:28,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010975 seconds.
2024-06-23 10:11:28,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:28,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:28,506:INFO:[LightGBM] [Info] Total Bins 12485
2024-06-23 10:11:28,507:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:11:28,508:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:28,508:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:29,391:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:29,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015168 seconds.
2024-06-23 10:11:29,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:29,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:29,422:INFO:[LightGBM] [Info] Total Bins 12230
2024-06-23 10:11:29,423:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:11:29,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:29,425:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:30,346:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:30,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011570 seconds.
2024-06-23 10:11:30,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:30,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:30,369:INFO:[LightGBM] [Info] Total Bins 11975
2024-06-23 10:11:30,370:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:11:30,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:30,371:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:31,256:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:31,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013947 seconds.
2024-06-23 10:11:31,281:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:31,282:INFO:[LightGBM] [Info] Total Bins 11720
2024-06-23 10:11:31,282:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:11:31,282:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:31,282:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:32,233:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:32,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009697 seconds.
2024-06-23 10:11:32,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:32,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:32,260:INFO:[LightGBM] [Info] Total Bins 11465
2024-06-23 10:11:32,261:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:11:32,262:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:32,262:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:33,113:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:33,133:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011427 seconds.
2024-06-23 10:11:33,133:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:33,133:INFO:[LightGBM] [Info] Total Bins 11210
2024-06-23 10:11:33,133:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:11:33,133:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:33,133:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:34,192:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:34,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015340 seconds.
2024-06-23 10:11:34,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:34,218:INFO:[LightGBM] [Info] Total Bins 10955
2024-06-23 10:11:34,219:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:11:34,220:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:34,221:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:35,153:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:35,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010844 seconds.
2024-06-23 10:11:35,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:35,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:35,176:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:11:35,176:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:11:35,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:35,177:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:36,075:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:36,105:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016676 seconds.
2024-06-23 10:11:36,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:36,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:36,106:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:11:36,107:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:11:36,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:36,108:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:36,933:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:36,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011224 seconds.
2024-06-23 10:11:36,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:36,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:36,956:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:11:36,957:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:11:36,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:36,958:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:37,927:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:37,957:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012955 seconds.
2024-06-23 10:11:37,957:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:37,958:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:11:37,958:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:11:37,959:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:37,959:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:38,867:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:38,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028122 seconds.
2024-06-23 10:11:38,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:38,916:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:11:38,917:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:11:38,919:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:38,919:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:39,785:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:39,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010930 seconds.
2024-06-23 10:11:39,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:39,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:39,806:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:11:39,807:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:11:39,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:39,808:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:40,579:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:40,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012836 seconds.
2024-06-23 10:11:40,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:40,603:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:11:40,604:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:11:40,605:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:40,606:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:41,595:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:41,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015478 seconds.
2024-06-23 10:11:41,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:41,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:41,625:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:11:41,627:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:11:41,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:41,628:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:42,432:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:42,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012023 seconds.
2024-06-23 10:11:42,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:42,453:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:11:42,454:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:11:42,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:42,455:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:43,437:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:43,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008898 seconds.
2024-06-23 10:11:43,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:43,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:43,458:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:11:43,458:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:11:43,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:43,459:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:44,409:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:44,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009582 seconds.
2024-06-23 10:11:44,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:44,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:44,429:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:11:44,430:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:11:44,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:44,432:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:45,158:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:45,174:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006492 seconds.
2024-06-23 10:11:45,174:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:45,174:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:45,174:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:11:45,175:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:11:45,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:45,176:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:45,848:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:45,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007081 seconds.
2024-06-23 10:11:45,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:45,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:45,863:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:11:45,864:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:11:45,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:45,865:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:46,539:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:46,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006734 seconds.
2024-06-23 10:11:46,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:46,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:46,560:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:11:46,560:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:11:46,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:46,561:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:47,238:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:47,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007748 seconds.
2024-06-23 10:11:47,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:47,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:47,250:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:11:47,250:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:11:47,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:47,250:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:47,912:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:47,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006033 seconds.
2024-06-23 10:11:47,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:47,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:47,926:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:11:47,927:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:11:47,927:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:47,928:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:48,557:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:48,570:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006347 seconds.
2024-06-23 10:11:48,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:48,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:48,570:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:11:48,571:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:11:48,572:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:48,572:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:49,197:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:49,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005303 seconds.
2024-06-23 10:11:49,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:49,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:49,212:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:11:49,212:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:11:49,213:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:49,213:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:49,937:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:49,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007473 seconds.
2024-06-23 10:11:49,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:49,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:49,945:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:11:49,945:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:11:49,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:49,953:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:50,574:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:50,584:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005032 seconds.
2024-06-23 10:11:50,584:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:50,584:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:50,584:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:11:50,586:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:11:50,586:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:50,586:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:51,218:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:51,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008473 seconds.
2024-06-23 10:11:51,234:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:51,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:51,234:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:11:51,234:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:11:51,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:51,235:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:51,915:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:51,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004948 seconds.
2024-06-23 10:11:51,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:51,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:51,928:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:11:51,928:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:11:51,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:51,929:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:52,485:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:52,498:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005813 seconds.
2024-06-23 10:11:52,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:52,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:52,498:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:11:52,498:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:11:52,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:52,498:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:53,097:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:53,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006439 seconds.
2024-06-23 10:11:53,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:53,110:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:11:53,110:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:11:53,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:53,111:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:53,698:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:53,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004876 seconds.
2024-06-23 10:11:53,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:53,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:53,716:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:11:53,717:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:11:53,717:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:53,717:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:54,216:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:54,226:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003759 seconds.
2024-06-23 10:11:54,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:54,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:54,227:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:11:54,227:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:11:54,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:54,228:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:54,716:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:54,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003757 seconds.
2024-06-23 10:11:54,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:54,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:54,725:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:11:54,725:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:11:54,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:54,726:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:55,219:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:55,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005124 seconds.
2024-06-23 10:11:55,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:55,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:55,230:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:11:55,230:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:11:55,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:55,231:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:55,757:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:55,764:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.
2024-06-23 10:11:55,764:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:55,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:55,765:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:11:55,765:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:11:55,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:55,766:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:56,217:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:56,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002722 seconds.
2024-06-23 10:11:56,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:56,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:56,224:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:11:56,224:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:11:56,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:56,225:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:56,796:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:56,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.
2024-06-23 10:11:56,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:56,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:56,804:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:11:56,804:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:11:56,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:56,804:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:57,247:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:57,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002211 seconds.
2024-06-23 10:11:57,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:57,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:57,254:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:11:57,254:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:11:57,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:57,255:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:57,699:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:57,704:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.
2024-06-23 10:11:57,705:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:57,705:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:57,705:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:11:57,705:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:11:57,706:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:57,706:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:58,151:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:58,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003067 seconds.
2024-06-23 10:11:58,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:58,157:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:11:58,157:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:11:58,158:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:58,159:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:58,533:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:58,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.
2024-06-23 10:11:58,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:58,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:58,533:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:11:58,533:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:11:58,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:58,533:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:58,993:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:58,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.
2024-06-23 10:11:58,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:58,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:58,998:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:11:58,999:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:11:58,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:58,999:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:59,327:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:59,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001074 seconds.
2024-06-23 10:11:59,334:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:11:59,334:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:11:59,334:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:11:59,334:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:11:59,334:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:59,334:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:11:59,652:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:11:59,654:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002315 seconds.
2024-06-23 10:11:59,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:11:59,655:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:11:59,655:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:11:59,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:11:59,656:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:00,115:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:00,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.
2024-06-23 10:12:00,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:00,118:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:12:00,118:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:12:00,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:00,119:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:00,478:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:00,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.
2024-06-23 10:12:00,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:00,480:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:12:00,480:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:12:00,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:00,480:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:00,763:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:00,764:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-06-23 10:12:00,764:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:00,764:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:00,765:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:12:00,765:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:12:00,765:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:00,765:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:01,072:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:01,073:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.
2024-06-23 10:12:01,073:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:01,073:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:12:01,073:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 1
2024-06-23 10:12:01,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:01,074:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:01,552:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:01,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014737 seconds.
2024-06-23 10:12:01,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:01,579:INFO:[LightGBM] [Info] Total Bins 14606
2024-06-23 10:12:01,580:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:12:01,582:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:01,582:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:02,621:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:02,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016236 seconds.
2024-06-23 10:12:02,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:02,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:02,652:INFO:[LightGBM] [Info] Total Bins 14351
2024-06-23 10:12:02,653:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:12:02,654:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:02,654:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:03,727:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:03,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016935 seconds.
2024-06-23 10:12:03,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:03,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:03,764:INFO:[LightGBM] [Info] Total Bins 14351
2024-06-23 10:12:03,765:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:12:03,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:03,767:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:04,745:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:04,773:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011228 seconds.
2024-06-23 10:12:04,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:04,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:04,774:INFO:[LightGBM] [Info] Total Bins 14339
2024-06-23 10:12:04,775:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:12:04,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:04,776:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:05,804:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:05,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013479 seconds.
2024-06-23 10:12:05,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:05,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:05,832:INFO:[LightGBM] [Info] Total Bins 14310
2024-06-23 10:12:05,834:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:12:05,834:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:05,834:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:06,940:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:06,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015382 seconds.
2024-06-23 10:12:06,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:06,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:06,973:INFO:[LightGBM] [Info] Total Bins 14310
2024-06-23 10:12:06,974:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:12:06,975:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:06,976:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:08,104:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:08,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021397 seconds.
2024-06-23 10:12:08,132:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:08,132:INFO:[LightGBM] [Info] Total Bins 14055
2024-06-23 10:12:08,132:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:12:08,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:08,132:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:09,139:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:09,170:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018641 seconds.
2024-06-23 10:12:09,170:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:09,171:INFO:[LightGBM] [Info] Total Bins 13800
2024-06-23 10:12:09,172:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:12:09,174:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:09,174:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:10,255:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:10,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015269 seconds.
2024-06-23 10:12:10,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:10,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:10,281:INFO:[LightGBM] [Info] Total Bins 13764
2024-06-23 10:12:10,281:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:12:10,281:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:10,281:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:11,248:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:11,269:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010397 seconds.
2024-06-23 10:12:11,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:11,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:11,269:INFO:[LightGBM] [Info] Total Bins 13661
2024-06-23 10:12:11,269:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:12:11,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:11,278:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:12,266:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:12,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016019 seconds.
2024-06-23 10:12:12,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:12,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:12,297:INFO:[LightGBM] [Info] Total Bins 13406
2024-06-23 10:12:12,297:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:12:12,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:12,298:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:13,226:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:13,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016132 seconds.
2024-06-23 10:12:13,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:13,256:INFO:[LightGBM] [Info] Total Bins 13398
2024-06-23 10:12:13,257:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:12:13,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:13,259:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:14,207:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:14,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017017 seconds.
2024-06-23 10:12:14,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:14,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:14,240:INFO:[LightGBM] [Info] Total Bins 13143
2024-06-23 10:12:14,240:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:12:14,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:14,240:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:15,167:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:15,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010169 seconds.
2024-06-23 10:12:15,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:15,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:15,187:INFO:[LightGBM] [Info] Total Bins 12888
2024-06-23 10:12:15,187:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:12:15,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:15,195:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:16,176:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:16,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011363 seconds.
2024-06-23 10:12:16,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:16,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:16,200:INFO:[LightGBM] [Info] Total Bins 12633
2024-06-23 10:12:16,200:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:12:16,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:16,201:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:17,065:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:17,090:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016918 seconds.
2024-06-23 10:12:17,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:17,090:INFO:[LightGBM] [Info] Total Bins 12378
2024-06-23 10:12:17,090:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:12:17,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:17,090:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:18,082:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:18,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016415 seconds.
2024-06-23 10:12:18,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:18,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:18,112:INFO:[LightGBM] [Info] Total Bins 12231
2024-06-23 10:12:18,113:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:12:18,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:18,114:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:19,181:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:19,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012303 seconds.
2024-06-23 10:12:19,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:19,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:19,206:INFO:[LightGBM] [Info] Total Bins 11976
2024-06-23 10:12:19,206:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:12:19,207:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:19,207:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:20,051:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:20,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014236 seconds.
2024-06-23 10:12:20,076:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:20,076:INFO:[LightGBM] [Info] Total Bins 11721
2024-06-23 10:12:20,078:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:12:20,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:20,079:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:20,966:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:20,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014046 seconds.
2024-06-23 10:12:20,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:20,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:20,993:INFO:[LightGBM] [Info] Total Bins 11466
2024-06-23 10:12:20,993:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:12:21,000:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:21,000:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:21,898:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:21,922:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011513 seconds.
2024-06-23 10:12:21,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:21,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:21,923:INFO:[LightGBM] [Info] Total Bins 11211
2024-06-23 10:12:21,924:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:12:21,925:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:21,925:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:22,883:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:22,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010322 seconds.
2024-06-23 10:12:22,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:22,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:22,909:INFO:[LightGBM] [Info] Total Bins 10956
2024-06-23 10:12:22,909:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:12:22,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:22,910:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:23,732:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:23,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023579 seconds.
2024-06-23 10:12:23,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:23,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:23,772:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:12:23,774:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:12:23,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:23,776:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:24,792:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:24,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016000 seconds.
2024-06-23 10:12:24,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:24,817:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:12:24,817:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:12:24,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:24,821:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:25,702:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:25,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009224 seconds.
2024-06-23 10:12:25,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:25,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:25,722:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:12:25,722:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:12:25,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:25,724:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:26,520:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:26,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010721 seconds.
2024-06-23 10:12:26,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:26,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:26,544:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:12:26,544:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:12:26,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:26,547:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:27,339:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:27,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009025 seconds.
2024-06-23 10:12:27,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:27,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:27,359:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:12:27,360:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:12:27,361:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:27,361:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:28,328:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:28,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011421 seconds.
2024-06-23 10:12:28,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:28,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:28,357:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:12:28,358:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:12:28,358:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:28,359:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:29,158:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:29,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008355 seconds.
2024-06-23 10:12:29,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:29,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:29,176:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:12:29,176:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:12:29,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:29,177:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:30,060:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:30,082:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010700 seconds.
2024-06-23 10:12:30,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:30,082:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:30,082:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:12:30,083:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:12:30,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:30,085:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:30,838:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:30,855:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007307 seconds.
2024-06-23 10:12:30,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:30,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:30,856:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:12:30,856:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:12:30,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:30,857:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:31,636:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:31,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008965 seconds.
2024-06-23 10:12:31,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:31,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:31,654:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:12:31,655:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:12:31,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:31,656:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:32,390:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:32,414:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.
2024-06-23 10:12:32,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:32,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:32,415:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:12:32,415:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:12:32,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:32,417:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:33,087:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:33,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008583 seconds.
2024-06-23 10:12:33,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:33,104:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:12:33,105:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:12:33,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:33,106:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:33,813:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:33,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008738 seconds.
2024-06-23 10:12:33,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:33,830:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:12:33,831:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:12:33,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:33,832:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:34,562:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:34,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006341 seconds.
2024-06-23 10:12:34,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:34,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:34,579:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:12:34,579:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:12:34,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:34,580:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:35,262:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:35,277:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006281 seconds.
2024-06-23 10:12:35,277:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:35,277:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:35,277:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:12:35,278:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:12:35,279:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:35,279:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:35,938:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:35,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006796 seconds.
2024-06-23 10:12:35,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:35,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:35,952:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:12:35,952:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:12:35,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:35,955:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:36,588:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:36,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005659 seconds.
2024-06-23 10:12:36,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:36,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:36,596:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:12:36,596:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:12:36,605:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:36,605:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:37,236:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:37,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008396 seconds.
2024-06-23 10:12:37,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:37,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:37,246:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:12:37,246:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:12:37,246:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:37,246:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:37,868:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:37,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005545 seconds.
2024-06-23 10:12:37,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:37,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:37,884:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:12:37,884:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:12:37,885:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:37,885:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:38,476:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:38,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007169 seconds.
2024-06-23 10:12:38,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:38,488:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:12:38,488:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:12:38,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:38,492:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:39,113:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:39,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005197 seconds.
2024-06-23 10:12:39,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:39,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:39,124:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:12:39,124:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:12:39,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:39,125:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:39,719:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:39,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006011 seconds.
2024-06-23 10:12:39,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:39,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:39,732:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:12:39,733:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:12:39,733:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:39,733:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:40,286:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:40,291:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005767 seconds.
2024-06-23 10:12:40,291:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:40,291:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:40,299:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:12:40,299:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:12:40,299:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:40,299:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:40,838:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:40,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006955 seconds.
2024-06-23 10:12:40,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:40,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:40,850:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:12:40,850:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:12:40,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:40,850:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:41,374:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:41,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003885 seconds.
2024-06-23 10:12:41,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:41,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:41,385:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:12:41,385:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:12:41,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:41,386:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:41,888:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:41,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008753 seconds.
2024-06-23 10:12:41,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:41,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:41,899:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:12:41,899:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:12:41,907:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:41,907:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:42,466:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:42,480:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005080 seconds.
2024-06-23 10:12:42,480:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:42,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:42,480:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:12:42,481:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:12:42,481:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:42,481:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:43,016:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:43,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003842 seconds.
2024-06-23 10:12:43,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:43,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:43,025:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:12:43,026:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:12:43,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:43,026:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:43,492:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:43,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005448 seconds.
2024-06-23 10:12:43,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:43,494:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:12:43,502:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:12:43,502:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:43,502:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:44,020:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:44,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005273 seconds.
2024-06-23 10:12:44,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:44,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:44,030:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:12:44,030:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:12:44,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:44,031:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:44,487:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:44,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004648 seconds.
2024-06-23 10:12:44,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:44,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:44,496:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:12:44,496:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:12:44,496:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:44,499:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:44,892:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:44,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002734 seconds.
2024-06-23 10:12:44,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:44,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:44,901:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:12:44,901:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:12:44,901:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:44,907:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:45,333:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:45,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.
2024-06-23 10:12:45,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:45,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:45,339:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:12:45,340:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:12:45,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:45,341:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:45,768:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:45,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004727 seconds.
2024-06-23 10:12:45,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:45,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:45,777:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:12:45,777:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:12:45,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:45,779:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:46,189:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:46,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003132 seconds.
2024-06-23 10:12:46,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:46,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:46,195:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:12:46,197:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:12:46,197:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:46,197:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:46,623:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:46,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003926 seconds.
2024-06-23 10:12:46,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:46,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:46,626:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:12:46,626:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:12:46,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:46,626:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:46,981:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:46,981:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002682 seconds.
2024-06-23 10:12:46,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:46,981:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:12:46,981:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:12:46,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:46,981:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:47,343:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:47,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.
2024-06-23 10:12:47,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:47,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:47,347:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:12:47,347:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:12:47,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:47,348:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:47,684:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:47,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001440 seconds.
2024-06-23 10:12:47,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:47,684:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:12:47,684:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:12:47,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:47,684:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:47,956:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:47,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-06-23 10:12:47,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:47,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:47,959:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:12:47,959:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:12:47,959:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:47,959:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:48,231:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:48,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-06-23 10:12:48,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:48,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:48,231:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:12:48,231:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:12:48,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:48,231:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:48,475:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:48,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.
2024-06-23 10:12:48,475:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:48,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:48,482:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:12:48,482:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 1
2024-06-23 10:12:48,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:48,482:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:48,923:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:48,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015782 seconds.
2024-06-23 10:12:48,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:48,952:INFO:[LightGBM] [Info] Total Bins 14597
2024-06-23 10:12:48,954:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:12:48,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:48,955:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:49,994:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:50,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012656 seconds.
2024-06-23 10:12:50,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:50,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:50,026:INFO:[LightGBM] [Info] Total Bins 14588
2024-06-23 10:12:50,026:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:12:50,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:50,026:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:51,007:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:51,037:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015665 seconds.
2024-06-23 10:12:51,037:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:51,037:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:51,037:INFO:[LightGBM] [Info] Total Bins 14333
2024-06-23 10:12:51,039:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:12:51,039:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:51,039:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:52,044:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:52,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011902 seconds.
2024-06-23 10:12:52,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:52,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:52,074:INFO:[LightGBM] [Info] Total Bins 14333
2024-06-23 10:12:52,074:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:12:52,075:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:52,076:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:53,039:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:53,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012761 seconds.
2024-06-23 10:12:53,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:53,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:53,069:INFO:[LightGBM] [Info] Total Bins 14333
2024-06-23 10:12:53,070:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:12:53,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:53,071:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:54,048:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:54,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012625 seconds.
2024-06-23 10:12:54,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:54,074:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:54,074:INFO:[LightGBM] [Info] Total Bins 14078
2024-06-23 10:12:54,075:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:12:54,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:54,076:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:55,050:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:55,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015008 seconds.
2024-06-23 10:12:55,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:55,077:INFO:[LightGBM] [Info] Total Bins 14066
2024-06-23 10:12:55,077:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:12:55,077:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:55,077:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:56,078:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:56,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015751 seconds.
2024-06-23 10:12:56,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:56,110:INFO:[LightGBM] [Info] Total Bins 13811
2024-06-23 10:12:56,110:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:12:56,112:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:56,112:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:57,079:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:57,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011595 seconds.
2024-06-23 10:12:57,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:12:57,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:12:57,104:INFO:[LightGBM] [Info] Total Bins 13771
2024-06-23 10:12:57,105:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:12:57,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:57,106:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:58,046:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:58,080:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024099 seconds.
2024-06-23 10:12:58,080:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:58,080:INFO:[LightGBM] [Info] Total Bins 13516
2024-06-23 10:12:58,080:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:12:58,080:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:58,080:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:12:59,046:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:12:59,073:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016419 seconds.
2024-06-23 10:12:59,073:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:12:59,073:INFO:[LightGBM] [Info] Total Bins 13486
2024-06-23 10:12:59,075:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:12:59,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:12:59,077:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:00,046:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:00,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016824 seconds.
2024-06-23 10:13:00,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:00,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:00,079:INFO:[LightGBM] [Info] Total Bins 13403
2024-06-23 10:13:00,079:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:13:00,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:00,079:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:01,028:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:01,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016287 seconds.
2024-06-23 10:13:01,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:01,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:01,060:INFO:[LightGBM] [Info] Total Bins 13148
2024-06-23 10:13:01,060:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:13:01,061:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:01,061:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:02,136:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:02,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013464 seconds.
2024-06-23 10:13:02,164:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:02,164:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:02,164:INFO:[LightGBM] [Info] Total Bins 12893
2024-06-23 10:13:02,165:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:13:02,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:02,166:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:03,091:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:03,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015035 seconds.
2024-06-23 10:13:03,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:03,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:03,123:INFO:[LightGBM] [Info] Total Bins 12638
2024-06-23 10:13:03,125:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:13:03,126:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:03,126:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:04,037:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:04,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010206 seconds.
2024-06-23 10:13:04,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:04,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:04,058:INFO:[LightGBM] [Info] Total Bins 12383
2024-06-23 10:13:04,059:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:13:04,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:04,060:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:04,931:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:04,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009754 seconds.
2024-06-23 10:13:04,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:04,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:04,957:INFO:[LightGBM] [Info] Total Bins 12128
2024-06-23 10:13:04,958:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:13:04,960:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:04,960:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:05,825:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:05,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011726 seconds.
2024-06-23 10:13:05,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:05,864:INFO:[LightGBM] [Info] Total Bins 11873
2024-06-23 10:13:05,865:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:13:05,866:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:05,866:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:06,750:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:06,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011790 seconds.
2024-06-23 10:13:06,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:06,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:06,773:INFO:[LightGBM] [Info] Total Bins 11717
2024-06-23 10:13:06,773:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:13:06,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:06,775:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:07,622:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:07,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012081 seconds.
2024-06-23 10:13:07,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:07,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:07,649:INFO:[LightGBM] [Info] Total Bins 11462
2024-06-23 10:13:07,650:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:13:07,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:07,651:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:08,515:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:08,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009879 seconds.
2024-06-23 10:13:08,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:08,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:08,536:INFO:[LightGBM] [Info] Total Bins 11207
2024-06-23 10:13:08,536:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:13:08,538:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:08,538:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:09,363:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:09,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011348 seconds.
2024-06-23 10:13:09,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:09,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:09,384:INFO:[LightGBM] [Info] Total Bins 10952
2024-06-23 10:13:09,384:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:13:09,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:09,384:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:10,213:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:10,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014469 seconds.
2024-06-23 10:13:10,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:10,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:10,238:INFO:[LightGBM] [Info] Total Bins 10697
2024-06-23 10:13:10,238:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:13:10,238:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:10,238:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:11,039:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:11,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012401 seconds.
2024-06-23 10:13:11,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:11,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:11,070:INFO:[LightGBM] [Info] Total Bins 10442
2024-06-23 10:13:11,070:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:13:11,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:11,071:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:11,877:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:11,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010891 seconds.
2024-06-23 10:13:11,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:11,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:11,900:INFO:[LightGBM] [Info] Total Bins 10187
2024-06-23 10:13:11,900:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:13:11,901:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:11,901:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:12,670:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:12,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012359 seconds.
2024-06-23 10:13:12,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:12,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:12,691:INFO:[LightGBM] [Info] Total Bins 9932
2024-06-23 10:13:12,691:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:13:12,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:12,691:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:13,484:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:13,503:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010026 seconds.
2024-06-23 10:13:13,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:13,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:13,504:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:13:13,504:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:13:13,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:13,506:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:14,273:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:14,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008388 seconds.
2024-06-23 10:13:14,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:14,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:14,288:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:13:14,295:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:13:14,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:14,295:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:15,048:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:15,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008670 seconds.
2024-06-23 10:13:15,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:15,068:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:15,068:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:13:15,068:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:13:15,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:15,069:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:15,815:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:15,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008478 seconds.
2024-06-23 10:13:15,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:15,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:15,841:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:13:15,841:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:13:15,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:15,843:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:16,573:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:16,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.
2024-06-23 10:13:16,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:16,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:16,595:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:13:16,595:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:13:16,595:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:16,595:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:17,307:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:17,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007396 seconds.
2024-06-23 10:13:17,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:17,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:17,324:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:13:17,325:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:13:17,326:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:17,326:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:18,039:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:18,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.
2024-06-23 10:13:18,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:18,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:18,059:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:13:18,059:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:13:18,061:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:18,061:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:18,740:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:18,762:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013864 seconds.
2024-06-23 10:13:18,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:18,763:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:13:18,763:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:13:18,764:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:18,764:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:19,503:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:19,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008320 seconds.
2024-06-23 10:13:19,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:19,520:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:19,520:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:13:19,521:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:13:19,522:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:19,522:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:20,226:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:20,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007146 seconds.
2024-06-23 10:13:20,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:20,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:20,240:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:13:20,240:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:13:20,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:20,240:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:21,007:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:21,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007615 seconds.
2024-06-23 10:13:21,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:21,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:21,023:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:13:21,023:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:13:21,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:21,024:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:21,663:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:21,680:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006572 seconds.
2024-06-23 10:13:21,680:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:21,680:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:21,680:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:13:21,681:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:13:21,681:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:21,681:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:22,310:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:22,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005540 seconds.
2024-06-23 10:13:22,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:22,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:22,328:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:13:22,328:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:13:22,329:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:22,329:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:22,941:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:22,960:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005838 seconds.
2024-06-23 10:13:22,960:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:22,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:22,961:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:13:22,961:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:13:22,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:22,962:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:23,616:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:23,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010544 seconds.
2024-06-23 10:13:23,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:23,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:23,641:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:13:23,641:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:13:23,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:23,641:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:24,366:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:24,379:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006849 seconds.
2024-06-23 10:13:24,380:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:24,380:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:24,380:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:13:24,380:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:13:24,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:24,381:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:24,987:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:25,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007236 seconds.
2024-06-23 10:13:25,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:25,005:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:13:25,005:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:13:25,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:25,006:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:25,629:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:25,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004739 seconds.
2024-06-23 10:13:25,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:25,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:25,638:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:13:25,638:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:13:25,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:25,638:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:26,190:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:26,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004251 seconds.
2024-06-23 10:13:26,199:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:26,199:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:26,199:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:13:26,199:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:13:26,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:26,199:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:26,798:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:26,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006724 seconds.
2024-06-23 10:13:26,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:26,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:26,811:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:13:26,811:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:13:26,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:26,812:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:27,335:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:27,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006323 seconds.
2024-06-23 10:13:27,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:27,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:27,346:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:13:27,348:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:13:27,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:27,348:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:27,899:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:27,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003756 seconds.
2024-06-23 10:13:27,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:27,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:27,911:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:13:27,911:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:13:27,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:27,912:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:28,397:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:28,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003854 seconds.
2024-06-23 10:13:28,412:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:28,412:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:28,412:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:13:28,412:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:13:28,413:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:28,413:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:28,988:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:28,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005776 seconds.
2024-06-23 10:13:28,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:28,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:28,997:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:13:28,999:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:13:28,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:28,999:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:29,489:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:29,498:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004239 seconds.
2024-06-23 10:13:29,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:29,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:29,498:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:13:29,498:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:13:29,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:29,506:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:29,958:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:29,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002788 seconds.
2024-06-23 10:13:29,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:29,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:29,966:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:13:29,966:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:13:29,967:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:29,967:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:30,475:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:30,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002736 seconds.
2024-06-23 10:13:30,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:30,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:30,481:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:13:30,482:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:13:30,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:30,482:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:30,907:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:30,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002486 seconds.
2024-06-23 10:13:30,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:30,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:30,914:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:13:30,914:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:13:30,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:30,915:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:31,342:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:31,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006501 seconds.
2024-06-23 10:13:31,361:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:31,361:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:31,361:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:13:31,361:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:13:31,362:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:31,362:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:31,776:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:31,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.
2024-06-23 10:13:31,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:31,781:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:31,781:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:13:31,781:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:13:31,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:31,782:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:32,155:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:32,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003885 seconds.
2024-06-23 10:13:32,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:32,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:32,164:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:13:32,164:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:13:32,164:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:32,165:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:32,591:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:32,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004713 seconds.
2024-06-23 10:13:32,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:32,600:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:13:32,600:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:13:32,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:32,600:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:33,051:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:33,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002814 seconds.
2024-06-23 10:13:33,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:33,051:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:13:33,051:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:13:33,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:33,051:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:33,576:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:33,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.
2024-06-23 10:13:33,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:33,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:33,579:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:13:33,580:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:13:33,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:33,580:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:33,901:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:33,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001076 seconds.
2024-06-23 10:13:33,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:33,903:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:13:33,903:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:13:33,903:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:33,903:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:34,186:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:34,187:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
2024-06-23 10:13:34,188:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:34,188:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:13:34,188:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:13:34,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:34,189:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:34,442:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:34,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.
2024-06-23 10:13:34,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:34,442:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:13:34,442:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:13:34,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:34,450:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:34,733:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:13:34,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
2024-06-23 10:13:34,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:34,734:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:13:34,734:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 1
2024-06-23 10:13:34,735:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:13:34,735:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:13:35,233:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:35,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015964 seconds.
2024-06-23 10:13:35,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:35,266:INFO:[LightGBM] [Info] Total Bins 14611
2024-06-23 10:13:35,268:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:13:35,270:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:35,270:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:36,310:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:36,334:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011609 seconds.
2024-06-23 10:13:36,335:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:36,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:36,335:INFO:[LightGBM] [Info] Total Bins 14356
2024-06-23 10:13:36,336:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:13:36,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:36,338:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:37,380:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:37,412:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016262 seconds.
2024-06-23 10:13:37,413:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:37,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:37,413:INFO:[LightGBM] [Info] Total Bins 14348
2024-06-23 10:13:37,414:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:13:37,415:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:37,415:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:38,430:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:38,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011940 seconds.
2024-06-23 10:13:38,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:38,456:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:38,456:INFO:[LightGBM] [Info] Total Bins 14348
2024-06-23 10:13:38,457:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:13:38,458:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:38,459:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:39,698:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:39,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014698 seconds.
2024-06-23 10:13:39,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:39,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:39,726:INFO:[LightGBM] [Info] Total Bins 14348
2024-06-23 10:13:39,726:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:13:39,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:39,726:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:40,747:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:40,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017189 seconds.
2024-06-23 10:13:40,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:40,776:INFO:[LightGBM] [Info] Total Bins 14335
2024-06-23 10:13:40,780:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:13:40,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:40,782:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:41,949:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:41,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013817 seconds.
2024-06-23 10:13:41,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:41,974:INFO:[LightGBM] [Info] Total Bins 14080
2024-06-23 10:13:41,975:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:13:41,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:41,976:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:43,029:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:43,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014790 seconds.
2024-06-23 10:13:43,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:43,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:43,066:INFO:[LightGBM] [Info] Total Bins 14051
2024-06-23 10:13:43,068:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:13:43,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:43,070:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:44,100:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:44,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018517 seconds.
2024-06-23 10:13:44,130:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:44,130:INFO:[LightGBM] [Info] Total Bins 14013
2024-06-23 10:13:44,131:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:13:44,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:44,131:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:45,157:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:45,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016699 seconds.
2024-06-23 10:13:45,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:45,186:INFO:[LightGBM] [Info] Total Bins 13909
2024-06-23 10:13:45,188:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:13:45,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:45,188:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:46,186:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:46,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013048 seconds.
2024-06-23 10:13:46,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:46,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:46,216:INFO:[LightGBM] [Info] Total Bins 13654
2024-06-23 10:13:46,216:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:13:46,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:46,216:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:47,375:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:47,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013801 seconds.
2024-06-23 10:13:47,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:47,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:47,403:INFO:[LightGBM] [Info] Total Bins 13399
2024-06-23 10:13:47,403:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:13:47,404:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:47,405:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:48,401:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:48,440:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014599 seconds.
2024-06-23 10:13:48,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:48,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:48,440:INFO:[LightGBM] [Info] Total Bins 13144
2024-06-23 10:13:48,440:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:13:48,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:48,440:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:49,405:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:49,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014544 seconds.
2024-06-23 10:13:49,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:49,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:49,429:INFO:[LightGBM] [Info] Total Bins 12889
2024-06-23 10:13:49,429:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:13:49,429:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:49,437:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:50,326:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:50,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011967 seconds.
2024-06-23 10:13:50,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:50,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:50,350:INFO:[LightGBM] [Info] Total Bins 12634
2024-06-23 10:13:50,350:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:13:50,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:50,351:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:51,238:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:51,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013852 seconds.
2024-06-23 10:13:51,269:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:51,269:INFO:[LightGBM] [Info] Total Bins 12379
2024-06-23 10:13:51,270:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:13:51,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:51,272:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:52,323:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:52,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019039 seconds.
2024-06-23 10:13:52,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:52,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:52,364:INFO:[LightGBM] [Info] Total Bins 12124
2024-06-23 10:13:52,366:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:13:52,367:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:52,368:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:53,461:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:53,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017572 seconds.
2024-06-23 10:13:53,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:53,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:53,505:INFO:[LightGBM] [Info] Total Bins 11869
2024-06-23 10:13:53,508:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:13:53,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:53,509:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:54,657:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:54,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021006 seconds.
2024-06-23 10:13:54,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:54,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:54,702:INFO:[LightGBM] [Info] Total Bins 11716
2024-06-23 10:13:54,702:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:13:54,703:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:54,703:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:55,643:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:55,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013982 seconds.
2024-06-23 10:13:55,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:55,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:55,669:INFO:[LightGBM] [Info] Total Bins 11461
2024-06-23 10:13:55,669:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:13:55,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:55,670:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:56,762:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:56,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023702 seconds.
2024-06-23 10:13:56,815:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:56,816:INFO:[LightGBM] [Info] Total Bins 11206
2024-06-23 10:13:56,820:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:13:56,821:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:56,822:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:57,922:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:57,942:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009202 seconds.
2024-06-23 10:13:57,942:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:57,942:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:57,942:INFO:[LightGBM] [Info] Total Bins 10951
2024-06-23 10:13:57,942:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:13:57,942:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:57,942:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:58,870:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:58,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016964 seconds.
2024-06-23 10:13:58,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:13:58,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:13:58,900:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:13:58,900:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:13:58,901:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:58,901:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:13:59,805:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:13:59,835:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014485 seconds.
2024-06-23 10:13:59,835:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:13:59,835:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:13:59,836:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:13:59,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:13:59,837:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:00,883:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:00,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012494 seconds.
2024-06-23 10:14:00,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:00,912:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:00,912:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:14:00,912:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:14:00,913:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:00,913:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:01,804:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:01,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016706 seconds.
2024-06-23 10:14:01,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:01,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:01,839:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:14:01,839:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:14:01,839:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:01,839:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:02,888:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:02,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013272 seconds.
2024-06-23 10:14:02,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:02,918:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:14:02,919:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:14:02,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:02,920:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:03,791:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:03,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008105 seconds.
2024-06-23 10:14:03,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:03,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:03,812:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:14:03,812:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:14:03,813:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:03,813:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:04,579:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:04,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008915 seconds.
2024-06-23 10:14:04,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:04,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:04,595:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:14:04,595:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:14:04,595:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:04,595:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:05,672:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:05,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012814 seconds.
2024-06-23 10:14:05,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:05,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:05,693:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:14:05,693:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:14:05,693:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:05,693:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:06,418:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:06,435:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008089 seconds.
2024-06-23 10:14:06,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:06,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:06,435:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:14:06,436:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:14:06,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:06,437:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:07,367:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:07,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011730 seconds.
2024-06-23 10:14:07,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:07,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:07,393:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:14:07,393:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:14:07,395:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:07,395:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:08,176:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:08,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010418 seconds.
2024-06-23 10:14:08,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:08,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:08,190:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:14:08,190:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:14:08,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:08,198:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:08,877:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:08,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006873 seconds.
2024-06-23 10:14:08,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:08,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:08,897:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:14:08,897:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:14:08,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:08,897:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:09,627:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:09,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010289 seconds.
2024-06-23 10:14:09,640:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:09,640:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:09,640:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:14:09,640:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:14:09,648:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:09,648:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:10,328:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:10,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007090 seconds.
2024-06-23 10:14:10,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:10,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:10,346:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:14:10,346:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:14:10,346:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:10,348:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:10,999:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:11,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013227 seconds.
2024-06-23 10:14:11,024:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:11,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:11,025:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:14:11,025:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:14:11,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:11,026:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:11,704:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:11,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006707 seconds.
2024-06-23 10:14:11,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:11,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:11,721:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:14:11,721:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:14:11,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:11,722:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:12,363:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:12,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006749 seconds.
2024-06-23 10:14:12,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:12,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:12,377:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:14:12,377:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:14:12,378:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:12,378:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:13,128:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:13,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009212 seconds.
2024-06-23 10:14:13,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:13,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:13,146:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:14:13,148:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:14:13,148:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:13,148:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:13,887:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:13,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006597 seconds.
2024-06-23 10:14:13,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:13,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:13,911:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:14:13,911:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:14:13,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:13,912:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:14,622:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:14,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006764 seconds.
2024-06-23 10:14:14,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:14,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:14,637:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:14:14,637:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:14:14,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:14,637:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:15,338:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:15,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006619 seconds.
2024-06-23 10:14:15,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:15,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:15,350:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:14:15,350:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:14:15,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:15,350:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:16,034:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:16,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006259 seconds.
2024-06-23 10:14:16,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:16,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:16,046:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:14:16,046:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:14:16,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:16,046:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:16,714:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:16,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006419 seconds.
2024-06-23 10:14:16,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:16,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:16,727:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:14:16,728:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:14:16,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:16,729:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:17,386:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:17,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007880 seconds.
2024-06-23 10:14:17,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:17,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:17,399:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:14:17,399:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:14:17,399:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:17,399:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:18,129:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:18,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006389 seconds.
2024-06-23 10:14:18,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:18,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:18,142:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:14:18,142:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:14:18,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:18,144:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:18,868:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:18,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006933 seconds.
2024-06-23 10:14:18,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:18,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:18,883:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:14:18,883:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:14:18,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:18,884:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:19,507:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:19,514:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003671 seconds.
2024-06-23 10:14:19,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:19,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:19,515:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:14:19,515:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:14:19,516:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:19,516:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:20,053:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:20,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007422 seconds.
2024-06-23 10:14:20,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:20,066:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:14:20,067:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:14:20,067:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:20,068:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:20,653:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:20,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003659 seconds.
2024-06-23 10:14:20,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:20,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:20,664:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:14:20,665:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:14:20,665:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:20,666:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:21,227:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:21,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004752 seconds.
2024-06-23 10:14:21,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:21,235:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:14:21,236:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:14:21,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:21,236:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:21,720:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:21,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004440 seconds.
2024-06-23 10:14:21,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:21,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:21,729:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:14:21,729:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:14:21,730:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:21,730:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:22,123:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:22,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005423 seconds.
2024-06-23 10:14:22,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:22,131:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:14:22,132:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:14:22,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:22,132:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:22,675:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:22,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004891 seconds.
2024-06-23 10:14:22,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:22,684:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:14:22,684:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:14:22,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:22,685:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:23,131:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:23,136:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002496 seconds.
2024-06-23 10:14:23,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:23,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:23,137:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:14:23,137:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:14:23,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:23,138:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:23,632:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:23,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002209 seconds.
2024-06-23 10:14:23,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:23,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:23,638:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:14:23,638:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:14:23,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:23,639:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:24,015:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:24,020:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001826 seconds.
2024-06-23 10:14:24,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:24,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:24,020:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:14:24,021:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:14:24,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:24,021:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:24,372:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:24,380:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004067 seconds.
2024-06-23 10:14:24,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:24,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:24,381:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:14:24,381:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:14:24,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:24,382:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:24,870:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:24,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002843 seconds.
2024-06-23 10:14:24,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:24,875:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:14:24,875:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:14:24,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:24,875:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:25,208:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:25,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001903 seconds.
2024-06-23 10:14:25,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:25,211:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:14:25,211:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:14:25,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:25,212:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:25,497:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:25,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.
2024-06-23 10:14:25,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:25,497:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:14:25,497:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:14:25,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:25,497:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:25,770:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:25,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-06-23 10:14:25,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:25,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:25,771:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:14:25,771:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:14:25,772:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:25,772:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:26,013:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:26,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.
2024-06-23 10:14:26,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:26,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:26,015:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:14:26,015:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 1
2024-06-23 10:14:26,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:26,016:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:26,475:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:26,514:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014388 seconds.
2024-06-23 10:14:26,514:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:26,515:INFO:[LightGBM] [Info] Total Bins 14599
2024-06-23 10:14:26,516:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:14:26,517:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:26,517:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:27,569:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:27,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015293 seconds.
2024-06-23 10:14:27,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:27,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:27,602:INFO:[LightGBM] [Info] Total Bins 14344
2024-06-23 10:14:27,603:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:14:27,604:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:27,604:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:28,740:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:28,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011396 seconds.
2024-06-23 10:14:28,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:28,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:28,767:INFO:[LightGBM] [Info] Total Bins 14089
2024-06-23 10:14:28,767:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:14:28,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:28,769:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:29,770:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:29,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025148 seconds.
2024-06-23 10:14:29,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:29,814:INFO:[LightGBM] [Info] Total Bins 14089
2024-06-23 10:14:29,817:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:14:29,818:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:29,818:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:30,885:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:30,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017135 seconds.
2024-06-23 10:14:30,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:30,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:30,917:INFO:[LightGBM] [Info] Total Bins 14089
2024-06-23 10:14:30,917:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:14:30,918:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:30,918:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:32,012:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:32,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015644 seconds.
2024-06-23 10:14:32,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:32,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:32,048:INFO:[LightGBM] [Info] Total Bins 13834
2024-06-23 10:14:32,050:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:14:32,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:32,051:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:33,011:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:33,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015469 seconds.
2024-06-23 10:14:33,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:33,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:33,041:INFO:[LightGBM] [Info] Total Bins 13796
2024-06-23 10:14:33,044:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:14:33,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:33,044:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:34,132:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:34,173:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019108 seconds.
2024-06-23 10:14:34,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:34,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:34,173:INFO:[LightGBM] [Info] Total Bins 13784
2024-06-23 10:14:34,173:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:14:34,173:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:34,173:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:35,124:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:35,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018100 seconds.
2024-06-23 10:14:35,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:35,156:INFO:[LightGBM] [Info] Total Bins 13753
2024-06-23 10:14:35,157:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:14:35,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:35,159:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:36,155:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:36,185:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018523 seconds.
2024-06-23 10:14:36,185:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:36,185:INFO:[LightGBM] [Info] Total Bins 13744
2024-06-23 10:14:36,187:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:14:36,187:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:36,187:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:37,199:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:37,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010735 seconds.
2024-06-23 10:14:37,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:37,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:37,225:INFO:[LightGBM] [Info] Total Bins 13489
2024-06-23 10:14:37,226:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:14:37,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:37,227:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:38,164:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:38,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013541 seconds.
2024-06-23 10:14:38,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:38,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:38,198:INFO:[LightGBM] [Info] Total Bins 13403
2024-06-23 10:14:38,200:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:14:38,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:38,202:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:39,152:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:39,176:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012622 seconds.
2024-06-23 10:14:39,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:39,177:INFO:[LightGBM] [Info] Total Bins 13148
2024-06-23 10:14:39,178:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:14:39,179:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:39,179:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:40,155:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:40,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010607 seconds.
2024-06-23 10:14:40,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:40,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:40,176:INFO:[LightGBM] [Info] Total Bins 12893
2024-06-23 10:14:40,185:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:14:40,185:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:40,185:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:41,091:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:41,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010610 seconds.
2024-06-23 10:14:41,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:41,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:41,117:INFO:[LightGBM] [Info] Total Bins 12638
2024-06-23 10:14:41,119:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:14:41,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:41,119:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:42,127:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:42,159:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015829 seconds.
2024-06-23 10:14:42,159:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:42,160:INFO:[LightGBM] [Info] Total Bins 12383
2024-06-23 10:14:42,161:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:14:42,162:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:42,164:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:43,190:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:43,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018811 seconds.
2024-06-23 10:14:43,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:43,229:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:43,230:INFO:[LightGBM] [Info] Total Bins 12128
2024-06-23 10:14:43,230:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:14:43,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:43,231:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:44,163:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:44,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012297 seconds.
2024-06-23 10:14:44,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:44,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:44,187:INFO:[LightGBM] [Info] Total Bins 11976
2024-06-23 10:14:44,187:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:14:44,187:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:44,187:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:45,131:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:45,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012728 seconds.
2024-06-23 10:14:45,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:45,155:INFO:[LightGBM] [Info] Total Bins 11721
2024-06-23 10:14:45,156:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:14:45,156:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:45,157:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:46,176:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:46,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013751 seconds.
2024-06-23 10:14:46,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:46,206:INFO:[LightGBM] [Info] Total Bins 11466
2024-06-23 10:14:46,207:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:14:46,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:46,209:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:47,082:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:47,104:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009104 seconds.
2024-06-23 10:14:47,105:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:47,105:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:47,105:INFO:[LightGBM] [Info] Total Bins 11211
2024-06-23 10:14:47,106:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:14:47,107:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:47,107:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:47,934:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:47,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009163 seconds.
2024-06-23 10:14:47,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:47,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:47,956:INFO:[LightGBM] [Info] Total Bins 10956
2024-06-23 10:14:47,957:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:14:47,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:47,958:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:48,759:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:48,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012872 seconds.
2024-06-23 10:14:48,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:48,782:INFO:[LightGBM] [Info] Total Bins 10701
2024-06-23 10:14:48,785:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:14:48,785:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:48,785:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:49,635:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:49,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009198 seconds.
2024-06-23 10:14:49,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:49,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:49,665:INFO:[LightGBM] [Info] Total Bins 10446
2024-06-23 10:14:49,665:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:14:49,667:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:49,667:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:50,640:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:50,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012765 seconds.
2024-06-23 10:14:50,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:50,662:INFO:[LightGBM] [Info] Total Bins 10191
2024-06-23 10:14:50,663:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:14:50,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:50,664:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:51,501:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:51,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008658 seconds.
2024-06-23 10:14:51,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:51,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:51,521:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:14:51,522:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:14:51,522:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:51,523:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:52,404:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:52,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017296 seconds.
2024-06-23 10:14:52,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:52,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:52,444:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:14:52,444:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:14:52,444:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:52,444:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:53,261:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:53,278:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008402 seconds.
2024-06-23 10:14:53,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:53,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:53,279:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:14:53,280:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:14:53,281:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:53,281:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:54,119:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:54,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007563 seconds.
2024-06-23 10:14:54,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:54,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:54,139:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:14:54,139:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:14:54,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:54,139:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:54,868:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:54,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011212 seconds.
2024-06-23 10:14:54,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:14:54,884:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:14:54,884:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:14:54,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:54,884:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:55,654:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:55,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012362 seconds.
2024-06-23 10:14:55,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:55,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:55,685:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:14:55,685:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:14:55,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:55,685:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:56,464:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:56,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008000 seconds.
2024-06-23 10:14:56,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:56,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:56,482:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:14:56,482:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:14:56,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:56,483:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:57,265:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:57,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008230 seconds.
2024-06-23 10:14:57,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:57,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:57,282:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:14:57,282:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:14:57,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:57,283:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:57,985:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:58,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008248 seconds.
2024-06-23 10:14:58,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:58,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:58,005:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:14:58,005:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:14:58,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:58,007:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:58,776:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:58,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008874 seconds.
2024-06-23 10:14:58,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:58,791:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:58,791:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:14:58,791:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:14:58,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:58,791:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:14:59,486:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:14:59,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007659 seconds.
2024-06-23 10:14:59,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:14:59,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:14:59,508:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:14:59,508:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:14:59,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:14:59,509:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:00,315:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:00,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007066 seconds.
2024-06-23 10:15:00,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:00,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:00,337:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:15:00,337:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:15:00,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:00,337:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:01,157:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:01,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010128 seconds.
2024-06-23 10:15:01,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:01,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:01,175:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:15:01,176:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:15:01,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:01,177:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:01,934:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:01,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012539 seconds.
2024-06-23 10:15:01,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:01,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:01,966:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:15:01,967:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:15:01,967:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:01,968:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:02,635:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:02,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008491 seconds.
2024-06-23 10:15:02,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:02,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:02,647:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:15:02,647:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:15:02,647:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:02,647:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:03,255:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:03,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005821 seconds.
2024-06-23 10:15:03,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:03,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:03,269:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:15:03,269:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:15:03,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:03,271:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:03,926:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:03,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010040 seconds.
2024-06-23 10:15:03,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:03,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:03,948:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:15:03,948:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:15:03,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:03,956:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:04,812:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:04,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005725 seconds.
2024-06-23 10:15:04,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:04,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:04,827:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:15:04,828:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:15:04,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:04,828:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:05,424:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:05,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005245 seconds.
2024-06-23 10:15:05,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:05,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:05,437:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:15:05,437:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:15:05,442:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:05,442:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:06,062:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:06,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009064 seconds.
2024-06-23 10:15:06,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:06,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:06,085:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:15:06,085:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:15:06,086:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:06,086:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:06,710:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:06,720:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004536 seconds.
2024-06-23 10:15:06,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:06,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:06,722:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:15:06,722:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:15:06,723:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:06,723:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:07,237:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:07,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006174 seconds.
2024-06-23 10:15:07,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:07,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:07,247:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:15:07,247:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:15:07,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:07,247:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:07,741:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:07,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008480 seconds.
2024-06-23 10:15:07,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:07,756:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:15:07,756:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:15:07,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:07,757:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:08,274:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:08,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003904 seconds.
2024-06-23 10:15:08,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:08,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:08,283:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:15:08,283:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:15:08,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:08,284:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:08,775:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:08,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003286 seconds.
2024-06-23 10:15:08,783:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:08,783:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:08,783:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:15:08,783:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:15:08,784:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:08,784:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:09,233:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:09,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003355 seconds.
2024-06-23 10:15:09,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:09,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:09,239:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:15:09,239:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:15:09,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:09,239:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:09,694:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:09,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003172 seconds.
2024-06-23 10:15:09,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:09,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:09,702:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:15:09,702:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:15:09,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:09,704:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:10,149:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:10,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003143 seconds.
2024-06-23 10:15:10,164:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:10,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:10,165:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:15:10,165:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:15:10,167:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:10,167:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:10,575:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:10,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002827 seconds.
2024-06-23 10:15:10,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:10,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:10,582:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:15:10,582:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:15:10,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:10,583:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:10,989:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:10,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004105 seconds.
2024-06-23 10:15:10,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:10,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:10,994:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:15:10,994:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:15:10,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:10,994:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:11,374:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:11,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003082 seconds.
2024-06-23 10:15:11,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:11,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:11,382:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:15:11,382:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:15:11,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:11,383:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:11,753:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:11,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004455 seconds.
2024-06-23 10:15:11,764:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:11,764:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:15:11,764:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:15:11,765:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:11,765:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:12,212:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:12,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.
2024-06-23 10:15:12,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:12,218:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:12,218:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:15:12,218:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:15:12,219:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:12,219:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:12,630:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:12,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.
2024-06-23 10:15:12,634:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:12,634:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:12,634:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:15:12,634:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:15:12,635:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:12,635:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:12,964:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:12,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.
2024-06-23 10:15:12,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:12,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:12,968:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:15:12,969:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:15:12,969:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:12,969:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:13,270:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:13,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.
2024-06-23 10:15:13,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:13,271:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:15:13,272:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:15:13,272:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:13,272:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:13,529:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:13,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-06-23 10:15:13,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:13,531:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:13,531:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:15:13,532:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:15:13,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:13,532:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:13,833:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:13,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-06-23 10:15:13,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:13,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:13,834:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:15:13,835:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:15:13,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:13,835:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:14,095:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:14,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-06-23 10:15:14,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:14,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:14,095:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:15:14,095:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 1
2024-06-23 10:15:14,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:14,095:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:14,609:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:14,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017022 seconds.
2024-06-23 10:15:14,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:14,640:INFO:[LightGBM] [Info] Total Bins 14618
2024-06-23 10:15:14,641:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:15:14,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:14,643:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:15,745:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:15,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015817 seconds.
2024-06-23 10:15:15,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:15,775:INFO:[LightGBM] [Info] Total Bins 14618
2024-06-23 10:15:15,775:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:15:15,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:15,782:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:16,802:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:16,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014715 seconds.
2024-06-23 10:15:16,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:16,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:16,831:INFO:[LightGBM] [Info] Total Bins 14363
2024-06-23 10:15:16,831:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:15:16,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:16,831:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:17,806:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:17,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016627 seconds.
2024-06-23 10:15:17,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:17,837:INFO:[LightGBM] [Info] Total Bins 14354
2024-06-23 10:15:17,840:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:15:17,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:17,840:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:18,848:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:18,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012742 seconds.
2024-06-23 10:15:18,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:18,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:18,874:INFO:[LightGBM] [Info] Total Bins 14354
2024-06-23 10:15:18,875:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:15:18,876:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:18,876:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:19,963:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:20,003:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018897 seconds.
2024-06-23 10:15:20,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:20,003:INFO:[LightGBM] [Info] Total Bins 14099
2024-06-23 10:15:20,004:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:15:20,005:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:20,005:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:21,075:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:21,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019457 seconds.
2024-06-23 10:15:21,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:21,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:21,116:INFO:[LightGBM] [Info] Total Bins 14087
2024-06-23 10:15:21,118:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:15:21,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:21,120:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:22,133:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:22,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011407 seconds.
2024-06-23 10:15:22,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:22,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:22,159:INFO:[LightGBM] [Info] Total Bins 14058
2024-06-23 10:15:22,160:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:15:22,161:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:22,161:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:23,098:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:23,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017678 seconds.
2024-06-23 10:15:23,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:23,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:23,127:INFO:[LightGBM] [Info] Total Bins 14018
2024-06-23 10:15:23,127:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:15:23,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:23,129:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:24,084:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:24,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012199 seconds.
2024-06-23 10:15:24,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:24,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:24,117:INFO:[LightGBM] [Info] Total Bins 13763
2024-06-23 10:15:24,118:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:15:24,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:24,119:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:25,182:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:25,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014197 seconds.
2024-06-23 10:15:25,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:25,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:25,214:INFO:[LightGBM] [Info] Total Bins 13508
2024-06-23 10:15:25,215:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:15:25,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:25,217:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:26,204:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:26,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016046 seconds.
2024-06-23 10:15:26,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:26,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:26,250:INFO:[LightGBM] [Info] Total Bins 13253
2024-06-23 10:15:26,251:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:15:26,252:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:26,252:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:27,224:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:27,251:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014716 seconds.
2024-06-23 10:15:27,251:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:27,251:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:27,252:INFO:[LightGBM] [Info] Total Bins 13151
2024-06-23 10:15:27,253:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:15:27,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:27,254:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:28,247:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:28,273:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010547 seconds.
2024-06-23 10:15:28,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:28,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:28,274:INFO:[LightGBM] [Info] Total Bins 12896
2024-06-23 10:15:28,275:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:15:28,276:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:28,276:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:29,290:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:29,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014953 seconds.
2024-06-23 10:15:29,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:29,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:29,333:INFO:[LightGBM] [Info] Total Bins 12641
2024-06-23 10:15:29,333:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:15:29,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:29,333:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:30,258:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:30,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012591 seconds.
2024-06-23 10:15:30,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:30,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:30,284:INFO:[LightGBM] [Info] Total Bins 12386
2024-06-23 10:15:30,284:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:15:30,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:30,292:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:31,238:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:31,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013725 seconds.
2024-06-23 10:15:31,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:31,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:31,276:INFO:[LightGBM] [Info] Total Bins 12131
2024-06-23 10:15:31,277:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:15:31,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:31,278:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:32,208:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:32,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010246 seconds.
2024-06-23 10:15:32,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:32,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:32,232:INFO:[LightGBM] [Info] Total Bins 11876
2024-06-23 10:15:32,233:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:15:32,234:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:32,234:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:33,138:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:33,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013474 seconds.
2024-06-23 10:15:33,166:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:33,166:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:33,166:INFO:[LightGBM] [Info] Total Bins 11621
2024-06-23 10:15:33,168:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:15:33,169:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:33,170:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:34,081:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:34,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010377 seconds.
2024-06-23 10:15:34,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:34,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:34,107:INFO:[LightGBM] [Info] Total Bins 11366
2024-06-23 10:15:34,108:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:15:34,109:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:34,109:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:34,989:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:35,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010102 seconds.
2024-06-23 10:15:35,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:35,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:35,012:INFO:[LightGBM] [Info] Total Bins 11111
2024-06-23 10:15:35,013:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:15:35,014:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:35,015:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:35,890:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:35,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009772 seconds.
2024-06-23 10:15:35,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:35,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:35,911:INFO:[LightGBM] [Info] Total Bins 10856
2024-06-23 10:15:35,912:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:15:35,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:35,913:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:36,744:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:36,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009279 seconds.
2024-06-23 10:15:36,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:36,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:36,764:INFO:[LightGBM] [Info] Total Bins 10699
2024-06-23 10:15:36,764:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:15:36,765:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:36,766:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:37,556:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:37,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010828 seconds.
2024-06-23 10:15:37,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:37,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:37,578:INFO:[LightGBM] [Info] Total Bins 10444
2024-06-23 10:15:37,579:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:15:37,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:37,580:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:38,438:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:38,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009087 seconds.
2024-06-23 10:15:38,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:38,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:38,461:INFO:[LightGBM] [Info] Total Bins 10189
2024-06-23 10:15:38,462:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:15:38,463:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:38,463:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:39,451:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:39,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015354 seconds.
2024-06-23 10:15:39,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:39,477:INFO:[LightGBM] [Info] Total Bins 9934
2024-06-23 10:15:39,478:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:15:39,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:39,480:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:40,504:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:40,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008809 seconds.
2024-06-23 10:15:40,528:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:40,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:40,528:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:15:40,529:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:15:40,530:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:40,530:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:41,341:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:41,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009014 seconds.
2024-06-23 10:15:41,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:41,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:41,364:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:15:41,364:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:15:41,365:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:41,365:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:42,157:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:42,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012723 seconds.
2024-06-23 10:15:42,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:42,179:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:15:42,180:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:15:42,181:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:42,181:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:42,989:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:43,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007791 seconds.
2024-06-23 10:15:43,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:43,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:43,007:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:15:43,008:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:15:43,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:43,009:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:43,754:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:43,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007791 seconds.
2024-06-23 10:15:43,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:43,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:43,771:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:15:43,772:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:15:43,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:43,773:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:44,513:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:44,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009967 seconds.
2024-06-23 10:15:44,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:44,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:44,533:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:15:44,534:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:15:44,539:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:44,539:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:45,397:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:45,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009649 seconds.
2024-06-23 10:15:45,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:45,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:45,416:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:15:45,416:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:15:45,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:45,417:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:46,159:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:46,182:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009844 seconds.
2024-06-23 10:15:46,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:46,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:46,183:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:15:46,183:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:15:46,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:46,184:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:47,007:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:47,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007760 seconds.
2024-06-23 10:15:47,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:47,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:47,025:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:15:47,026:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:15:47,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:47,027:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:47,748:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:47,762:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006624 seconds.
2024-06-23 10:15:47,762:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:47,763:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:47,763:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:15:47,763:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:15:47,764:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:47,764:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:48,464:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:48,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006298 seconds.
2024-06-23 10:15:48,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:48,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:48,478:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:15:48,479:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:15:48,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:48,480:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:49,117:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:49,130:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005797 seconds.
2024-06-23 10:15:49,130:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:49,130:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:49,131:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:15:49,131:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:15:49,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:49,132:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:49,755:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:49,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006063 seconds.
2024-06-23 10:15:49,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:49,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:49,770:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:15:49,771:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:15:49,771:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:49,772:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:50,404:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:50,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006164 seconds.
2024-06-23 10:15:50,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:50,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:50,418:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:15:50,418:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:15:50,419:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:50,419:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:51,060:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:51,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009556 seconds.
2024-06-23 10:15:51,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:51,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:51,084:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:15:51,085:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:15:51,086:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:51,086:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:51,784:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:51,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010425 seconds.
2024-06-23 10:15:51,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:51,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:51,803:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:15:51,803:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:15:51,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:51,805:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:52,463:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:52,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006383 seconds.
2024-06-23 10:15:52,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:52,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:52,481:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:15:52,482:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:15:52,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:52,483:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:53,143:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:53,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005948 seconds.
2024-06-23 10:15:53,158:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:53,158:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:53,159:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:15:53,159:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:15:53,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:53,160:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:53,753:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:53,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006391 seconds.
2024-06-23 10:15:53,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:53,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:53,766:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:15:53,766:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:15:53,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:53,767:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:54,328:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:54,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004505 seconds.
2024-06-23 10:15:54,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:54,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:54,338:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:15:54,338:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:15:54,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:54,340:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:54,853:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:54,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005361 seconds.
2024-06-23 10:15:54,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:54,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:54,864:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:15:54,864:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:15:54,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:54,865:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:55,359:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:55,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005878 seconds.
2024-06-23 10:15:55,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:55,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:55,373:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:15:55,374:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:15:55,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:55,374:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:55,862:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:55,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003892 seconds.
2024-06-23 10:15:55,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:55,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:55,871:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:15:55,872:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:15:55,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:55,873:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:56,371:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:56,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004718 seconds.
2024-06-23 10:15:56,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:56,380:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:15:56,380:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:15:56,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:56,381:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:56,864:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:56,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005144 seconds.
2024-06-23 10:15:56,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:56,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:56,876:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:15:56,876:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:15:56,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:56,877:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:57,335:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:57,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003163 seconds.
2024-06-23 10:15:57,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:57,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:57,344:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:15:57,344:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:15:57,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:57,345:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:57,780:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:57,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.
2024-06-23 10:15:57,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:57,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:57,790:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:15:57,790:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:15:57,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:57,791:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:58,215:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:58,222:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003129 seconds.
2024-06-23 10:15:58,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:58,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:58,223:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:15:58,223:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:15:58,224:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:58,224:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:58,625:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:58,632:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003733 seconds.
2024-06-23 10:15:58,632:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:58,633:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:15:58,633:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:15:58,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:58,634:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:59,049:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:59,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002356 seconds.
2024-06-23 10:15:59,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:59,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:59,055:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:15:59,055:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:15:59,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:59,056:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:59,416:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:59,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.
2024-06-23 10:15:59,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:15:59,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:15:59,421:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:15:59,421:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:15:59,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:59,422:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:15:59,764:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:15:59,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002971 seconds.
2024-06-23 10:15:59,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:15:59,769:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:15:59,769:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:15:59,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:15:59,770:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:00,215:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:16:00,221:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003912 seconds.
2024-06-23 10:16:00,221:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:00,222:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:16:00,222:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:16:00,222:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:16:00,223:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:00,564:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:16:00,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.
2024-06-23 10:16:00,568:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:00,568:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:00,568:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:16:00,568:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:16:00,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:16:00,569:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:00,882:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:16:00,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001077 seconds.
2024-06-23 10:16:00,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:00,884:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:16:00,884:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:16:00,885:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:16:00,885:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:01,254:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:16:01,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001205 seconds.
2024-06-23 10:16:01,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:01,256:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:16:01,256:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:16:01,256:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:16:01,257:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:01,543:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:16:01,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-06-23 10:16:01,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:01,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:01,544:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:16:01,544:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:16:01,545:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:16:01,545:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:01,806:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18421
2024-06-23 10:16:01,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-06-23 10:16:01,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:01,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:01,807:INFO:[LightGBM] [Info] Total Bins 255
2024-06-23 10:16:01,808:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 1
2024-06-23 10:16:01,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499986 -> initscore=-0.000054
2024-06-23 10:16:01,808:INFO:[LightGBM] [Info] Start training from score -0.000054
2024-06-23 10:16:02,286:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:02,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015791 seconds.
2024-06-23 10:16:02,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:02,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:02,316:INFO:[LightGBM] [Info] Total Bins 14647
2024-06-23 10:16:02,317:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:16:02,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:03,318:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:03,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017125 seconds.
2024-06-23 10:16:03,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:03,349:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:16:03,351:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:16:03,352:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:04,661:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:04,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030775 seconds.
2024-06-23 10:16:04,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:04,705:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:16:04,707:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:16:04,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:05,951:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:05,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017724 seconds.
2024-06-23 10:16:05,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:05,979:INFO:[LightGBM] [Info] Total Bins 14383
2024-06-23 10:16:05,979:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:16:05,979:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:07,073:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:07,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017868 seconds.
2024-06-23 10:16:07,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:07,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:07,107:INFO:[LightGBM] [Info] Total Bins 14128
2024-06-23 10:16:07,107:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:16:07,109:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:08,176:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:08,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015330 seconds.
2024-06-23 10:16:08,212:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:08,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:08,212:INFO:[LightGBM] [Info] Total Bins 14085
2024-06-23 10:16:08,213:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:16:08,214:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:09,243:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:09,272:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014357 seconds.
2024-06-23 10:16:09,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:09,273:INFO:[LightGBM] [Info] Total Bins 14072
2024-06-23 10:16:09,274:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:16:09,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:10,349:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:10,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015569 seconds.
2024-06-23 10:16:10,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:10,376:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:16:10,376:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:16:10,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:11,383:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:11,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012505 seconds.
2024-06-23 10:16:11,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:11,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:11,417:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:16:11,417:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:16:11,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:12,379:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:12,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014083 seconds.
2024-06-23 10:16:12,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:12,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:12,417:INFO:[LightGBM] [Info] Total Bins 13783
2024-06-23 10:16:12,418:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:16:12,419:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:13,512:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:13,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021892 seconds.
2024-06-23 10:16:13,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:13,546:INFO:[LightGBM] [Info] Total Bins 13528
2024-06-23 10:16:13,546:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:16:13,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:14,760:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:14,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018842 seconds.
2024-06-23 10:16:14,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:14,790:INFO:[LightGBM] [Info] Total Bins 13422
2024-06-23 10:16:14,794:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:16:14,795:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:15,823:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:15,855:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019632 seconds.
2024-06-23 10:16:15,855:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:15,855:INFO:[LightGBM] [Info] Total Bins 13260
2024-06-23 10:16:15,857:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:16:15,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:16,941:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:16,989:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019465 seconds.
2024-06-23 10:16:16,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:16,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:16,989:INFO:[LightGBM] [Info] Total Bins 13005
2024-06-23 10:16:16,989:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:16:16,989:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:18,001:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:18,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011389 seconds.
2024-06-23 10:16:18,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:18,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:18,025:INFO:[LightGBM] [Info] Total Bins 12750
2024-06-23 10:16:18,026:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:16:18,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:18,932:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:18,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010357 seconds.
2024-06-23 10:16:18,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:18,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:18,955:INFO:[LightGBM] [Info] Total Bins 12495
2024-06-23 10:16:18,956:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:16:18,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:19,856:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:19,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017214 seconds.
2024-06-23 10:16:19,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:19,883:INFO:[LightGBM] [Info] Total Bins 12240
2024-06-23 10:16:19,883:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:16:19,887:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:20,829:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:20,851:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011088 seconds.
2024-06-23 10:16:20,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:20,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:20,852:INFO:[LightGBM] [Info] Total Bins 11985
2024-06-23 10:16:20,852:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:16:20,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:21,742:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:21,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013214 seconds.
2024-06-23 10:16:21,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:21,769:INFO:[LightGBM] [Info] Total Bins 11730
2024-06-23 10:16:21,769:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:16:21,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:22,707:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:22,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009865 seconds.
2024-06-23 10:16:22,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:22,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:22,727:INFO:[LightGBM] [Info] Total Bins 11475
2024-06-23 10:16:22,728:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:16:22,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:23,580:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:23,605:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014410 seconds.
2024-06-23 10:16:23,606:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:23,606:INFO:[LightGBM] [Info] Total Bins 11220
2024-06-23 10:16:23,607:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:16:23,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:24,521:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:24,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015468 seconds.
2024-06-23 10:16:24,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:24,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:24,551:INFO:[LightGBM] [Info] Total Bins 10965
2024-06-23 10:16:24,551:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:16:24,552:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:25,462:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:25,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013033 seconds.
2024-06-23 10:16:25,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:25,484:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:16:25,484:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:16:25,485:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:26,371:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:26,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009453 seconds.
2024-06-23 10:16:26,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:26,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:26,390:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:16:26,390:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:16:26,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:27,208:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:27,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016014 seconds.
2024-06-23 10:16:27,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:27,236:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:16:27,236:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:16:27,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:28,136:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:28,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020753 seconds.
2024-06-23 10:16:28,173:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:28,174:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:16:28,174:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:16:28,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:29,055:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:29,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010655 seconds.
2024-06-23 10:16:29,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:29,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:29,077:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:16:29,078:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:16:29,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:29,850:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:29,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008174 seconds.
2024-06-23 10:16:29,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:29,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:29,869:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:16:29,869:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:16:29,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:30,663:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:30,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011994 seconds.
2024-06-23 10:16:30,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:30,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:30,691:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:16:30,691:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:16:30,695:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:31,452:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:31,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007604 seconds.
2024-06-23 10:16:31,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:31,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:31,471:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:16:31,472:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:16:31,473:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:32,255:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:32,275:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007776 seconds.
2024-06-23 10:16:32,275:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:32,275:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:32,276:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:16:32,276:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:16:32,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:33,022:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:33,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008127 seconds.
2024-06-23 10:16:33,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:33,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:33,042:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:16:33,042:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:16:33,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:33,821:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:33,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007863 seconds.
2024-06-23 10:16:33,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:33,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:33,841:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:16:33,841:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:16:33,841:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:34,589:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:34,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007590 seconds.
2024-06-23 10:16:34,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:34,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:34,608:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:16:34,608:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:16:34,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:35,438:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:35,456:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007552 seconds.
2024-06-23 10:16:35,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:35,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:35,457:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:16:35,457:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:16:35,458:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:36,275:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:36,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010379 seconds.
2024-06-23 10:16:36,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:36,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:36,293:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:16:36,297:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:16:36,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:37,047:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:37,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006680 seconds.
2024-06-23 10:16:37,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:37,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:37,062:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:16:37,062:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:16:37,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:37,728:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:37,754:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014538 seconds.
2024-06-23 10:16:37,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:37,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:37,755:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:16:37,755:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:16:37,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:38,485:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:38,498:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.
2024-06-23 10:16:38,498:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:38,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:38,498:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:16:38,502:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:16:38,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:39,189:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:39,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005963 seconds.
2024-06-23 10:16:39,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:39,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:39,203:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:16:39,203:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:16:39,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:39,848:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:39,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005343 seconds.
2024-06-23 10:16:39,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:39,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:39,863:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:16:39,864:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:16:39,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:40,487:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:40,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007616 seconds.
2024-06-23 10:16:40,503:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:40,503:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:40,503:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:16:40,504:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:16:40,504:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:41,155:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:41,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004834 seconds.
2024-06-23 10:16:41,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:41,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:41,168:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:16:41,169:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:16:41,169:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:41,745:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:41,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004847 seconds.
2024-06-23 10:16:41,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:41,758:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:41,758:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:16:41,759:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:16:41,759:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:42,332:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:42,341:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.
2024-06-23 10:16:42,341:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:42,341:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:42,341:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:16:42,341:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:16:42,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:42,887:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:42,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006999 seconds.
2024-06-23 10:16:42,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:42,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:42,903:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:16:42,904:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:16:42,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:43,432:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:43,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008981 seconds.
2024-06-23 10:16:43,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:43,446:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:16:43,446:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:16:43,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:44,024:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:44,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006432 seconds.
2024-06-23 10:16:44,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:44,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:44,036:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:16:44,036:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:16:44,037:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:44,585:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:44,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004030 seconds.
2024-06-23 10:16:44,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:44,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:44,597:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:16:44,597:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:16:44,597:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:45,088:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:45,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004266 seconds.
2024-06-23 10:16:45,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:45,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:45,096:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:16:45,096:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:16:45,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:45,644:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:45,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004736 seconds.
2024-06-23 10:16:45,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:45,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:45,663:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:16:45,663:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:16:45,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:46,180:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:46,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003313 seconds.
2024-06-23 10:16:46,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:46,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:46,188:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:16:46,188:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:16:46,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:46,802:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:46,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005289 seconds.
2024-06-23 10:16:46,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:46,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:46,818:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:16:46,818:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:16:46,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:47,327:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:47,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002431 seconds.
2024-06-23 10:16:47,334:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:47,334:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:47,334:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:16:47,334:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:16:47,335:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:47,812:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:47,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002415 seconds.
2024-06-23 10:16:47,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:47,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:47,818:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:16:47,818:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:16:47,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:48,329:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:48,335:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004203 seconds.
2024-06-23 10:16:48,336:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:48,336:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:16:48,336:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:16:48,336:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:48,911:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:48,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.
2024-06-23 10:16:48,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:48,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:48,917:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:16:48,917:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:16:48,917:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:49,327:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:49,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.
2024-06-23 10:16:49,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:49,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:49,332:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:16:49,332:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:16:49,332:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:49,761:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:49,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003291 seconds.
2024-06-23 10:16:49,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:49,766:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:16:49,766:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:16:49,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:50,181:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:50,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002004 seconds.
2024-06-23 10:16:50,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:50,184:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:16:50,184:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:16:50,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:50,518:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:50,520:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001158 seconds.
2024-06-23 10:16:50,520:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:50,520:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:16:50,520:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:16:50,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:50,808:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:50,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001103 seconds.
2024-06-23 10:16:50,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:50,810:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:16:50,810:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:16:50,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:51,071:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:51,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-06-23 10:16:51,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:51,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:51,072:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:16:51,072:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:16:51,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:51,529:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:51,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018708 seconds.
2024-06-23 10:16:51,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:51,560:INFO:[LightGBM] [Info] Total Bins 14621
2024-06-23 10:16:51,562:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:16:51,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:52,595:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:52,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012464 seconds.
2024-06-23 10:16:52,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:52,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:52,628:INFO:[LightGBM] [Info] Total Bins 14366
2024-06-23 10:16:52,629:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:16:52,630:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:53,591:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:53,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013656 seconds.
2024-06-23 10:16:53,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:53,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:53,618:INFO:[LightGBM] [Info] Total Bins 14366
2024-06-23 10:16:53,619:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:16:53,620:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:54,614:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:54,647:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016997 seconds.
2024-06-23 10:16:54,647:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:54,647:INFO:[LightGBM] [Info] Total Bins 14111
2024-06-23 10:16:54,648:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:16:54,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:55,781:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:55,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018885 seconds.
2024-06-23 10:16:55,815:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:16:55,815:INFO:[LightGBM] [Info] Total Bins 14103
2024-06-23 10:16:55,817:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:16:55,818:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:56,937:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:56,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015731 seconds.
2024-06-23 10:16:56,969:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:56,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:56,969:INFO:[LightGBM] [Info] Total Bins 14103
2024-06-23 10:16:56,970:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:16:56,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:57,919:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:57,951:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017062 seconds.
2024-06-23 10:16:57,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:57,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:57,952:INFO:[LightGBM] [Info] Total Bins 14091
2024-06-23 10:16:57,953:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:16:57,954:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:16:59,084:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:16:59,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011289 seconds.
2024-06-23 10:16:59,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:16:59,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:16:59,109:INFO:[LightGBM] [Info] Total Bins 14059
2024-06-23 10:16:59,110:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:16:59,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:00,136:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:00,176:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017236 seconds.
2024-06-23 10:17:00,176:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:00,176:INFO:[LightGBM] [Info] Total Bins 13804
2024-06-23 10:17:00,176:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:17:00,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:01,377:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:01,405:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012557 seconds.
2024-06-23 10:17:01,405:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:01,406:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:01,406:INFO:[LightGBM] [Info] Total Bins 13704
2024-06-23 10:17:01,407:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:17:01,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:02,484:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:02,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012554 seconds.
2024-06-23 10:17:02,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:02,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:02,512:INFO:[LightGBM] [Info] Total Bins 13449
2024-06-23 10:17:02,513:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:17:02,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:03,563:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:03,589:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010287 seconds.
2024-06-23 10:17:03,589:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:03,589:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:03,589:INFO:[LightGBM] [Info] Total Bins 13194
2024-06-23 10:17:03,590:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:17:03,591:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:04,497:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:04,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016183 seconds.
2024-06-23 10:17:04,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:04,528:INFO:[LightGBM] [Info] Total Bins 13155
2024-06-23 10:17:04,528:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:17:04,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:05,607:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:05,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013217 seconds.
2024-06-23 10:17:05,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:05,628:INFO:[LightGBM] [Info] Total Bins 12900
2024-06-23 10:17:05,628:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:17:05,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:06,613:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:06,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010792 seconds.
2024-06-23 10:17:06,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:06,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:06,633:INFO:[LightGBM] [Info] Total Bins 12645
2024-06-23 10:17:06,633:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:17:06,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:07,529:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:07,551:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010996 seconds.
2024-06-23 10:17:07,551:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:07,551:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:07,552:INFO:[LightGBM] [Info] Total Bins 12390
2024-06-23 10:17:07,552:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:17:07,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:08,473:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:08,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012847 seconds.
2024-06-23 10:17:08,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:08,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:08,564:INFO:[LightGBM] [Info] Total Bins 12135
2024-06-23 10:17:08,566:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:17:08,567:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:09,530:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:09,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010326 seconds.
2024-06-23 10:17:09,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:09,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:09,559:INFO:[LightGBM] [Info] Total Bins 11880
2024-06-23 10:17:09,560:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:17:09,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:10,580:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:10,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020403 seconds.
2024-06-23 10:17:10,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:10,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:10,616:INFO:[LightGBM] [Info] Total Bins 11625
2024-06-23 10:17:10,617:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:17:10,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:11,532:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:11,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009872 seconds.
2024-06-23 10:17:11,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:11,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:11,554:INFO:[LightGBM] [Info] Total Bins 11370
2024-06-23 10:17:11,554:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:17:11,555:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:12,431:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:12,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022300 seconds.
2024-06-23 10:17:12,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:12,467:INFO:[LightGBM] [Info] Total Bins 11115
2024-06-23 10:17:12,469:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:17:12,470:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:13,380:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:13,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010322 seconds.
2024-06-23 10:17:13,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:13,401:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:13,401:INFO:[LightGBM] [Info] Total Bins 10960
2024-06-23 10:17:13,402:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:17:13,402:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:14,377:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:14,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012394 seconds.
2024-06-23 10:17:14,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:14,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:14,400:INFO:[LightGBM] [Info] Total Bins 10705
2024-06-23 10:17:14,401:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:17:14,402:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:15,291:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:15,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014407 seconds.
2024-06-23 10:17:15,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:15,317:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:17:15,318:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:17:15,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:16,182:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:16,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011274 seconds.
2024-06-23 10:17:16,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:16,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:16,208:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:17:16,208:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:17:16,211:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:17,147:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:17,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011790 seconds.
2024-06-23 10:17:17,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:17,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:17,176:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:17:17,177:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:17:17,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:18,030:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:18,054:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012787 seconds.
2024-06-23 10:17:18,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:18,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:18,054:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:17:18,055:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:17:18,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:18,991:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:19,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012355 seconds.
2024-06-23 10:17:19,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:19,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:19,021:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:17:19,021:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:17:19,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:19,771:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:19,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008802 seconds.
2024-06-23 10:17:19,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:19,791:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:19,791:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:17:19,791:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:17:19,793:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:20,934:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:20,960:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012503 seconds.
2024-06-23 10:17:20,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:20,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:20,961:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:17:20,962:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:17:20,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:21,910:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:21,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014199 seconds.
2024-06-23 10:17:21,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:21,936:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:17:21,936:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:17:21,936:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:23,256:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:23,290:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022013 seconds.
2024-06-23 10:17:23,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:23,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:23,290:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:17:23,290:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:17:23,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:24,425:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:24,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016168 seconds.
2024-06-23 10:17:24,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:24,452:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:17:24,453:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:17:24,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:25,508:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:25,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009815 seconds.
2024-06-23 10:17:25,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:25,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:25,528:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:17:25,528:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:17:25,529:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:26,406:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:26,420:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.
2024-06-23 10:17:26,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:26,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:26,421:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:17:26,421:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:17:26,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:27,107:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:27,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008452 seconds.
2024-06-23 10:17:27,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:27,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:27,125:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:17:27,127:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:17:27,128:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:27,848:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:27,865:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007043 seconds.
2024-06-23 10:17:27,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:27,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:27,866:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:17:27,866:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:17:27,867:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:28,526:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:28,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006290 seconds.
2024-06-23 10:17:28,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:28,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:28,549:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:17:28,549:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:17:28,549:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:29,289:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:29,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007763 seconds.
2024-06-23 10:17:29,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:29,303:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:17:29,304:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:17:29,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:29,948:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:29,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005814 seconds.
2024-06-23 10:17:29,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:29,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:29,961:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:17:29,962:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:17:29,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:30,603:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:30,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006750 seconds.
2024-06-23 10:17:30,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:30,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:30,625:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:17:30,625:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:17:30,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:31,234:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:31,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010115 seconds.
2024-06-23 10:17:31,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:31,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:31,253:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:17:31,253:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:17:31,254:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:31,844:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:31,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005182 seconds.
2024-06-23 10:17:31,858:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:31,858:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:31,859:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:17:31,859:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:17:31,860:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:32,480:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:32,495:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013081 seconds.
2024-06-23 10:17:32,495:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:32,495:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:17:32,495:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:17:32,495:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:33,110:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:33,119:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004420 seconds.
2024-06-23 10:17:33,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:33,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:33,120:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:17:33,124:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:17:33,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:33,750:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:33,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009553 seconds.
2024-06-23 10:17:33,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:33,766:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:17:33,766:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:17:33,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:34,465:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:34,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004493 seconds.
2024-06-23 10:17:34,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:34,479:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:34,479:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:17:34,479:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:17:34,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:35,013:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:35,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004303 seconds.
2024-06-23 10:17:35,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:35,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:35,023:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:17:35,023:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:17:35,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:35,686:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:35,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005960 seconds.
2024-06-23 10:17:35,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:35,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:35,695:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:17:35,695:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:17:35,699:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:36,330:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:36,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.
2024-06-23 10:17:36,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:36,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:36,338:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:17:36,339:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:17:36,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:36,882:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:36,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003733 seconds.
2024-06-23 10:17:36,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:36,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:36,891:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:17:36,891:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:17:36,893:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:37,422:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:37,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006331 seconds.
2024-06-23 10:17:37,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:37,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:37,435:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:17:37,435:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:17:37,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:38,336:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:38,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002876 seconds.
2024-06-23 10:17:38,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:38,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:38,346:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:17:38,346:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:17:38,346:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:38,882:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:38,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002748 seconds.
2024-06-23 10:17:38,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:38,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:38,889:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:17:38,889:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:17:38,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:39,287:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:39,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002562 seconds.
2024-06-23 10:17:39,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:39,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:39,294:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:17:39,294:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:17:39,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:39,666:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:39,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006190 seconds.
2024-06-23 10:17:39,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:39,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:39,684:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:17:39,684:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:17:39,685:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:40,067:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:40,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.
2024-06-23 10:17:40,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:40,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:40,072:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:17:40,072:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:17:40,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:40,431:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:40,435:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.
2024-06-23 10:17:40,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:40,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:40,436:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:17:40,436:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:17:40,436:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:40,769:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:40,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003415 seconds.
2024-06-23 10:17:40,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:40,775:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:17:40,775:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:17:40,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:41,145:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:41,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.
2024-06-23 10:17:41,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:41,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:41,149:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:17:41,149:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:17:41,149:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:41,483:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:41,485:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001038 seconds.
2024-06-23 10:17:41,485:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:41,485:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:17:41,485:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:17:41,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:41,761:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:41,762:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.
2024-06-23 10:17:41,762:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:41,762:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:17:41,762:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:17:41,763:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:42,037:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:42,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.
2024-06-23 10:17:42,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:42,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:42,039:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:17:42,039:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:17:42,040:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:42,533:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:42,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014714 seconds.
2024-06-23 10:17:42,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:42,560:INFO:[LightGBM] [Info] Total Bins 14600
2024-06-23 10:17:42,561:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:17:42,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:43,585:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:43,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015896 seconds.
2024-06-23 10:17:43,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:43,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:43,615:INFO:[LightGBM] [Info] Total Bins 14345
2024-06-23 10:17:43,615:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:17:43,616:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:44,599:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:44,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015496 seconds.
2024-06-23 10:17:44,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:44,625:INFO:[LightGBM] [Info] Total Bins 14345
2024-06-23 10:17:44,625:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:17:44,625:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:45,647:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:45,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017608 seconds.
2024-06-23 10:17:45,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:45,677:INFO:[LightGBM] [Info] Total Bins 14333
2024-06-23 10:17:45,679:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:17:45,679:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:46,708:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:46,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014589 seconds.
2024-06-23 10:17:46,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:46,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:46,737:INFO:[LightGBM] [Info] Total Bins 14304
2024-06-23 10:17:46,737:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:17:46,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:47,684:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:47,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014360 seconds.
2024-06-23 10:17:47,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:47,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:47,716:INFO:[LightGBM] [Info] Total Bins 14304
2024-06-23 10:17:47,717:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:17:47,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:48,680:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:48,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014993 seconds.
2024-06-23 10:17:48,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:48,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:48,709:INFO:[LightGBM] [Info] Total Bins 14049
2024-06-23 10:17:48,710:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:17:48,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:49,662:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:49,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021300 seconds.
2024-06-23 10:17:49,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:49,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:49,703:INFO:[LightGBM] [Info] Total Bins 14040
2024-06-23 10:17:49,705:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:17:49,706:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:50,754:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:50,790:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020453 seconds.
2024-06-23 10:17:50,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:50,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:50,795:INFO:[LightGBM] [Info] Total Bins 13785
2024-06-23 10:17:50,796:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:17:50,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:51,752:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:51,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015871 seconds.
2024-06-23 10:17:51,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:17:51,777:INFO:[LightGBM] [Info] Total Bins 13749
2024-06-23 10:17:51,781:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:17:51,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:52,764:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:52,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010762 seconds.
2024-06-23 10:17:52,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:52,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:52,786:INFO:[LightGBM] [Info] Total Bins 13494
2024-06-23 10:17:52,786:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:17:52,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:53,711:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:53,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012773 seconds.
2024-06-23 10:17:53,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:53,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:53,742:INFO:[LightGBM] [Info] Total Bins 13409
2024-06-23 10:17:53,745:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:17:53,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:54,737:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:54,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015195 seconds.
2024-06-23 10:17:54,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:54,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:54,768:INFO:[LightGBM] [Info] Total Bins 13154
2024-06-23 10:17:54,768:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:17:54,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:55,787:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:55,809:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010816 seconds.
2024-06-23 10:17:55,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:55,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:55,810:INFO:[LightGBM] [Info] Total Bins 12899
2024-06-23 10:17:55,811:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:17:55,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:56,735:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:56,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010531 seconds.
2024-06-23 10:17:56,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:56,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:56,762:INFO:[LightGBM] [Info] Total Bins 12644
2024-06-23 10:17:56,763:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:17:56,763:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:57,637:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:57,666:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014363 seconds.
2024-06-23 10:17:57,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:57,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:57,666:INFO:[LightGBM] [Info] Total Bins 12389
2024-06-23 10:17:57,668:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:17:57,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:58,556:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:58,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010627 seconds.
2024-06-23 10:17:58,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:58,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:58,580:INFO:[LightGBM] [Info] Total Bins 12134
2024-06-23 10:17:58,580:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:17:58,582:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:17:59,452:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:17:59,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009390 seconds.
2024-06-23 10:17:59,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:17:59,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:17:59,473:INFO:[LightGBM] [Info] Total Bins 11879
2024-06-23 10:17:59,474:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:17:59,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:00,369:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:00,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012486 seconds.
2024-06-23 10:18:00,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:00,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:00,392:INFO:[LightGBM] [Info] Total Bins 11624
2024-06-23 10:18:00,392:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:18:00,396:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:01,266:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:01,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021871 seconds.
2024-06-23 10:18:01,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:01,298:INFO:[LightGBM] [Info] Total Bins 11469
2024-06-23 10:18:01,299:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:18:01,300:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:02,184:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:02,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009488 seconds.
2024-06-23 10:18:02,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:02,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:02,206:INFO:[LightGBM] [Info] Total Bins 11214
2024-06-23 10:18:02,207:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:18:02,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:03,035:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:03,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009188 seconds.
2024-06-23 10:18:03,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:03,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:03,057:INFO:[LightGBM] [Info] Total Bins 10959
2024-06-23 10:18:03,057:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:18:03,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:03,863:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:03,889:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015995 seconds.
2024-06-23 10:18:03,889:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:03,889:INFO:[LightGBM] [Info] Total Bins 10704
2024-06-23 10:18:03,889:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:18:03,889:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:04,735:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:04,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008265 seconds.
2024-06-23 10:18:04,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:04,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:04,757:INFO:[LightGBM] [Info] Total Bins 10449
2024-06-23 10:18:04,757:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:18:04,758:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:05,544:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:05,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009787 seconds.
2024-06-23 10:18:05,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:05,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:05,568:INFO:[LightGBM] [Info] Total Bins 10194
2024-06-23 10:18:05,569:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:18:05,570:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:06,369:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:06,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013735 seconds.
2024-06-23 10:18:06,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:06,394:INFO:[LightGBM] [Info] Total Bins 9939
2024-06-23 10:18:06,394:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:18:06,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:07,194:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:07,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008854 seconds.
2024-06-23 10:18:07,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:07,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:07,217:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:18:07,218:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:18:07,218:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:08,001:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:08,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010723 seconds.
2024-06-23 10:18:08,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:08,019:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:18:08,020:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:18:08,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:08,821:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:08,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012790 seconds.
2024-06-23 10:18:08,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:08,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:08,850:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:18:08,851:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:18:08,851:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:09,599:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:09,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009762 seconds.
2024-06-23 10:18:09,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:09,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:09,619:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:18:09,620:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:18:09,621:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:10,333:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:10,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013078 seconds.
2024-06-23 10:18:10,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:10,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:10,364:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:18:10,365:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:18:10,366:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:11,136:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:11,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012955 seconds.
2024-06-23 10:18:11,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:11,161:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:18:11,161:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:18:11,162:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:12,030:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:12,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012675 seconds.
2024-06-23 10:18:12,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:12,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:12,056:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:18:12,056:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:18:12,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:12,778:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:12,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007888 seconds.
2024-06-23 10:18:12,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:12,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:12,803:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:18:12,804:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:18:12,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:13,679:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:13,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017639 seconds.
2024-06-23 10:18:13,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:13,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:13,708:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:18:13,708:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:18:13,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:14,416:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:14,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008565 seconds.
2024-06-23 10:18:14,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:14,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:14,433:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:18:14,433:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:18:14,434:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:15,114:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:15,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010417 seconds.
2024-06-23 10:18:15,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:15,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:15,133:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:18:15,133:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:18:15,134:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:15,798:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:15,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013090 seconds.
2024-06-23 10:18:15,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:15,819:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:18:15,819:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:18:15,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:16,565:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:16,583:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009928 seconds.
2024-06-23 10:18:16,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:16,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:16,584:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:18:16,584:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:18:16,585:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:17,310:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:17,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005695 seconds.
2024-06-23 10:18:17,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:17,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:17,324:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:18:17,325:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:18:17,325:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:18,016:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:18,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009338 seconds.
2024-06-23 10:18:18,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:18,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:18,034:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:18:18,034:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:18:18,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:18,793:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:18,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014888 seconds.
2024-06-23 10:18:18,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:18,817:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:18:18,817:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:18:18,818:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:19,573:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:19,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006357 seconds.
2024-06-23 10:18:19,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:19,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:19,587:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:18:19,587:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:18:19,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:20,187:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:20,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006709 seconds.
2024-06-23 10:18:20,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:20,196:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:18:20,196:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:18:20,196:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:21,016:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:21,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008755 seconds.
2024-06-23 10:18:21,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:21,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:21,033:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:18:21,033:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:18:21,034:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:21,711:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:21,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004382 seconds.
2024-06-23 10:18:21,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:21,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:21,722:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:18:21,723:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:18:21,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:22,264:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:22,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003994 seconds.
2024-06-23 10:18:22,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:22,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:22,274:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:18:22,275:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:18:22,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:22,796:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:22,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003850 seconds.
2024-06-23 10:18:22,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:22,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:22,808:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:18:22,808:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:18:22,809:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:23,288:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:23,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003633 seconds.
2024-06-23 10:18:23,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:23,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:23,297:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:18:23,297:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:18:23,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:23,790:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:23,800:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004809 seconds.
2024-06-23 10:18:23,800:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:23,800:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:18:23,800:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:18:23,800:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:24,298:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:24,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004123 seconds.
2024-06-23 10:18:24,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:24,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:24,312:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:18:24,312:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:18:24,313:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:24,795:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:24,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003598 seconds.
2024-06-23 10:18:24,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:24,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:24,809:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:18:24,809:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:18:24,810:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:25,288:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:25,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003343 seconds.
2024-06-23 10:18:25,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:25,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:25,295:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:18:25,295:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:18:25,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:25,712:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:25,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003870 seconds.
2024-06-23 10:18:25,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:25,719:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:18:25,719:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:18:25,720:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:26,226:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:26,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003241 seconds.
2024-06-23 10:18:26,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:26,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:26,234:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:18:26,234:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:18:26,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:26,665:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:26,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.
2024-06-23 10:18:26,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:26,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:26,671:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:18:26,671:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:18:26,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:27,079:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:27,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002980 seconds.
2024-06-23 10:18:27,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:27,085:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:18:27,086:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:18:27,086:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:27,489:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:27,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002853 seconds.
2024-06-23 10:18:27,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:27,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:27,495:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:18:27,495:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:18:27,496:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:27,883:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:27,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002466 seconds.
2024-06-23 10:18:27,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:27,887:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:18:27,888:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:18:27,888:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:28,219:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:28,224:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.
2024-06-23 10:18:28,224:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:28,224:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:28,224:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:18:28,225:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:18:28,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:28,550:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:28,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.
2024-06-23 10:18:28,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:28,550:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:18:28,550:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:18:28,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:28,840:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:28,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001535 seconds.
2024-06-23 10:18:28,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:28,840:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:18:28,840:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:18:28,844:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:29,135:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:29,136:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-06-23 10:18:29,136:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:29,136:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:29,136:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:18:29,137:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:18:29,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:29,597:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:29,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015977 seconds.
2024-06-23 10:18:29,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:29,629:INFO:[LightGBM] [Info] Total Bins 14596
2024-06-23 10:18:29,631:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:18:29,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:30,679:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:30,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016260 seconds.
2024-06-23 10:18:30,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:30,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:30,709:INFO:[LightGBM] [Info] Total Bins 14341
2024-06-23 10:18:30,710:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:18:30,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:31,695:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:31,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018422 seconds.
2024-06-23 10:18:31,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:31,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:31,728:INFO:[LightGBM] [Info] Total Bins 14341
2024-06-23 10:18:31,730:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:18:31,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:32,725:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:32,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011306 seconds.
2024-06-23 10:18:32,745:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:32,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:32,753:INFO:[LightGBM] [Info] Total Bins 14086
2024-06-23 10:18:32,753:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:18:32,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:33,766:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:33,799:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015297 seconds.
2024-06-23 10:18:33,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:33,800:INFO:[LightGBM] [Info] Total Bins 14086
2024-06-23 10:18:33,802:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:18:33,803:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:34,809:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:34,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010706 seconds.
2024-06-23 10:18:34,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:34,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:34,838:INFO:[LightGBM] [Info] Total Bins 14074
2024-06-23 10:18:34,840:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:18:34,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:35,794:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:35,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020504 seconds.
2024-06-23 10:18:35,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:35,830:INFO:[LightGBM] [Info] Total Bins 14044
2024-06-23 10:18:35,830:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:18:35,830:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:36,858:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:36,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013471 seconds.
2024-06-23 10:18:36,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:36,887:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:36,887:INFO:[LightGBM] [Info] Total Bins 14035
2024-06-23 10:18:36,887:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:18:36,889:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:38,047:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:38,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011660 seconds.
2024-06-23 10:18:38,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:38,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:38,072:INFO:[LightGBM] [Info] Total Bins 13780
2024-06-23 10:18:38,073:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:18:38,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:39,170:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:39,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013631 seconds.
2024-06-23 10:18:39,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:39,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:39,201:INFO:[LightGBM] [Info] Total Bins 13740
2024-06-23 10:18:39,201:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:18:39,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:40,232:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:40,264:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015573 seconds.
2024-06-23 10:18:40,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:40,265:INFO:[LightGBM] [Info] Total Bins 13655
2024-06-23 10:18:40,266:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:18:40,268:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:41,244:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:41,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012104 seconds.
2024-06-23 10:18:41,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:41,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:41,271:INFO:[LightGBM] [Info] Total Bins 13400
2024-06-23 10:18:41,271:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:18:41,273:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:42,180:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:42,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014587 seconds.
2024-06-23 10:18:42,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:42,206:INFO:[LightGBM] [Info] Total Bins 13145
2024-06-23 10:18:42,207:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:18:42,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:43,167:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:43,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017800 seconds.
2024-06-23 10:18:43,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:43,195:INFO:[LightGBM] [Info] Total Bins 12890
2024-06-23 10:18:43,196:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 51
2024-06-23 10:18:43,197:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:44,154:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:44,182:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014671 seconds.
2024-06-23 10:18:44,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:44,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:44,182:INFO:[LightGBM] [Info] Total Bins 12635
2024-06-23 10:18:44,182:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 50
2024-06-23 10:18:44,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:45,204:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:45,230:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015819 seconds.
2024-06-23 10:18:45,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:45,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:45,230:INFO:[LightGBM] [Info] Total Bins 12380
2024-06-23 10:18:45,230:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 49
2024-06-23 10:18:45,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:46,125:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:46,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013260 seconds.
2024-06-23 10:18:46,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:46,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:46,150:INFO:[LightGBM] [Info] Total Bins 12125
2024-06-23 10:18:46,151:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 48
2024-06-23 10:18:46,152:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:47,035:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:47,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012957 seconds.
2024-06-23 10:18:47,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:47,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:47,069:INFO:[LightGBM] [Info] Total Bins 11972
2024-06-23 10:18:47,071:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 47
2024-06-23 10:18:47,072:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:47,953:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:47,977:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010406 seconds.
2024-06-23 10:18:47,977:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:47,977:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:47,978:INFO:[LightGBM] [Info] Total Bins 11730
2024-06-23 10:18:47,978:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 46
2024-06-23 10:18:47,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:48,851:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:48,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012477 seconds.
2024-06-23 10:18:48,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:48,872:INFO:[LightGBM] [Info] Total Bins 11475
2024-06-23 10:18:48,874:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 45
2024-06-23 10:18:48,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:49,769:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:49,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018252 seconds.
2024-06-23 10:18:49,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:49,798:INFO:[LightGBM] [Info] Total Bins 11220
2024-06-23 10:18:49,798:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 44
2024-06-23 10:18:49,799:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:50,763:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:50,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014256 seconds.
2024-06-23 10:18:50,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:50,787:INFO:[LightGBM] [Info] Total Bins 10965
2024-06-23 10:18:50,787:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 43
2024-06-23 10:18:50,787:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:51,665:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:51,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009155 seconds.
2024-06-23 10:18:51,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:51,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:51,691:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:18:51,693:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 42
2024-06-23 10:18:51,693:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:52,486:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:52,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011246 seconds.
2024-06-23 10:18:52,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:52,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:52,516:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:18:52,517:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 41
2024-06-23 10:18:52,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:53,288:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:53,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013860 seconds.
2024-06-23 10:18:53,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:18:53,316:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:18:53,316:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 40
2024-06-23 10:18:53,317:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:54,220:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:54,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011465 seconds.
2024-06-23 10:18:54,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:54,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:54,245:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:18:54,245:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 39
2024-06-23 10:18:54,245:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:55,091:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:55,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009851 seconds.
2024-06-23 10:18:55,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:55,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:55,118:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:18:55,118:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 38
2024-06-23 10:18:55,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:55,910:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:55,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009942 seconds.
2024-06-23 10:18:55,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:55,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:55,933:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:18:55,933:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 37
2024-06-23 10:18:55,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:56,721:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:56,741:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007802 seconds.
2024-06-23 10:18:56,741:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:56,741:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:56,741:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:18:56,741:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 36
2024-06-23 10:18:56,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:57,494:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:57,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009444 seconds.
2024-06-23 10:18:57,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:57,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:57,517:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:18:57,517:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 35
2024-06-23 10:18:57,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:58,303:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:58,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008781 seconds.
2024-06-23 10:18:58,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:58,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:58,322:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:18:58,323:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 34
2024-06-23 10:18:58,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:59,082:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:59,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010431 seconds.
2024-06-23 10:18:59,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:59,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:59,107:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:18:59,107:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 33
2024-06-23 10:18:59,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:18:59,869:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:18:59,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010968 seconds.
2024-06-23 10:18:59,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:18:59,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:18:59,888:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:18:59,888:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 32
2024-06-23 10:18:59,888:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:00,612:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:00,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008294 seconds.
2024-06-23 10:19:00,629:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:00,629:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:00,629:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:19:00,630:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 31
2024-06-23 10:19:00,630:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:01,431:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:01,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009433 seconds.
2024-06-23 10:19:01,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:01,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:01,453:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:19:01,453:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 30
2024-06-23 10:19:01,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:02,186:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:02,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007562 seconds.
2024-06-23 10:19:02,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:02,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:02,203:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:19:02,203:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 29
2024-06-23 10:19:02,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:02,928:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:02,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006762 seconds.
2024-06-23 10:19:02,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:02,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:02,941:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:19:02,941:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 28
2024-06-23 10:19:02,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:03,567:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:03,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007867 seconds.
2024-06-23 10:19:03,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:03,581:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:19:03,582:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 27
2024-06-23 10:19:03,582:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:04,241:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:04,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005819 seconds.
2024-06-23 10:19:04,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:04,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:04,258:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:19:04,259:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 26
2024-06-23 10:19:04,260:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:04,882:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:04,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006479 seconds.
2024-06-23 10:19:04,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:04,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:04,891:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:19:04,891:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 25
2024-06-23 10:19:04,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:05,543:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:05,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005697 seconds.
2024-06-23 10:19:05,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:05,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:05,565:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:19:05,565:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 24
2024-06-23 10:19:05,566:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:06,159:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:06,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005008 seconds.
2024-06-23 10:19:06,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:06,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:06,172:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:19:06,172:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 23
2024-06-23 10:19:06,173:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:06,740:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:06,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005288 seconds.
2024-06-23 10:19:06,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:06,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:06,752:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:19:06,753:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 22
2024-06-23 10:19:06,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:07,312:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:07,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004733 seconds.
2024-06-23 10:19:07,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:07,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:07,323:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:19:07,324:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 21
2024-06-23 10:19:07,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:07,958:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:07,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.
2024-06-23 10:19:07,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:07,970:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:19:07,970:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 20
2024-06-23 10:19:07,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:08,593:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:08,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
2024-06-23 10:19:08,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:08,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:08,608:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:19:08,608:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 19
2024-06-23 10:19:08,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:09,187:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:09,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004190 seconds.
2024-06-23 10:19:09,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:09,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:09,192:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:19:09,200:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 18
2024-06-23 10:19:09,200:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:09,729:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:09,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004374 seconds.
2024-06-23 10:19:09,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:09,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:09,737:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:19:09,738:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 17
2024-06-23 10:19:09,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:10,249:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:10,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004873 seconds.
2024-06-23 10:19:10,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:10,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:10,263:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:19:10,264:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 16
2024-06-23 10:19:10,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:10,796:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:10,812:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006402 seconds.
2024-06-23 10:19:10,812:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:10,812:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:10,812:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:19:10,813:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 15
2024-06-23 10:19:10,813:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:11,311:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:11,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003751 seconds.
2024-06-23 10:19:11,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:11,320:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:11,320:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:19:11,321:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 14
2024-06-23 10:19:11,321:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:11,806:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:11,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003079 seconds.
2024-06-23 10:19:11,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:11,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:11,814:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:19:11,815:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 13
2024-06-23 10:19:11,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:12,316:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:12,326:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006910 seconds.
2024-06-23 10:19:12,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:12,326:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:19:12,327:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 12
2024-06-23 10:19:12,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:12,792:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:12,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.
2024-06-23 10:19:12,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:12,805:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:19:12,805:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 11
2024-06-23 10:19:12,806:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:13,237:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:13,239:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003657 seconds.
2024-06-23 10:19:13,239:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:13,247:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:19:13,247:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 10
2024-06-23 10:19:13,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:13,696:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:13,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002658 seconds.
2024-06-23 10:19:13,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:13,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:13,710:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:19:13,710:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 9
2024-06-23 10:19:13,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:14,078:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:14,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002799 seconds.
2024-06-23 10:19:14,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:14,083:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:19:14,084:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 8
2024-06-23 10:19:14,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:14,449:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:14,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.
2024-06-23 10:19:14,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:14,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:14,449:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:19:14,449:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 7
2024-06-23 10:19:14,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:14,795:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:14,803:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003255 seconds.
2024-06-23 10:19:14,803:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:14,803:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:19:14,803:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 6
2024-06-23 10:19:14,803:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:15,151:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:15,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003168 seconds.
2024-06-23 10:19:15,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:15,157:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:19:15,157:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 5
2024-06-23 10:19:15,158:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:15,477:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:15,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001356 seconds.
2024-06-23 10:19:15,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:15,480:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:19:15,480:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 4
2024-06-23 10:19:15,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:15,753:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:15,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001366 seconds.
2024-06-23 10:19:15,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:15,756:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:19:15,757:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 3
2024-06-23 10:19:15,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:16,014:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:19:16,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.
2024-06-23 10:19:16,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:16,015:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:19:16,016:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 2
2024-06-23 10:19:16,016:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:19:16,446:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:16,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014819 seconds.
2024-06-23 10:19:16,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:16,479:INFO:[LightGBM] [Info] Total Bins 14616
2024-06-23 10:19:16,481:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:19:16,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:16,483:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:17,500:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:17,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012162 seconds.
2024-06-23 10:19:17,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:17,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:17,529:INFO:[LightGBM] [Info] Total Bins 14361
2024-06-23 10:19:17,530:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:19:17,531:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:17,532:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:18,496:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:18,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015970 seconds.
2024-06-23 10:19:18,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:18,529:INFO:[LightGBM] [Info] Total Bins 14331
2024-06-23 10:19:18,530:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:19:18,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:18,532:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:19,529:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:19,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012231 seconds.
2024-06-23 10:19:19,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:19,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:19,560:INFO:[LightGBM] [Info] Total Bins 14076
2024-06-23 10:19:19,561:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:19:19,562:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:19,563:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:20,596:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:20,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020299 seconds.
2024-06-23 10:19:20,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:20,631:INFO:[LightGBM] [Info] Total Bins 14076
2024-06-23 10:19:20,632:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:19:20,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:20,633:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:21,625:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:21,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013998 seconds.
2024-06-23 10:19:21,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:21,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:21,652:INFO:[LightGBM] [Info] Total Bins 14076
2024-06-23 10:19:21,652:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:19:21,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:21,652:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:22,608:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:22,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024860 seconds.
2024-06-23 10:19:22,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:22,650:INFO:[LightGBM] [Info] Total Bins 14064
2024-06-23 10:19:22,658:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:19:22,660:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:22,660:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:23,646:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:23,670:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010675 seconds.
2024-06-23 10:19:23,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:23,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:23,671:INFO:[LightGBM] [Info] Total Bins 13809
2024-06-23 10:19:23,672:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:19:23,673:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:23,673:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:24,600:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:24,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018809 seconds.
2024-06-23 10:19:24,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:24,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:24,635:INFO:[LightGBM] [Info] Total Bins 13770
2024-06-23 10:19:24,635:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:19:24,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:24,637:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:25,571:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:25,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011638 seconds.
2024-06-23 10:19:25,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:25,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:25,595:INFO:[LightGBM] [Info] Total Bins 13669
2024-06-23 10:19:25,596:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:19:25,597:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:25,597:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:26,533:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:26,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022104 seconds.
2024-06-23 10:19:26,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:26,574:INFO:[LightGBM] [Info] Total Bins 13661
2024-06-23 10:19:26,576:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:19:26,576:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:26,576:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:27,552:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:27,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011073 seconds.
2024-06-23 10:19:27,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:27,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:27,576:INFO:[LightGBM] [Info] Total Bins 13406
2024-06-23 10:19:27,576:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:19:27,579:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:27,579:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:28,479:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:28,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012113 seconds.
2024-06-23 10:19:28,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:28,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:28,503:INFO:[LightGBM] [Info] Total Bins 13151
2024-06-23 10:19:28,504:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:19:28,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:28,505:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:29,427:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:29,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011287 seconds.
2024-06-23 10:19:29,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:29,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:29,455:INFO:[LightGBM] [Info] Total Bins 12995
2024-06-23 10:19:29,455:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:19:29,456:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:29,457:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:30,359:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:30,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012034 seconds.
2024-06-23 10:19:30,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:30,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:30,389:INFO:[LightGBM] [Info] Total Bins 12740
2024-06-23 10:19:30,389:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:19:30,391:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:30,391:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:31,279:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:31,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010769 seconds.
2024-06-23 10:19:31,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:31,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:31,303:INFO:[LightGBM] [Info] Total Bins 12485
2024-06-23 10:19:31,304:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:19:31,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:31,305:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:32,178:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:32,205:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010113 seconds.
2024-06-23 10:19:32,206:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:32,206:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:32,206:INFO:[LightGBM] [Info] Total Bins 12230
2024-06-23 10:19:32,207:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:19:32,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:32,208:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:33,080:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:33,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015071 seconds.
2024-06-23 10:19:33,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:33,107:INFO:[LightGBM] [Info] Total Bins 11975
2024-06-23 10:19:33,108:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:19:33,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:33,110:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:33,999:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:34,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009525 seconds.
2024-06-23 10:19:34,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:34,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:34,022:INFO:[LightGBM] [Info] Total Bins 11720
2024-06-23 10:19:34,023:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:19:34,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:34,024:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:34,873:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:34,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018280 seconds.
2024-06-23 10:19:34,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:34,904:INFO:[LightGBM] [Info] Total Bins 11465
2024-06-23 10:19:34,905:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:19:34,906:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:34,906:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:35,771:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:35,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010511 seconds.
2024-06-23 10:19:35,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:35,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:35,794:INFO:[LightGBM] [Info] Total Bins 11210
2024-06-23 10:19:35,796:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:19:35,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:35,797:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:36,639:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:36,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013729 seconds.
2024-06-23 10:19:36,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:36,663:INFO:[LightGBM] [Info] Total Bins 10955
2024-06-23 10:19:36,665:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:19:36,666:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:36,666:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:37,517:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:37,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010414 seconds.
2024-06-23 10:19:37,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:37,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:37,543:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:19:37,543:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:19:37,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:37,545:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:38,451:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:38,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009655 seconds.
2024-06-23 10:19:38,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:38,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:38,473:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:19:38,474:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:19:38,474:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:38,475:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:39,324:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:39,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011221 seconds.
2024-06-23 10:19:39,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:39,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:39,349:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:19:39,350:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:19:39,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:39,351:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:40,224:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:40,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008724 seconds.
2024-06-23 10:19:40,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:40,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:40,240:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:19:40,240:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:19:40,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:40,240:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:41,033:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:41,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012992 seconds.
2024-06-23 10:19:41,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:41,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:41,067:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:19:41,068:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:19:41,068:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:41,069:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:41,826:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:41,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014812 seconds.
2024-06-23 10:19:41,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:41,851:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:19:41,852:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:19:41,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:41,854:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:42,631:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:42,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009697 seconds.
2024-06-23 10:19:42,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:42,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:42,653:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:19:42,654:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:19:42,655:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:42,655:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:43,410:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:43,429:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011692 seconds.
2024-06-23 10:19:43,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:43,430:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:19:43,431:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:19:43,431:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:43,431:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:44,285:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:44,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010817 seconds.
2024-06-23 10:19:44,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:44,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:44,313:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:19:44,314:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:19:44,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:44,316:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:45,088:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:45,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007929 seconds.
2024-06-23 10:19:45,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:45,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:45,112:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:19:45,113:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:19:45,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:45,114:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:45,934:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:45,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009713 seconds.
2024-06-23 10:19:45,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:45,955:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:19:45,956:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:19:45,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:45,957:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:46,947:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:46,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010417 seconds.
2024-06-23 10:19:46,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:46,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:46,969:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:19:46,969:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:19:46,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:46,970:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:47,788:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:47,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009472 seconds.
2024-06-23 10:19:47,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:47,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:47,807:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:19:47,808:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:19:47,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:47,809:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:48,794:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:48,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019893 seconds.
2024-06-23 10:19:48,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:48,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:48,829:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:19:48,830:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:19:48,830:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:48,831:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:49,605:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:49,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006815 seconds.
2024-06-23 10:19:49,624:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:49,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:49,624:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:19:49,625:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:19:49,625:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:49,626:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:50,363:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:50,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007527 seconds.
2024-06-23 10:19:50,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:50,380:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:19:50,380:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:19:50,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:50,381:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:51,084:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:51,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006094 seconds.
2024-06-23 10:19:51,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:51,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:51,103:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:19:51,103:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:19:51,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:51,104:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:51,776:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:51,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011879 seconds.
2024-06-23 10:19:51,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:51,794:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:19:51,794:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:19:51,795:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:51,795:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:52,431:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:52,440:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007058 seconds.
2024-06-23 10:19:52,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:52,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:52,440:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:19:52,440:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:19:52,449:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:52,449:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:53,045:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:53,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005336 seconds.
2024-06-23 10:19:53,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:53,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:53,059:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:19:53,059:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:19:53,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:53,060:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:53,635:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:53,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006954 seconds.
2024-06-23 10:19:53,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:53,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:53,645:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:19:53,645:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:19:53,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:53,645:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:54,202:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:54,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005033 seconds.
2024-06-23 10:19:54,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:54,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:54,216:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:19:54,216:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:19:54,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:54,217:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:54,756:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:54,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004967 seconds.
2024-06-23 10:19:54,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:54,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:54,767:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:19:54,768:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:19:54,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:54,769:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:55,303:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:55,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004334 seconds.
2024-06-23 10:19:55,317:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:55,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:55,319:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:19:55,319:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:19:55,319:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:55,319:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:55,832:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:55,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005882 seconds.
2024-06-23 10:19:55,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:55,844:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:19:55,844:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:19:55,844:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:55,844:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:56,575:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:56,588:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005408 seconds.
2024-06-23 10:19:56,588:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:56,588:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:56,588:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:19:56,588:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:19:56,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:56,588:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:57,183:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:57,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006734 seconds.
2024-06-23 10:19:57,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:19:57,194:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:19:57,194:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:19:57,194:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:57,194:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:57,766:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:57,774:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004006 seconds.
2024-06-23 10:19:57,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:57,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:57,775:INFO:[LightGBM] [Info] Total Bins 3825
2024-06-23 10:19:57,775:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 15
2024-06-23 10:19:57,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:57,776:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:58,298:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:58,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003592 seconds.
2024-06-23 10:19:58,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:58,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:58,311:INFO:[LightGBM] [Info] Total Bins 3570
2024-06-23 10:19:58,312:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 14
2024-06-23 10:19:58,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:58,312:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:58,920:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:58,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003444 seconds.
2024-06-23 10:19:58,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:58,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:58,928:INFO:[LightGBM] [Info] Total Bins 3315
2024-06-23 10:19:58,928:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 13
2024-06-23 10:19:58,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:58,929:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:19:59,822:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:19:59,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003658 seconds.
2024-06-23 10:19:59,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:19:59,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:19:59,831:INFO:[LightGBM] [Info] Total Bins 3060
2024-06-23 10:19:59,831:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 12
2024-06-23 10:19:59,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:19:59,832:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:00,378:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:00,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002869 seconds.
2024-06-23 10:20:00,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:00,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:00,385:INFO:[LightGBM] [Info] Total Bins 2805
2024-06-23 10:20:00,385:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 11
2024-06-23 10:20:00,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:00,386:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:00,795:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:00,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002814 seconds.
2024-06-23 10:20:00,805:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:00,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:00,806:INFO:[LightGBM] [Info] Total Bins 2550
2024-06-23 10:20:00,806:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 10
2024-06-23 10:20:00,807:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:00,807:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:01,241:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:01,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002007 seconds.
2024-06-23 10:20:01,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:01,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:01,249:INFO:[LightGBM] [Info] Total Bins 2295
2024-06-23 10:20:01,249:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 9
2024-06-23 10:20:01,249:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:01,249:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:01,608:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:01,612:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.
2024-06-23 10:20:01,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:01,613:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:01,613:INFO:[LightGBM] [Info] Total Bins 2040
2024-06-23 10:20:01,613:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 8
2024-06-23 10:20:01,614:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:01,614:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:01,960:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:01,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002548 seconds.
2024-06-23 10:20:01,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:01,964:INFO:[LightGBM] [Info] Total Bins 1785
2024-06-23 10:20:01,965:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 7
2024-06-23 10:20:01,965:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:01,965:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:02,296:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:02,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.
2024-06-23 10:20:02,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:02,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:02,300:INFO:[LightGBM] [Info] Total Bins 1530
2024-06-23 10:20:02,300:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 6
2024-06-23 10:20:02,300:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:02,300:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:02,633:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:02,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002928 seconds.
2024-06-23 10:20:02,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:02,637:INFO:[LightGBM] [Info] Total Bins 1275
2024-06-23 10:20:02,637:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 5
2024-06-23 10:20:02,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:02,638:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:02,950:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:02,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.
2024-06-23 10:20:02,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:02,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:02,956:INFO:[LightGBM] [Info] Total Bins 1020
2024-06-23 10:20:02,956:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 4
2024-06-23 10:20:02,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:02,957:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:03,238:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:03,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-06-23 10:20:03,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:03,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:03,242:INFO:[LightGBM] [Info] Total Bins 765
2024-06-23 10:20:03,242:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 3
2024-06-23 10:20:03,242:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:03,242:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:03,516:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:03,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-06-23 10:20:03,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:03,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:03,518:INFO:[LightGBM] [Info] Total Bins 510
2024-06-23 10:20:03,518:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 2
2024-06-23 10:20:03,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:03,519:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:03,957:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:03,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012789 seconds.
2024-06-23 10:20:03,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:03,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:03,985:INFO:[LightGBM] [Info] Total Bins 14606
2024-06-23 10:20:03,987:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 62
2024-06-23 10:20:03,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:03,988:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:05,083:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:05,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017538 seconds.
2024-06-23 10:20:05,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:05,118:INFO:[LightGBM] [Info] Total Bins 14351
2024-06-23 10:20:05,118:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:20:05,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:05,119:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:06,362:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:06,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015722 seconds.
2024-06-23 10:20:06,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:06,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:06,401:INFO:[LightGBM] [Info] Total Bins 14351
2024-06-23 10:20:06,401:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 61
2024-06-23 10:20:06,401:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:06,401:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:07,415:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:07,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016962 seconds.
2024-06-23 10:20:07,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:07,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:07,449:INFO:[LightGBM] [Info] Total Bins 14339
2024-06-23 10:20:07,453:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 60
2024-06-23 10:20:07,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:07,453:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:08,482:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:08,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012061 seconds.
2024-06-23 10:20:08,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:08,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:08,509:INFO:[LightGBM] [Info] Total Bins 14310
2024-06-23 10:20:08,510:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:20:08,511:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:08,511:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:09,562:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:09,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023381 seconds.
2024-06-23 10:20:09,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:09,594:INFO:[LightGBM] [Info] Total Bins 14310
2024-06-23 10:20:09,594:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 59
2024-06-23 10:20:09,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:09,594:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:10,702:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:10,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012380 seconds.
2024-06-23 10:20:10,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:10,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:10,733:INFO:[LightGBM] [Info] Total Bins 14055
2024-06-23 10:20:10,734:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 58
2024-06-23 10:20:10,735:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:10,735:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:11,939:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:12,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033763 seconds.
2024-06-23 10:20:12,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:12,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:12,005:INFO:[LightGBM] [Info] Total Bins 13800
2024-06-23 10:20:12,008:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 57
2024-06-23 10:20:12,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:12,013:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:13,103:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:13,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012016 seconds.
2024-06-23 10:20:13,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:13,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:13,129:INFO:[LightGBM] [Info] Total Bins 13764
2024-06-23 10:20:13,129:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 56
2024-06-23 10:20:13,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:13,129:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:14,198:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:14,227:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017034 seconds.
2024-06-23 10:20:14,227:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:14,227:INFO:[LightGBM] [Info] Total Bins 13661
2024-06-23 10:20:14,227:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 55
2024-06-23 10:20:14,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:14,227:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:15,371:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:15,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011484 seconds.
2024-06-23 10:20:15,396:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:15,396:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:15,396:INFO:[LightGBM] [Info] Total Bins 13406
2024-06-23 10:20:15,398:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 54
2024-06-23 10:20:15,398:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:15,398:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:16,444:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:16,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019373 seconds.
2024-06-23 10:20:16,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:16,476:INFO:[LightGBM] [Info] Total Bins 13398
2024-06-23 10:20:16,476:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 53
2024-06-23 10:20:16,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:16,480:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:17,719:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:17,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013002 seconds.
2024-06-23 10:20:17,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:17,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:17,749:INFO:[LightGBM] [Info] Total Bins 13143
2024-06-23 10:20:17,749:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 52
2024-06-23 10:20:17,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:17,750:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:18,754:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:18,785:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014580 seconds.
2024-06-23 10:20:18,785:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:18,785:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:18,789:INFO:[LightGBM] [Info] Total Bins 12888
2024-06-23 10:20:18,789:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 51
2024-06-23 10:20:18,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:18,789:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:19,748:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:19,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010491 seconds.
2024-06-23 10:20:19,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:19,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:19,772:INFO:[LightGBM] [Info] Total Bins 12633
2024-06-23 10:20:19,773:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 50
2024-06-23 10:20:19,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:19,774:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:20,701:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:20,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016780 seconds.
2024-06-23 10:20:20,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:20,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:20,731:INFO:[LightGBM] [Info] Total Bins 12378
2024-06-23 10:20:20,731:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 49
2024-06-23 10:20:20,735:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:20,735:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:21,640:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:21,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013799 seconds.
2024-06-23 10:20:21,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:21,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:21,673:INFO:[LightGBM] [Info] Total Bins 12231
2024-06-23 10:20:21,674:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 48
2024-06-23 10:20:21,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:21,675:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:22,626:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:22,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012670 seconds.
2024-06-23 10:20:22,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:22,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:22,650:INFO:[LightGBM] [Info] Total Bins 11976
2024-06-23 10:20:22,651:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 47
2024-06-23 10:20:22,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:22,652:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:23,817:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:23,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009952 seconds.
2024-06-23 10:20:23,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:23,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:23,836:INFO:[LightGBM] [Info] Total Bins 11721
2024-06-23 10:20:23,840:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 46
2024-06-23 10:20:23,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:23,840:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:24,959:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:24,989:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016924 seconds.
2024-06-23 10:20:24,989:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:24,993:INFO:[LightGBM] [Info] Total Bins 11466
2024-06-23 10:20:24,993:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 45
2024-06-23 10:20:24,996:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:24,997:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:25,884:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:25,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015241 seconds.
2024-06-23 10:20:25,912:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:25,912:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:25,913:INFO:[LightGBM] [Info] Total Bins 11211
2024-06-23 10:20:25,914:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 44
2024-06-23 10:20:25,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:25,916:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:26,813:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:26,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010093 seconds.
2024-06-23 10:20:26,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:26,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:26,841:INFO:[LightGBM] [Info] Total Bins 10956
2024-06-23 10:20:26,841:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 43
2024-06-23 10:20:26,841:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:26,841:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:27,742:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:27,764:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012415 seconds.
2024-06-23 10:20:27,764:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:27,765:INFO:[LightGBM] [Info] Total Bins 10710
2024-06-23 10:20:27,765:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 42
2024-06-23 10:20:27,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:27,766:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:28,708:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:28,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013319 seconds.
2024-06-23 10:20:28,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:28,734:INFO:[LightGBM] [Info] Total Bins 10455
2024-06-23 10:20:28,738:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 41
2024-06-23 10:20:28,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:28,738:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:29,651:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:29,672:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009293 seconds.
2024-06-23 10:20:29,672:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:29,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:29,673:INFO:[LightGBM] [Info] Total Bins 10200
2024-06-23 10:20:29,674:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 40
2024-06-23 10:20:29,674:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:29,675:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:30,508:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:30,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008830 seconds.
2024-06-23 10:20:30,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:30,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:30,531:INFO:[LightGBM] [Info] Total Bins 9945
2024-06-23 10:20:30,531:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 39
2024-06-23 10:20:30,531:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:30,531:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:31,362:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:31,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012739 seconds.
2024-06-23 10:20:31,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:31,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:31,385:INFO:[LightGBM] [Info] Total Bins 9690
2024-06-23 10:20:31,385:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 38
2024-06-23 10:20:31,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:31,385:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:32,138:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:32,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009041 seconds.
2024-06-23 10:20:32,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:32,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:32,162:INFO:[LightGBM] [Info] Total Bins 9435
2024-06-23 10:20:32,163:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 37
2024-06-23 10:20:32,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:32,165:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:32,910:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:32,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007718 seconds.
2024-06-23 10:20:32,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:32,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:32,931:INFO:[LightGBM] [Info] Total Bins 9180
2024-06-23 10:20:32,931:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 36
2024-06-23 10:20:32,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:32,933:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:33,730:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:33,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009613 seconds.
2024-06-23 10:20:33,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:33,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:33,750:INFO:[LightGBM] [Info] Total Bins 8925
2024-06-23 10:20:33,750:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 35
2024-06-23 10:20:33,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:33,751:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:34,526:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:34,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010610 seconds.
2024-06-23 10:20:34,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:34,550:INFO:[LightGBM] [Info] Total Bins 8670
2024-06-23 10:20:34,551:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 34
2024-06-23 10:20:34,552:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:34,553:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:35,533:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:35,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008018 seconds.
2024-06-23 10:20:35,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:35,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:35,558:INFO:[LightGBM] [Info] Total Bins 8415
2024-06-23 10:20:35,558:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 33
2024-06-23 10:20:35,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:35,559:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:36,433:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:36,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009187 seconds.
2024-06-23 10:20:36,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:36,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:36,461:INFO:[LightGBM] [Info] Total Bins 8160
2024-06-23 10:20:36,461:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 32
2024-06-23 10:20:36,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:36,462:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:37,368:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:37,390:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010002 seconds.
2024-06-23 10:20:37,390:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:37,390:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:37,390:INFO:[LightGBM] [Info] Total Bins 7905
2024-06-23 10:20:37,392:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 31
2024-06-23 10:20:37,392:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:37,392:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:38,127:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:38,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006745 seconds.
2024-06-23 10:20:38,145:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:38,145:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:38,145:INFO:[LightGBM] [Info] Total Bins 7650
2024-06-23 10:20:38,145:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 30
2024-06-23 10:20:38,145:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:38,145:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:38,878:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:38,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017129 seconds.
2024-06-23 10:20:38,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:38,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:38,908:INFO:[LightGBM] [Info] Total Bins 7395
2024-06-23 10:20:38,908:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 29
2024-06-23 10:20:38,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:38,909:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:39,685:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:39,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013718 seconds.
2024-06-23 10:20:39,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:39,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:39,714:INFO:[LightGBM] [Info] Total Bins 7140
2024-06-23 10:20:39,714:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 28
2024-06-23 10:20:39,715:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:39,715:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:40,484:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:40,498:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007331 seconds.
2024-06-23 10:20:40,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:40,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:40,501:INFO:[LightGBM] [Info] Total Bins 6885
2024-06-23 10:20:40,501:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 27
2024-06-23 10:20:40,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:40,503:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:41,220:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:41,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006488 seconds.
2024-06-23 10:20:41,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:41,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:41,238:INFO:[LightGBM] [Info] Total Bins 6630
2024-06-23 10:20:41,238:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 26
2024-06-23 10:20:41,238:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:41,238:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:42,043:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:42,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005378 seconds.
2024-06-23 10:20:42,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:42,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:42,057:INFO:[LightGBM] [Info] Total Bins 6375
2024-06-23 10:20:42,057:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 25
2024-06-23 10:20:42,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:42,058:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:42,725:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:42,735:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007253 seconds.
2024-06-23 10:20:42,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:42,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:42,735:INFO:[LightGBM] [Info] Total Bins 6120
2024-06-23 10:20:42,743:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 24
2024-06-23 10:20:42,743:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:42,743:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:43,344:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:43,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007095 seconds.
2024-06-23 10:20:43,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:43,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:43,365:INFO:[LightGBM] [Info] Total Bins 5865
2024-06-23 10:20:43,365:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 23
2024-06-23 10:20:43,366:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:43,366:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:44,224:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:44,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006911 seconds.
2024-06-23 10:20:44,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:44,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:44,241:INFO:[LightGBM] [Info] Total Bins 5610
2024-06-23 10:20:44,241:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 22
2024-06-23 10:20:44,242:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:44,242:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:44,865:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:44,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005201 seconds.
2024-06-23 10:20:44,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:44,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:44,877:INFO:[LightGBM] [Info] Total Bins 5355
2024-06-23 10:20:44,877:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 21
2024-06-23 10:20:44,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:44,878:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:45,447:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:45,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005351 seconds.
2024-06-23 10:20:45,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:45,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:45,462:INFO:[LightGBM] [Info] Total Bins 5100
2024-06-23 10:20:45,462:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 20
2024-06-23 10:20:45,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:45,464:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:46,084:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:46,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005581 seconds.
2024-06-23 10:20:46,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:46,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:46,097:INFO:[LightGBM] [Info] Total Bins 4845
2024-06-23 10:20:46,097:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 19
2024-06-23 10:20:46,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:46,098:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:46,619:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:46,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003914 seconds.
2024-06-23 10:20:46,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:46,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:46,630:INFO:[LightGBM] [Info] Total Bins 4590
2024-06-23 10:20:46,631:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 18
2024-06-23 10:20:46,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:46,632:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:47,148:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:47,159:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007409 seconds.
2024-06-23 10:20:47,159:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:20:47,159:INFO:[LightGBM] [Info] Total Bins 4335
2024-06-23 10:20:47,159:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 17
2024-06-23 10:20:47,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:47,159:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:47,741:INFO:[LightGBM] [Info] Number of positive: 18421, number of negative: 18420
2024-06-23 10:20:47,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.
2024-06-23 10:20:47,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:20:47,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:20:47,751:INFO:[LightGBM] [Info] Total Bins 4080
2024-06-23 10:20:47,752:INFO:[LightGBM] [Info] Number of data points in the train set: 36841, number of used features: 16
2024-06-23 10:20:47,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054
2024-06-23 10:20:47,753:INFO:[LightGBM] [Info] Start training from score 0.000054
2024-06-23 10:20:49,121:INFO:Initializing evaluate_model()
2024-06-23 10:20:49,121:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:20:49,151:INFO:Initializing plot_model()
2024-06-23 10:20:49,151:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:20:49,151:INFO:Checking exceptions
2024-06-23 10:20:49,157:INFO:Preloading libraries
2024-06-23 10:20:49,181:INFO:Copying training dataset
2024-06-23 10:20:49,181:INFO:Plot type: pipeline
2024-06-23 10:20:49,443:INFO:Visual Rendered Successfully
2024-06-23 10:20:49,620:INFO:plot_model() successfully completed......................................
2024-06-23 10:20:49,638:INFO:Initializing evaluate_model()
2024-06-23 10:20:49,638:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:20:49,657:INFO:Initializing plot_model()
2024-06-23 10:20:49,657:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:20:49,658:INFO:Checking exceptions
2024-06-23 10:20:49,666:INFO:Preloading libraries
2024-06-23 10:20:49,681:INFO:Copying training dataset
2024-06-23 10:20:49,681:INFO:Plot type: pipeline
2024-06-23 10:20:49,920:INFO:Visual Rendered Successfully
2024-06-23 10:20:50,071:INFO:plot_model() successfully completed......................................
2024-06-23 10:20:50,106:INFO:Initializing evaluate_model()
2024-06-23 10:20:50,107:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:20:50,130:INFO:Initializing plot_model()
2024-06-23 10:20:50,131:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:20:50,131:INFO:Checking exceptions
2024-06-23 10:20:50,149:INFO:Preloading libraries
2024-06-23 10:20:50,251:INFO:Copying training dataset
2024-06-23 10:20:50,251:INFO:Plot type: pipeline
2024-06-23 10:20:50,503:INFO:Visual Rendered Successfully
2024-06-23 10:20:50,642:INFO:plot_model() successfully completed......................................
2024-06-23 10:21:16,393:INFO:Initializing plot_model()
2024-06-23 10:21:16,395:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:21:16,395:INFO:Checking exceptions
2024-06-23 10:21:16,406:INFO:Preloading libraries
2024-06-23 10:21:16,426:INFO:Copying training dataset
2024-06-23 10:21:16,427:INFO:Plot type: auc
2024-06-23 10:21:16,796:INFO:Fitting Model
2024-06-23 10:21:16,796:INFO:Scoring test/hold-out set
2024-06-23 10:21:17,174:INFO:Visual Rendered Successfully
2024-06-23 10:21:17,346:INFO:plot_model() successfully completed......................................
2024-06-23 10:21:34,425:INFO:Initializing plot_model()
2024-06-23 10:21:34,425:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:21:34,426:INFO:Checking exceptions
2024-06-23 10:21:34,435:INFO:Preloading libraries
2024-06-23 10:21:34,456:INFO:Copying training dataset
2024-06-23 10:21:34,456:INFO:Plot type: feature
2024-06-23 10:21:34,457:WARNING:No coef_ found. Trying feature_importances_
2024-06-23 10:21:34,819:INFO:Visual Rendered Successfully
2024-06-23 10:21:34,967:INFO:plot_model() successfully completed......................................
2024-06-23 10:26:29,841:INFO:Initializing plot_model()
2024-06-23 10:26:29,842:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:26:29,842:INFO:Checking exceptions
2024-06-23 10:26:29,854:INFO:Preloading libraries
2024-06-23 10:26:29,872:INFO:Copying training dataset
2024-06-23 10:26:29,872:INFO:Plot type: pipeline
2024-06-23 10:26:30,196:INFO:Visual Rendered Successfully
2024-06-23 10:26:30,369:INFO:plot_model() successfully completed......................................
2024-06-23 10:26:45,785:INFO:Initializing plot_model()
2024-06-23 10:26:45,785:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:26:45,785:INFO:Checking exceptions
2024-06-23 10:26:45,795:INFO:Preloading libraries
2024-06-23 10:26:45,816:INFO:Copying training dataset
2024-06-23 10:26:45,816:INFO:Plot type: auc
2024-06-23 10:26:46,242:INFO:Fitting Model
2024-06-23 10:26:46,244:INFO:Scoring test/hold-out set
2024-06-23 10:26:46,602:INFO:Visual Rendered Successfully
2024-06-23 10:26:46,780:INFO:plot_model() successfully completed......................................
2024-06-23 10:26:56,292:INFO:Initializing plot_model()
2024-06-23 10:26:56,292:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:26:56,293:INFO:Checking exceptions
2024-06-23 10:26:56,306:INFO:Preloading libraries
2024-06-23 10:26:56,342:INFO:Copying training dataset
2024-06-23 10:26:56,342:INFO:Plot type: rfe
2024-06-23 10:26:56,702:INFO:Fitting Model
2024-06-23 10:26:56,884:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:26:56,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015167 seconds.
2024-06-23 10:26:56,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:26:56,922:INFO:[LightGBM] [Info] Total Bins 14647
2024-06-23 10:26:56,924:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 62
2024-06-23 10:26:56,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:26:57,863:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:26:57,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018500 seconds.
2024-06-23 10:26:57,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:26:57,904:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:26:57,906:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:26:57,906:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:26:58,885:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:26:58,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015367 seconds.
2024-06-23 10:26:58,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:26:58,915:INFO:[LightGBM] [Info] Total Bins 14638
2024-06-23 10:26:58,915:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 61
2024-06-23 10:26:58,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:26:59,976:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:26:59,996:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013917 seconds.
2024-06-23 10:26:59,996:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:26:59,996:INFO:[LightGBM] [Info] Total Bins 14383
2024-06-23 10:27:00,004:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 60
2024-06-23 10:27:00,004:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:01,001:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:01,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014225 seconds.
2024-06-23 10:27:01,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:27:01,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:27:01,032:INFO:[LightGBM] [Info] Total Bins 14128
2024-06-23 10:27:01,032:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 59
2024-06-23 10:27:01,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:02,158:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:02,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014044 seconds.
2024-06-23 10:27:02,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:27:02,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:27:02,180:INFO:[LightGBM] [Info] Total Bins 14085
2024-06-23 10:27:02,180:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 58
2024-06-23 10:27:02,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:03,319:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:03,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018757 seconds.
2024-06-23 10:27:03,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:27:03,353:INFO:[LightGBM] [Info] Total Bins 14072
2024-06-23 10:27:03,353:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 57
2024-06-23 10:27:03,353:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:04,590:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:04,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014635 seconds.
2024-06-23 10:27:04,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:27:04,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:27:04,621:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:27:04,622:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:27:04,623:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:05,749:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:05,774:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011541 seconds.
2024-06-23 10:27:05,774:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:27:05,774:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:27:05,774:INFO:[LightGBM] [Info] Total Bins 14038
2024-06-23 10:27:05,774:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 56
2024-06-23 10:27:05,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:06,653:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:06,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011940 seconds.
2024-06-23 10:27:06,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:27:06,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:27:06,683:INFO:[LightGBM] [Info] Total Bins 13783
2024-06-23 10:27:06,683:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 55
2024-06-23 10:27:06,683:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:07,542:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:07,562:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010248 seconds.
2024-06-23 10:27:07,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-23 10:27:07,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-23 10:27:07,562:INFO:[LightGBM] [Info] Total Bins 13528
2024-06-23 10:27:07,562:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 54
2024-06-23 10:27:07,570:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:08,529:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:08,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018883 seconds.
2024-06-23 10:27:08,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:27:08,559:INFO:[LightGBM] [Info] Total Bins 13422
2024-06-23 10:27:08,559:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 53
2024-06-23 10:27:08,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:09,574:INFO:[LightGBM] [Info] Number of positive: 18420, number of negative: 18420
2024-06-23 10:27:09,597:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012545 seconds.
2024-06-23 10:27:09,597:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-23 10:27:09,598:INFO:[LightGBM] [Info] Total Bins 13260
2024-06-23 10:27:09,598:INFO:[LightGBM] [Info] Number of data points in the train set: 36840, number of used features: 52
2024-06-23 10:27:09,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-23 10:27:10,995:INFO:Initializing evaluate_model()
2024-06-23 10:27:10,995:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-23 10:27:11,029:INFO:Initializing plot_model()
2024-06-23 10:27:11,029:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:27:11,030:INFO:Checking exceptions
2024-06-23 10:27:11,037:INFO:Preloading libraries
2024-06-23 10:27:11,050:INFO:Copying training dataset
2024-06-23 10:27:11,050:INFO:Plot type: pipeline
2024-06-23 10:27:11,296:INFO:Visual Rendered Successfully
2024-06-23 10:27:11,438:INFO:plot_model() successfully completed......................................
2024-06-23 10:27:11,466:INFO:Initializing plot_model()
2024-06-23 10:27:11,467:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3521, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-23 10:27:11,468:INFO:Checking exceptions
2024-06-23 10:27:11,474:INFO:Preloading libraries
2024-06-23 10:27:11,497:INFO:Copying training dataset
2024-06-23 10:27:11,497:INFO:Plot type: feature
2024-06-23 10:27:11,498:WARNING:No coef_ found. Trying feature_importances_
2024-06-23 10:27:11,851:INFO:Visual Rendered Successfully
2024-06-23 10:27:11,991:INFO:plot_model() successfully completed......................................
2024-06-23 11:23:56,269:INFO:Initializing get_config()
2024-06-23 11:23:56,270:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, variable=X_train)
2024-06-23 11:23:56,271:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-06-23 11:23:56,274:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2024-06-23 11:23:56,299:INFO:Variable:  returned as        age           job   marital            education  default  housing  \
4429    43    technician    single    university.degree       no      yes   
27703   42    management  divorced              unknown       no       no   
19072   38    technician   married  professional.course       no      yes   
32339   35      services   married          high.school       no       no   
11436   27   blue-collar   married             basic.4y       no      yes   
...    ...           ...       ...                  ...      ...      ...   
22028   48      services   married  professional.course  unknown      yes   
17890   49   blue-collar   married             basic.4y  unknown  unknown   
12744   45    management   married             basic.4y  unknown      yes   
23152   37   blue-collar   married             basic.9y       no      yes   
2464    45  entrepreneur   married    university.degree       no      yes   

          loan    contact month day_of_week  duration  campaign  pdays  \
4429        no   cellular   jul         thu       534         1    999   
27703       no   cellular   oct         thu        78         1    999   
19072       no   cellular   aug         fri       848         1    999   
32339       no  telephone   may         wed       188         1    999   
11436       no  telephone   may         thu       310         3    999   
...        ...        ...   ...         ...       ...       ...    ...   
22028      yes   cellular   jul         wed        98         2    999   
17890  unknown  telephone   jun         fri        25         1    999   
12744       no  telephone   may         fri       100         1    999   
23152       no   cellular   nov         fri       224         3    999   
2464        no   cellular   apr         thu       567         2    999   

      previous     poutcome  
4429         0  nonexistent  
27703        0  nonexistent  
19072        0  nonexistent  
32339        0  nonexistent  
11436        0  nonexistent  
...        ...          ...  
22028        0  nonexistent  
17890        0  nonexistent  
12744        0  nonexistent  
23152        0  nonexistent  
2464         0  nonexistent  

[23065 rows x 15 columns]
2024-06-23 11:23:56,300:INFO:get_config() successfully completed......................................
2024-06-23 11:26:55,466:INFO:Initializing get_config()
2024-06-23 11:26:55,466:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F2E0BA19D0>, variable=X)
2024-06-23 11:26:55,492:INFO:Variable:  returned as        age           job   marital            education  default housing loan  \
4429    43    technician    single    university.degree       no     yes   no   
27703   42    management  divorced              unknown       no      no   no   
19072   38    technician   married  professional.course       no     yes   no   
32339   35      services   married          high.school       no      no   no   
11436   27   blue-collar   married             basic.4y       no     yes   no   
...    ...           ...       ...                  ...      ...     ...  ...   
6743    30   blue-collar   married             basic.9y       no     yes   no   
17647   35    technician    single  professional.course       no     yes   no   
2623    33   blue-collar   married          high.school  unknown     yes   no   
20650   46  entrepreneur   married    university.degree  unknown      no   no   
26276   82       retired  divorced             basic.4y       no      no   no   

         contact month day_of_week  duration  campaign  pdays previous  \
4429    cellular   jul         thu       534         1    999        0   
27703   cellular   oct         thu        78         1    999        0   
19072   cellular   aug         fri       848         1    999        0   
32339  telephone   may         wed       188         1    999        0   
11436  telephone   may         thu       310         3    999        0   
...          ...   ...         ...       ...       ...    ...      ...   
6743    cellular   may         mon       175         5    999        0   
17647   cellular   jul         thu       307         4    999        0   
2623    cellular   jul         tue       624         6    999        0   
20650  telephone   may         wed       433         3    999        0   
26276   cellular   apr         mon       529         1      6        2   

          poutcome  
4429   nonexistent  
27703  nonexistent  
19072  nonexistent  
32339  nonexistent  
11436  nonexistent  
...            ...  
6743   nonexistent  
17647  nonexistent  
2623   nonexistent  
20650  nonexistent  
26276      success  

[32950 rows x 15 columns]
2024-06-23 11:26:55,492:INFO:get_config() successfully completed......................................
2024-06-27 08:10:23,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-27 08:10:23,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-27 08:10:23,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-27 08:10:23,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-27 08:10:31,909:INFO:PyCaret ClassificationExperiment
2024-06-27 08:10:31,909:INFO:Logging name: clf-default-name
2024-06-27 08:10:31,909:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-27 08:10:31,909:INFO:version 3.3.2
2024-06-27 08:10:31,909:INFO:Initializing setup()
2024-06-27 08:10:31,909:INFO:self.USI: 1693
2024-06-27 08:10:31,910:INFO:self._variable_keys: {'_ml_usecase', 'log_plots_param', 'gpu_param', 'target_param', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'memory', 'fix_imbalance', 'X_train', 'html_param', 'fold_generator', 'logging_param', 'seed', 'n_jobs_param', '_available_plots', 'pipeline', 'gpu_n_jobs_param', 'idx', 'X', 'y_test', 'exp_name_log', 'data', 'fold_groups_param', 'X_test', 'USI', 'y_train'}
2024-06-27 08:10:31,910:INFO:Checking environment
2024-06-27 08:10:31,910:INFO:python_version: 3.11.7
2024-06-27 08:10:31,910:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-27 08:10:31,910:INFO:machine: AMD64
2024-06-27 08:10:31,910:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-27 08:10:31,926:INFO:Memory: svmem(total=12756160512, available=3514302464, percent=72.5, used=9241858048, free=3514302464)
2024-06-27 08:10:31,926:INFO:Physical Core: 2
2024-06-27 08:10:31,927:INFO:Logical Core: 4
2024-06-27 08:10:31,927:INFO:Checking libraries
2024-06-27 08:10:31,927:INFO:System:
2024-06-27 08:10:31,927:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-27 08:10:31,927:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-27 08:10:31,927:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-27 08:10:31,927:INFO:PyCaret required dependencies:
2024-06-27 08:10:32,510:INFO:                 pip: 24.0
2024-06-27 08:10:32,510:INFO:          setuptools: 69.5.1
2024-06-27 08:10:32,510:INFO:             pycaret: 3.3.2
2024-06-27 08:10:32,511:INFO:             IPython: 8.24.0
2024-06-27 08:10:32,511:INFO:          ipywidgets: 8.1.3
2024-06-27 08:10:32,511:INFO:                tqdm: 4.66.4
2024-06-27 08:10:32,511:INFO:               numpy: 1.26.4
2024-06-27 08:10:32,511:INFO:              pandas: 2.1.4
2024-06-27 08:10:32,511:INFO:              jinja2: 3.1.4
2024-06-27 08:10:32,511:INFO:               scipy: 1.11.4
2024-06-27 08:10:32,512:INFO:              joblib: 1.3.2
2024-06-27 08:10:32,512:INFO:             sklearn: 1.4.2
2024-06-27 08:10:32,512:INFO:                pyod: 2.0.1
2024-06-27 08:10:32,512:INFO:            imblearn: 0.12.3
2024-06-27 08:10:32,512:INFO:   category_encoders: 2.6.3
2024-06-27 08:10:32,512:INFO:            lightgbm: 4.4.0
2024-06-27 08:10:32,512:INFO:               numba: 0.60.0
2024-06-27 08:10:32,512:INFO:            requests: 2.32.3
2024-06-27 08:10:32,513:INFO:          matplotlib: 3.7.5
2024-06-27 08:10:32,513:INFO:          scikitplot: 0.3.7
2024-06-27 08:10:32,513:INFO:         yellowbrick: 1.5
2024-06-27 08:10:32,513:INFO:              plotly: 5.22.0
2024-06-27 08:10:32,513:INFO:    plotly-resampler: Not installed
2024-06-27 08:10:32,513:INFO:             kaleido: 0.2.1
2024-06-27 08:10:32,513:INFO:           schemdraw: 0.15
2024-06-27 08:10:32,513:INFO:         statsmodels: 0.14.2
2024-06-27 08:10:32,513:INFO:              sktime: 0.26.0
2024-06-27 08:10:32,513:INFO:               tbats: 1.1.3
2024-06-27 08:10:32,514:INFO:            pmdarima: 2.0.4
2024-06-27 08:10:32,514:INFO:              psutil: 5.9.8
2024-06-27 08:10:32,514:INFO:          markupsafe: 2.1.5
2024-06-27 08:10:32,514:INFO:             pickle5: Not installed
2024-06-27 08:10:32,514:INFO:         cloudpickle: 3.0.0
2024-06-27 08:10:32,514:INFO:         deprecation: 2.1.0
2024-06-27 08:10:32,514:INFO:              xxhash: 3.4.1
2024-06-27 08:10:32,514:INFO:           wurlitzer: Not installed
2024-06-27 08:10:32,514:INFO:PyCaret optional dependencies:
2024-06-27 08:10:32,556:INFO:                shap: 0.44.1
2024-06-27 08:10:32,556:INFO:           interpret: 0.6.2
2024-06-27 08:10:32,556:INFO:                umap: 0.5.6
2024-06-27 08:10:32,556:INFO:     ydata_profiling: 4.8.3
2024-06-27 08:10:32,556:INFO:  explainerdashboard: 0.4.7
2024-06-27 08:10:32,556:INFO:             autoviz: Not installed
2024-06-27 08:10:32,556:INFO:           fairlearn: 0.7.0
2024-06-27 08:10:32,557:INFO:          deepchecks: Not installed
2024-06-27 08:10:32,557:INFO:             xgboost: Not installed
2024-06-27 08:10:32,557:INFO:            catboost: Not installed
2024-06-27 08:10:32,557:INFO:              kmodes: Not installed
2024-06-27 08:10:32,557:INFO:             mlxtend: Not installed
2024-06-27 08:10:32,557:INFO:       statsforecast: Not installed
2024-06-27 08:10:32,557:INFO:        tune_sklearn: Not installed
2024-06-27 08:10:32,558:INFO:                 ray: Not installed
2024-06-27 08:10:32,558:INFO:            hyperopt: Not installed
2024-06-27 08:10:32,558:INFO:              optuna: Not installed
2024-06-27 08:10:32,558:INFO:               skopt: Not installed
2024-06-27 08:10:32,558:INFO:              mlflow: Not installed
2024-06-27 08:10:32,558:INFO:              gradio: Not installed
2024-06-27 08:10:32,558:INFO:             fastapi: Not installed
2024-06-27 08:10:32,559:INFO:             uvicorn: Not installed
2024-06-27 08:10:32,559:INFO:              m2cgen: Not installed
2024-06-27 08:10:32,559:INFO:           evidently: Not installed
2024-06-27 08:10:32,559:INFO:               fugue: Not installed
2024-06-27 08:10:32,559:INFO:           streamlit: Not installed
2024-06-27 08:10:32,559:INFO:             prophet: Not installed
2024-06-27 08:10:32,559:INFO:None
2024-06-27 08:10:32,559:INFO:Set up data.
2024-06-27 08:10:33,889:INFO:Set up folding strategy.
2024-06-27 08:10:33,890:INFO:Set up train/test split.
2024-06-27 08:10:35,974:INFO:Set up index.
2024-06-27 08:10:36,038:INFO:Assigning column types.
2024-06-27 08:10:37,025:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-27 08:10:37,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-27 08:10:37,182:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:10:37,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:37,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:37,517:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-27 08:10:37,519:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:10:37,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:37,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:37,614:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-27 08:10:37,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:10:37,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:37,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:37,980:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:10:38,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:38,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:38,069:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-27 08:10:38,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:38,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:38,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:38,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:10:38,492:INFO:Preparing preprocessing pipeline...
2024-06-27 08:10:38,657:INFO:Set up label encoding.
2024-06-27 08:10:38,657:INFO:Set up date feature engineering.
2024-06-27 08:10:38,658:INFO:Set up simple imputation.
2024-06-27 08:10:39,135:INFO:Set up encoding of ordinal features.
2024-06-27 08:10:39,662:INFO:Set up encoding of categorical features.
2024-06-27 08:10:39,670:INFO:Set up imbalanced handling.
2024-06-27 08:13:44,655:INFO:PyCaret ClassificationExperiment
2024-06-27 08:13:44,656:INFO:Logging name: clf-default-name
2024-06-27 08:13:44,658:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-27 08:13:44,658:INFO:version 3.3.2
2024-06-27 08:13:44,658:INFO:Initializing setup()
2024-06-27 08:13:44,658:INFO:self.USI: 24a0
2024-06-27 08:13:44,659:INFO:self._variable_keys: {'_ml_usecase', 'log_plots_param', 'gpu_param', 'target_param', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'memory', 'fix_imbalance', 'X_train', 'html_param', 'fold_generator', 'logging_param', 'seed', 'n_jobs_param', '_available_plots', 'pipeline', 'gpu_n_jobs_param', 'idx', 'X', 'y_test', 'exp_name_log', 'data', 'fold_groups_param', 'X_test', 'USI', 'y_train'}
2024-06-27 08:13:44,659:INFO:Checking environment
2024-06-27 08:13:44,659:INFO:python_version: 3.11.7
2024-06-27 08:13:44,659:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-27 08:13:44,659:INFO:machine: AMD64
2024-06-27 08:13:44,659:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-27 08:13:44,665:INFO:Memory: svmem(total=12756160512, available=3243794432, percent=74.6, used=9512366080, free=3243794432)
2024-06-27 08:13:44,665:INFO:Physical Core: 2
2024-06-27 08:13:44,665:INFO:Logical Core: 4
2024-06-27 08:13:44,666:INFO:Checking libraries
2024-06-27 08:13:44,666:INFO:System:
2024-06-27 08:13:44,666:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-27 08:13:44,666:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-27 08:13:44,666:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-27 08:13:44,666:INFO:PyCaret required dependencies:
2024-06-27 08:13:44,666:INFO:                 pip: 24.0
2024-06-27 08:13:44,666:INFO:          setuptools: 69.5.1
2024-06-27 08:13:44,667:INFO:             pycaret: 3.3.2
2024-06-27 08:13:44,667:INFO:             IPython: 8.24.0
2024-06-27 08:13:44,667:INFO:          ipywidgets: 8.1.3
2024-06-27 08:13:44,667:INFO:                tqdm: 4.66.4
2024-06-27 08:13:44,668:INFO:               numpy: 1.26.4
2024-06-27 08:13:44,668:INFO:              pandas: 2.1.4
2024-06-27 08:13:44,668:INFO:              jinja2: 3.1.4
2024-06-27 08:13:44,668:INFO:               scipy: 1.11.4
2024-06-27 08:13:44,668:INFO:              joblib: 1.3.2
2024-06-27 08:13:44,668:INFO:             sklearn: 1.4.2
2024-06-27 08:13:44,669:INFO:                pyod: 2.0.1
2024-06-27 08:13:44,669:INFO:            imblearn: 0.12.3
2024-06-27 08:13:44,669:INFO:   category_encoders: 2.6.3
2024-06-27 08:13:44,669:INFO:            lightgbm: 4.4.0
2024-06-27 08:13:44,669:INFO:               numba: 0.60.0
2024-06-27 08:13:44,669:INFO:            requests: 2.32.3
2024-06-27 08:13:44,669:INFO:          matplotlib: 3.7.5
2024-06-27 08:13:44,669:INFO:          scikitplot: 0.3.7
2024-06-27 08:13:44,672:INFO:         yellowbrick: 1.5
2024-06-27 08:13:44,672:INFO:              plotly: 5.22.0
2024-06-27 08:13:44,673:INFO:    plotly-resampler: Not installed
2024-06-27 08:13:44,673:INFO:             kaleido: 0.2.1
2024-06-27 08:13:44,673:INFO:           schemdraw: 0.15
2024-06-27 08:13:44,673:INFO:         statsmodels: 0.14.2
2024-06-27 08:13:44,673:INFO:              sktime: 0.26.0
2024-06-27 08:13:44,673:INFO:               tbats: 1.1.3
2024-06-27 08:13:44,673:INFO:            pmdarima: 2.0.4
2024-06-27 08:13:44,673:INFO:              psutil: 5.9.8
2024-06-27 08:13:44,674:INFO:          markupsafe: 2.1.5
2024-06-27 08:13:44,674:INFO:             pickle5: Not installed
2024-06-27 08:13:44,674:INFO:         cloudpickle: 3.0.0
2024-06-27 08:13:44,674:INFO:         deprecation: 2.1.0
2024-06-27 08:13:44,674:INFO:              xxhash: 3.4.1
2024-06-27 08:13:44,674:INFO:           wurlitzer: Not installed
2024-06-27 08:13:44,675:INFO:PyCaret optional dependencies:
2024-06-27 08:13:44,675:INFO:                shap: 0.44.1
2024-06-27 08:13:44,675:INFO:           interpret: 0.6.2
2024-06-27 08:13:44,676:INFO:                umap: 0.5.6
2024-06-27 08:13:44,676:INFO:     ydata_profiling: 4.8.3
2024-06-27 08:13:44,676:INFO:  explainerdashboard: 0.4.7
2024-06-27 08:13:44,676:INFO:             autoviz: Not installed
2024-06-27 08:13:44,677:INFO:           fairlearn: 0.7.0
2024-06-27 08:13:44,677:INFO:          deepchecks: Not installed
2024-06-27 08:13:44,677:INFO:             xgboost: Not installed
2024-06-27 08:13:44,677:INFO:            catboost: Not installed
2024-06-27 08:13:44,677:INFO:              kmodes: Not installed
2024-06-27 08:13:44,677:INFO:             mlxtend: Not installed
2024-06-27 08:13:44,677:INFO:       statsforecast: Not installed
2024-06-27 08:13:44,677:INFO:        tune_sklearn: Not installed
2024-06-27 08:13:44,678:INFO:                 ray: Not installed
2024-06-27 08:13:44,678:INFO:            hyperopt: Not installed
2024-06-27 08:13:44,679:INFO:              optuna: Not installed
2024-06-27 08:13:44,679:INFO:               skopt: Not installed
2024-06-27 08:13:44,680:INFO:              mlflow: Not installed
2024-06-27 08:13:44,680:INFO:              gradio: Not installed
2024-06-27 08:13:44,695:INFO:             fastapi: Not installed
2024-06-27 08:13:44,695:INFO:             uvicorn: Not installed
2024-06-27 08:13:44,696:INFO:              m2cgen: Not installed
2024-06-27 08:13:44,696:INFO:           evidently: Not installed
2024-06-27 08:13:44,696:INFO:               fugue: Not installed
2024-06-27 08:13:44,696:INFO:           streamlit: Not installed
2024-06-27 08:13:44,697:INFO:             prophet: Not installed
2024-06-27 08:13:44,698:INFO:None
2024-06-27 08:13:44,698:INFO:Set up data.
2024-06-27 08:13:46,398:INFO:Set up folding strategy.
2024-06-27 08:13:46,399:INFO:Set up train/test split.
2024-06-27 08:13:48,261:INFO:Set up index.
2024-06-27 08:13:48,316:INFO:Assigning column types.
2024-06-27 08:13:49,242:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-27 08:13:49,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-27 08:13:49,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:13:49,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:49,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:49,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-27 08:13:49,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:13:49,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:49,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:49,637:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-27 08:13:49,762:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:13:49,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:49,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:49,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:13:50,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:50,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:50,020:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-27 08:13:50,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:50,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:50,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:50,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:13:50,417:INFO:Preparing preprocessing pipeline...
2024-06-27 08:13:50,547:INFO:Set up label encoding.
2024-06-27 08:13:50,547:INFO:Set up date feature engineering.
2024-06-27 08:13:50,547:INFO:Set up simple imputation.
2024-06-27 08:13:51,071:INFO:Set up encoding of ordinal features.
2024-06-27 08:13:51,675:INFO:Set up encoding of categorical features.
2024-06-27 08:13:51,683:INFO:Set up imbalanced handling.
2024-06-27 08:24:07,690:INFO:PyCaret ClassificationExperiment
2024-06-27 08:24:07,690:INFO:Logging name: clf-default-name
2024-06-27 08:24:07,690:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-27 08:24:07,690:INFO:version 3.3.2
2024-06-27 08:24:07,690:INFO:Initializing setup()
2024-06-27 08:24:07,691:INFO:self.USI: d093
2024-06-27 08:24:07,691:INFO:self._variable_keys: {'_ml_usecase', 'log_plots_param', 'gpu_param', 'target_param', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'memory', 'fix_imbalance', 'X_train', 'html_param', 'fold_generator', 'logging_param', 'seed', 'n_jobs_param', '_available_plots', 'pipeline', 'gpu_n_jobs_param', 'idx', 'X', 'y_test', 'exp_name_log', 'data', 'fold_groups_param', 'X_test', 'USI', 'y_train'}
2024-06-27 08:24:07,691:INFO:Checking environment
2024-06-27 08:24:07,691:INFO:python_version: 3.11.7
2024-06-27 08:24:07,691:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-27 08:24:07,691:INFO:machine: AMD64
2024-06-27 08:24:07,691:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-27 08:24:07,696:INFO:Memory: svmem(total=12756160512, available=3322953728, percent=74.0, used=9433206784, free=3322953728)
2024-06-27 08:24:07,696:INFO:Physical Core: 2
2024-06-27 08:24:07,696:INFO:Logical Core: 4
2024-06-27 08:24:07,696:INFO:Checking libraries
2024-06-27 08:24:07,696:INFO:System:
2024-06-27 08:24:07,697:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-27 08:24:07,697:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-27 08:24:07,697:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-27 08:24:07,698:INFO:PyCaret required dependencies:
2024-06-27 08:24:07,699:INFO:                 pip: 24.0
2024-06-27 08:24:07,699:INFO:          setuptools: 69.5.1
2024-06-27 08:24:07,699:INFO:             pycaret: 3.3.2
2024-06-27 08:24:07,700:INFO:             IPython: 8.24.0
2024-06-27 08:24:07,700:INFO:          ipywidgets: 8.1.3
2024-06-27 08:24:07,700:INFO:                tqdm: 4.66.4
2024-06-27 08:24:07,700:INFO:               numpy: 1.26.4
2024-06-27 08:24:07,700:INFO:              pandas: 2.1.4
2024-06-27 08:24:07,700:INFO:              jinja2: 3.1.4
2024-06-27 08:24:07,701:INFO:               scipy: 1.11.4
2024-06-27 08:24:07,701:INFO:              joblib: 1.3.2
2024-06-27 08:24:07,701:INFO:             sklearn: 1.4.2
2024-06-27 08:24:07,701:INFO:                pyod: 2.0.1
2024-06-27 08:24:07,702:INFO:            imblearn: 0.12.3
2024-06-27 08:24:07,702:INFO:   category_encoders: 2.6.3
2024-06-27 08:24:07,702:INFO:            lightgbm: 4.4.0
2024-06-27 08:24:07,702:INFO:               numba: 0.60.0
2024-06-27 08:24:07,702:INFO:            requests: 2.32.3
2024-06-27 08:24:07,702:INFO:          matplotlib: 3.7.5
2024-06-27 08:24:07,702:INFO:          scikitplot: 0.3.7
2024-06-27 08:24:07,702:INFO:         yellowbrick: 1.5
2024-06-27 08:24:07,703:INFO:              plotly: 5.22.0
2024-06-27 08:24:07,703:INFO:    plotly-resampler: Not installed
2024-06-27 08:24:07,704:INFO:             kaleido: 0.2.1
2024-06-27 08:24:07,704:INFO:           schemdraw: 0.15
2024-06-27 08:24:07,704:INFO:         statsmodels: 0.14.2
2024-06-27 08:24:07,704:INFO:              sktime: 0.26.0
2024-06-27 08:24:07,704:INFO:               tbats: 1.1.3
2024-06-27 08:24:07,705:INFO:            pmdarima: 2.0.4
2024-06-27 08:24:07,705:INFO:              psutil: 5.9.8
2024-06-27 08:24:07,705:INFO:          markupsafe: 2.1.5
2024-06-27 08:24:07,706:INFO:             pickle5: Not installed
2024-06-27 08:24:07,706:INFO:         cloudpickle: 3.0.0
2024-06-27 08:24:07,706:INFO:         deprecation: 2.1.0
2024-06-27 08:24:07,706:INFO:              xxhash: 3.4.1
2024-06-27 08:24:07,706:INFO:           wurlitzer: Not installed
2024-06-27 08:24:07,706:INFO:PyCaret optional dependencies:
2024-06-27 08:24:07,707:INFO:                shap: 0.44.1
2024-06-27 08:24:07,707:INFO:           interpret: 0.6.2
2024-06-27 08:24:07,707:INFO:                umap: 0.5.6
2024-06-27 08:24:07,707:INFO:     ydata_profiling: 4.8.3
2024-06-27 08:24:07,707:INFO:  explainerdashboard: 0.4.7
2024-06-27 08:24:07,707:INFO:             autoviz: Not installed
2024-06-27 08:24:07,707:INFO:           fairlearn: 0.7.0
2024-06-27 08:24:07,708:INFO:          deepchecks: Not installed
2024-06-27 08:24:07,708:INFO:             xgboost: Not installed
2024-06-27 08:24:07,708:INFO:            catboost: Not installed
2024-06-27 08:24:07,708:INFO:              kmodes: Not installed
2024-06-27 08:24:07,709:INFO:             mlxtend: Not installed
2024-06-27 08:24:07,709:INFO:       statsforecast: Not installed
2024-06-27 08:24:07,709:INFO:        tune_sklearn: Not installed
2024-06-27 08:24:07,709:INFO:                 ray: Not installed
2024-06-27 08:24:07,709:INFO:            hyperopt: Not installed
2024-06-27 08:24:07,709:INFO:              optuna: Not installed
2024-06-27 08:24:07,710:INFO:               skopt: Not installed
2024-06-27 08:24:07,710:INFO:              mlflow: Not installed
2024-06-27 08:24:07,710:INFO:              gradio: Not installed
2024-06-27 08:24:07,711:INFO:             fastapi: Not installed
2024-06-27 08:24:07,711:INFO:             uvicorn: Not installed
2024-06-27 08:24:07,712:INFO:              m2cgen: Not installed
2024-06-27 08:24:07,716:INFO:           evidently: Not installed
2024-06-27 08:24:07,717:INFO:               fugue: Not installed
2024-06-27 08:24:07,717:INFO:           streamlit: Not installed
2024-06-27 08:24:07,718:INFO:             prophet: Not installed
2024-06-27 08:24:07,719:INFO:None
2024-06-27 08:24:07,719:INFO:Set up data.
2024-06-27 08:24:09,329:INFO:Set up folding strategy.
2024-06-27 08:24:09,329:INFO:Set up train/test split.
2024-06-27 08:24:11,003:INFO:Set up index.
2024-06-27 08:24:11,050:INFO:Assigning column types.
2024-06-27 08:24:11,847:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-27 08:24:12,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-27 08:24:12,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:24:12,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-27 08:24:12,253:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:24:12,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,340:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-27 08:24:12,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:24:12,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,710:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-27 08:24:12,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:12,805:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-27 08:24:13,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:13,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:13,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:13,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:24:13,375:INFO:Preparing preprocessing pipeline...
2024-06-27 08:24:13,580:INFO:Set up label encoding.
2024-06-27 08:24:13,581:INFO:Set up date feature engineering.
2024-06-27 08:24:13,581:INFO:Set up simple imputation.
2024-06-27 08:24:14,064:INFO:Set up encoding of ordinal features.
2024-06-27 08:24:14,575:INFO:Set up encoding of categorical features.
2024-06-27 08:24:14,585:INFO:Set up imbalanced handling.
2024-06-27 08:24:24,320:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:256: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2024-06-27 08:24:31,386:INFO:Finished creating preprocessing pipeline.
2024-06-27 08:24:31,474:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-06-27 08:24:31,474:INFO:Creating final display dataframe.
2024-06-27 08:24:35,766:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-06-27 08:25:59,323:INFO:Setup _display_container:                     Description             Value
0                    Session id              6709
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (719624, 80)
6   Transformed train set shape      (579738, 80)
7    Transformed test set shape      (139886, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              d093
2024-06-27 08:25:59,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:25:59,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:26:00,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:26:00,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-27 08:26:00,084:INFO:setup() successfully completed in 112.41s...............
2024-06-27 08:31:34,484:INFO:Initializing compare_models()
2024-06-27 08:31:34,485:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, include=['lightgbm', 'lr', 'rf'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, 'include': ['lightgbm', 'lr', 'rf'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-27 08:31:34,485:INFO:Checking exceptions
2024-06-27 08:31:35,247:INFO:Preparing display monitor
2024-06-27 08:31:35,359:INFO:Initializing Light Gradient Boosting Machine
2024-06-27 08:31:35,360:INFO:Total runtime is 1.666545867919922e-05 minutes
2024-06-27 08:31:35,372:INFO:SubProcess create_model() called ==================================
2024-06-27 08:31:35,372:INFO:Initializing create_model()
2024-06-27 08:31:35,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAD7DDF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-27 08:31:35,373:INFO:Checking exceptions
2024-06-27 08:31:35,373:INFO:Importing libraries
2024-06-27 08:31:35,373:INFO:Copying training dataset
2024-06-27 08:31:37,007:INFO:Defining folds
2024-06-27 08:31:37,007:INFO:Declaring metric variables
2024-06-27 08:31:37,022:INFO:Importing untrained model
2024-06-27 08:31:37,032:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-27 08:31:37,057:INFO:Starting cross validation
2024-06-27 08:31:37,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-27 08:35:02,118:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:35:02,119:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:35:02,934:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:35:02,977:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:35:03,693:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:35:03,740:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:36:05,446:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:36:05,983:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:36:06,305:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:36:06,922:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:36:07,250:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:36:07,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:37:44,749:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:37:45,503:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:37:46,277:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:07,543:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:08,451:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:09,583:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:10,867:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:11,876:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:12,855:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:22,209:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:23,207:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:38:24,239:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:19,564:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:20,251:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:20,944:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:25,521:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:26,207:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:26,864:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:39:27,963:INFO:Calculating mean and std
2024-06-27 08:39:27,966:INFO:Creating metrics dataframe
2024-06-27 08:39:27,981:INFO:Uploading results into container
2024-06-27 08:39:27,982:INFO:Uploading model into container now
2024-06-27 08:39:27,983:INFO:_master_model_container: 1
2024-06-27 08:39:27,983:INFO:_display_container: 2
2024-06-27 08:39:27,984:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-27 08:39:27,984:INFO:create_model() successfully completed......................................
2024-06-27 08:39:28,327:INFO:SubProcess create_model() end ==================================
2024-06-27 08:39:28,327:INFO:Creating metrics dataframe
2024-06-27 08:39:28,343:INFO:Initializing Logistic Regression
2024-06-27 08:39:28,344:INFO:Total runtime is 7.883082409699758 minutes
2024-06-27 08:39:28,351:INFO:SubProcess create_model() called ==================================
2024-06-27 08:39:28,354:INFO:Initializing create_model()
2024-06-27 08:39:28,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAD7DDF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-27 08:39:28,354:INFO:Checking exceptions
2024-06-27 08:39:28,354:INFO:Importing libraries
2024-06-27 08:39:28,354:INFO:Copying training dataset
2024-06-27 08:39:29,516:INFO:Defining folds
2024-06-27 08:39:29,516:INFO:Declaring metric variables
2024-06-27 08:39:29,526:INFO:Importing untrained model
2024-06-27 08:39:29,541:INFO:Logistic Regression Imported successfully
2024-06-27 08:39:29,561:INFO:Starting cross validation
2024-06-27 08:39:29,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-27 08:46:41,448:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:46:43,670:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:44,142:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:46:44,707:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:45,257:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:46:45,772:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:46,346:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:47,119:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:46:47,431:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:47,456:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:48,434:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:48,445:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:49,247:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:49,408:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:50,307:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:46:51,394:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:16,679:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:54:19,129:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:20,257:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:20,751:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:54:21,406:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:22,943:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:54:23,275:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:23,508:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:54:24,448:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:25,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:25,674:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:26,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:26,628:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:27,252:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:27,761:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:54:28,414:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:16,166:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:59:16,959:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-27 08:59:18,371:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:18,844:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:19,179:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:19,680:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:20,105:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:20,550:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 08:59:21,816:INFO:Calculating mean and std
2024-06-27 08:59:21,819:INFO:Creating metrics dataframe
2024-06-27 08:59:21,834:INFO:Uploading results into container
2024-06-27 08:59:21,835:INFO:Uploading model into container now
2024-06-27 08:59:21,836:INFO:_master_model_container: 2
2024-06-27 08:59:21,836:INFO:_display_container: 2
2024-06-27 08:59:21,837:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6709, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-27 08:59:21,838:INFO:create_model() successfully completed......................................
2024-06-27 08:59:22,164:INFO:SubProcess create_model() end ==================================
2024-06-27 08:59:22,165:INFO:Creating metrics dataframe
2024-06-27 08:59:22,200:INFO:Initializing Random Forest Classifier
2024-06-27 08:59:22,201:INFO:Total runtime is 27.780690467357633 minutes
2024-06-27 08:59:22,209:INFO:SubProcess create_model() called ==================================
2024-06-27 08:59:22,209:INFO:Initializing create_model()
2024-06-27 08:59:22,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAD7DDF0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-27 08:59:22,210:INFO:Checking exceptions
2024-06-27 08:59:22,210:INFO:Importing libraries
2024-06-27 08:59:22,210:INFO:Copying training dataset
2024-06-27 08:59:23,742:INFO:Defining folds
2024-06-27 08:59:23,742:INFO:Declaring metric variables
2024-06-27 08:59:23,756:INFO:Importing untrained model
2024-06-27 08:59:23,765:INFO:Random Forest Classifier Imported successfully
2024-06-27 08:59:23,829:INFO:Starting cross validation
2024-06-27 08:59:23,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-27 09:09:41,545:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:41,967:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:42,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:42,494:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:42,986:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:43,065:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:43,445:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:44,180:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:44,295:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:46,370:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:47,385:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:09:48,410:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:17:56,806:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:17:58,035:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:17:59,068:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:00,125:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:00,504:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:00,924:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:01,214:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:01,625:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:01,927:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:03,786:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:04,414:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:18:05,040:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:02,897:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:03,583:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:03,795:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:04,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:04,345:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:04,912:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:22:05,597:INFO:Calculating mean and std
2024-06-27 09:22:05,597:INFO:Creating metrics dataframe
2024-06-27 09:22:05,631:INFO:Uploading results into container
2024-06-27 09:22:05,631:INFO:Uploading model into container now
2024-06-27 09:22:05,646:INFO:_master_model_container: 3
2024-06-27 09:22:05,647:INFO:_display_container: 2
2024-06-27 09:22:05,651:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6709, verbose=0,
                       warm_start=False)
2024-06-27 09:22:05,652:INFO:create_model() successfully completed......................................
2024-06-27 09:22:05,929:INFO:SubProcess create_model() end ==================================
2024-06-27 09:22:05,929:INFO:Creating metrics dataframe
2024-06-27 09:22:06,083:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-27 09:22:06,135:INFO:Initializing create_model()
2024-06-27 09:22:06,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-27 09:22:06,135:INFO:Checking exceptions
2024-06-27 09:22:06,180:INFO:Importing libraries
2024-06-27 09:22:06,180:INFO:Copying training dataset
2024-06-27 09:22:06,810:INFO:Defining folds
2024-06-27 09:22:06,810:INFO:Declaring metric variables
2024-06-27 09:22:06,810:INFO:Importing untrained model
2024-06-27 09:22:06,810:INFO:Declaring custom model
2024-06-27 09:22:06,810:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-27 09:22:06,826:INFO:Cross validation set to False
2024-06-27 09:22:06,826:INFO:Fitting Model
2024-06-27 09:22:28,553:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-27 09:22:28,669:INFO:[LightGBM] [Info] Number of positive: 289869, number of negative: 289869
2024-06-27 09:22:29,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.226278 seconds.
2024-06-27 09:22:29,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-27 09:22:29,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-27 09:22:29,354:INFO:[LightGBM] [Info] Total Bins 16699
2024-06-27 09:22:29,354:INFO:[LightGBM] [Info] Number of data points in the train set: 579738, number of used features: 75
2024-06-27 09:22:29,387:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-27 09:22:38,660:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-27 09:22:38,660:INFO:create_model() successfully completed......................................
2024-06-27 09:22:39,280:INFO:_master_model_container: 3
2024-06-27 09:22:39,280:INFO:_display_container: 2
2024-06-27 09:22:39,280:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-27 09:22:39,280:INFO:compare_models() successfully completed......................................
2024-06-27 09:40:50,211:INFO:Initializing plot_model()
2024-06-27 09:40:50,211:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-27 09:40:50,212:INFO:Checking exceptions
2024-06-27 09:40:50,448:INFO:Preloading libraries
2024-06-27 09:40:50,469:INFO:Copying training dataset
2024-06-27 09:40:50,470:INFO:Plot type: confusion_matrix
2024-06-27 09:41:00,080:INFO:Fitting Model
2024-06-27 09:41:00,097:INFO:Scoring test/hold-out set
2024-06-27 09:41:01,684:INFO:Visual Rendered Successfully
2024-06-27 09:41:01,912:INFO:plot_model() successfully completed......................................
2024-06-27 09:44:31,989:INFO:Initializing plot_model()
2024-06-27 09:44:31,989:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-27 09:44:31,989:INFO:Checking exceptions
2024-06-27 09:44:32,401:INFO:Preloading libraries
2024-06-27 09:44:32,502:INFO:Copying training dataset
2024-06-27 09:44:32,502:INFO:Plot type: auc
2024-06-27 09:44:35,885:INFO:Fitting Model
2024-06-27 09:44:35,901:INFO:Scoring test/hold-out set
2024-06-27 09:44:37,352:INFO:Visual Rendered Successfully
2024-06-27 09:44:37,584:INFO:plot_model() successfully completed......................................
2024-06-27 09:45:32,089:INFO:Initializing evaluate_model()
2024-06-27 09:45:32,089:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-27 09:45:32,576:INFO:Initializing plot_model()
2024-06-27 09:45:32,576:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-27 09:45:32,576:INFO:Checking exceptions
2024-06-27 09:45:32,874:INFO:Preloading libraries
2024-06-27 09:45:32,874:INFO:Copying training dataset
2024-06-27 09:45:32,874:INFO:Plot type: pipeline
2024-06-27 09:45:34,305:INFO:Visual Rendered Successfully
2024-06-27 09:45:34,491:INFO:plot_model() successfully completed......................................
2024-06-27 09:45:40,944:INFO:Initializing plot_model()
2024-06-27 09:45:40,944:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-27 09:45:40,944:INFO:Checking exceptions
2024-06-27 09:45:41,117:INFO:Preloading libraries
2024-06-27 09:45:41,133:INFO:Copying training dataset
2024-06-27 09:45:41,133:INFO:Plot type: feature
2024-06-27 09:45:41,133:WARNING:No coef_ found. Trying feature_importances_
2024-06-27 09:45:42,320:INFO:Visual Rendered Successfully
2024-06-27 09:45:42,461:INFO:plot_model() successfully completed......................................
2024-06-27 09:46:11,485:INFO:Initializing predict_model()
2024-06-27 09:46:11,485:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CADB4BC4D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6709, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CACB812340>)
2024-06-27 09:46:11,485:INFO:Checking exceptions
2024-06-27 09:46:11,485:INFO:Preloading libraries
2024-06-27 09:46:15,237:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:46:16,536:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-27 09:46:17,870:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:23:10,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-28 04:23:10,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-28 04:23:10,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-28 04:23:10,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-28 04:27:04,642:INFO:PyCaret ClassificationExperiment
2024-06-28 04:27:04,642:INFO:Logging name: clf-default-name
2024-06-28 04:27:04,642:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-28 04:27:04,642:INFO:version 3.3.2
2024-06-28 04:27:04,642:INFO:Initializing setup()
2024-06-28 04:27:04,642:INFO:self.USI: b030
2024-06-28 04:27:04,642:INFO:self._variable_keys: {'idx', 'logging_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X', '_available_plots', 'gpu_param', '_ml_usecase', 'data', 'fold_shuffle_param', 'y_train', 'y_test', 'pipeline', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'log_plots_param', 'X_train', 'X_test', 'n_jobs_param', 'seed', 'memory', 'fold_generator', 'USI', 'fix_imbalance', 'y'}
2024-06-28 04:27:04,642:INFO:Checking environment
2024-06-28 04:27:04,642:INFO:python_version: 3.11.7
2024-06-28 04:27:04,642:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-28 04:27:04,642:INFO:machine: AMD64
2024-06-28 04:27:04,642:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-28 04:27:04,651:INFO:Memory: svmem(total=12756160512, available=5616148480, percent=56.0, used=7140012032, free=5616148480)
2024-06-28 04:27:04,651:INFO:Physical Core: 2
2024-06-28 04:27:04,651:INFO:Logical Core: 4
2024-06-28 04:27:04,651:INFO:Checking libraries
2024-06-28 04:27:04,651:INFO:System:
2024-06-28 04:27:04,651:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-28 04:27:04,651:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-28 04:27:04,651:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-28 04:27:04,651:INFO:PyCaret required dependencies:
2024-06-28 04:27:05,351:INFO:                 pip: 24.0
2024-06-28 04:27:05,351:INFO:          setuptools: 69.5.1
2024-06-28 04:27:05,351:INFO:             pycaret: 3.3.2
2024-06-28 04:27:05,351:INFO:             IPython: 8.24.0
2024-06-28 04:27:05,351:INFO:          ipywidgets: 8.1.3
2024-06-28 04:27:05,351:INFO:                tqdm: 4.66.4
2024-06-28 04:27:05,351:INFO:               numpy: 1.26.4
2024-06-28 04:27:05,351:INFO:              pandas: 2.1.4
2024-06-28 04:27:05,351:INFO:              jinja2: 3.1.4
2024-06-28 04:27:05,351:INFO:               scipy: 1.11.4
2024-06-28 04:27:05,351:INFO:              joblib: 1.3.2
2024-06-28 04:27:05,351:INFO:             sklearn: 1.4.2
2024-06-28 04:27:05,351:INFO:                pyod: 2.0.1
2024-06-28 04:27:05,351:INFO:            imblearn: 0.12.3
2024-06-28 04:27:05,351:INFO:   category_encoders: 2.6.3
2024-06-28 04:27:05,351:INFO:            lightgbm: 4.4.0
2024-06-28 04:27:05,351:INFO:               numba: 0.60.0
2024-06-28 04:27:05,351:INFO:            requests: 2.32.3
2024-06-28 04:27:05,351:INFO:          matplotlib: 3.7.5
2024-06-28 04:27:05,351:INFO:          scikitplot: 0.3.7
2024-06-28 04:27:05,351:INFO:         yellowbrick: 1.5
2024-06-28 04:27:05,351:INFO:              plotly: 5.22.0
2024-06-28 04:27:05,351:INFO:    plotly-resampler: Not installed
2024-06-28 04:27:05,351:INFO:             kaleido: 0.2.1
2024-06-28 04:27:05,351:INFO:           schemdraw: 0.15
2024-06-28 04:27:05,351:INFO:         statsmodels: 0.14.2
2024-06-28 04:27:05,351:INFO:              sktime: 0.26.0
2024-06-28 04:27:05,351:INFO:               tbats: 1.1.3
2024-06-28 04:27:05,351:INFO:            pmdarima: 2.0.4
2024-06-28 04:27:05,351:INFO:              psutil: 5.9.8
2024-06-28 04:27:05,351:INFO:          markupsafe: 2.1.5
2024-06-28 04:27:05,351:INFO:             pickle5: Not installed
2024-06-28 04:27:05,351:INFO:         cloudpickle: 3.0.0
2024-06-28 04:27:05,351:INFO:         deprecation: 2.1.0
2024-06-28 04:27:05,351:INFO:              xxhash: 3.4.1
2024-06-28 04:27:05,351:INFO:           wurlitzer: Not installed
2024-06-28 04:27:05,351:INFO:PyCaret optional dependencies:
2024-06-28 04:27:05,368:INFO:                shap: 0.44.1
2024-06-28 04:27:05,368:INFO:           interpret: 0.6.2
2024-06-28 04:27:05,368:INFO:                umap: 0.5.6
2024-06-28 04:27:05,368:INFO:     ydata_profiling: 4.8.3
2024-06-28 04:27:05,368:INFO:  explainerdashboard: 0.4.7
2024-06-28 04:27:05,368:INFO:             autoviz: Not installed
2024-06-28 04:27:05,368:INFO:           fairlearn: 0.7.0
2024-06-28 04:27:05,368:INFO:          deepchecks: Not installed
2024-06-28 04:27:05,368:INFO:             xgboost: Not installed
2024-06-28 04:27:05,368:INFO:            catboost: Not installed
2024-06-28 04:27:05,368:INFO:              kmodes: Not installed
2024-06-28 04:27:05,368:INFO:             mlxtend: Not installed
2024-06-28 04:27:05,368:INFO:       statsforecast: Not installed
2024-06-28 04:27:05,368:INFO:        tune_sklearn: Not installed
2024-06-28 04:27:05,368:INFO:                 ray: Not installed
2024-06-28 04:27:05,368:INFO:            hyperopt: Not installed
2024-06-28 04:27:05,368:INFO:              optuna: Not installed
2024-06-28 04:27:05,368:INFO:               skopt: Not installed
2024-06-28 04:27:05,368:INFO:              mlflow: Not installed
2024-06-28 04:27:05,368:INFO:              gradio: Not installed
2024-06-28 04:27:05,368:INFO:             fastapi: Not installed
2024-06-28 04:27:05,368:INFO:             uvicorn: Not installed
2024-06-28 04:27:05,368:INFO:              m2cgen: Not installed
2024-06-28 04:27:05,368:INFO:           evidently: Not installed
2024-06-28 04:27:05,368:INFO:               fugue: Not installed
2024-06-28 04:27:05,368:INFO:           streamlit: Not installed
2024-06-28 04:27:05,368:INFO:             prophet: Not installed
2024-06-28 04:27:05,368:INFO:None
2024-06-28 04:27:05,368:INFO:Set up data.
2024-06-28 04:27:06,336:INFO:Set up folding strategy.
2024-06-28 04:27:06,336:INFO:Set up train/test split.
2024-06-28 04:27:07,221:INFO:Set up index.
2024-06-28 04:27:07,253:INFO:Assigning column types.
2024-06-28 04:27:07,622:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-28 04:27:07,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 04:27:07,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 04:27:07,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:07,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 04:27:08,039:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 04:27:08,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,080:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-28 04:27:08,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 04:27:08,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 04:27:08,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,271:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-28 04:27:08,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:08,488:INFO:Preparing preprocessing pipeline...
2024-06-28 04:27:08,549:INFO:Set up label encoding.
2024-06-28 04:27:08,549:INFO:Set up date feature engineering.
2024-06-28 04:27:08,549:INFO:Set up simple imputation.
2024-06-28 04:27:08,800:INFO:Set up encoding of ordinal features.
2024-06-28 04:27:09,038:INFO:Set up encoding of categorical features.
2024-06-28 04:27:15,589:INFO:Finished creating preprocessing pipeline.
2024-06-28 04:27:15,620:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['grade', 'emp_length',
                                             'home_ownership',
                                             'verification_status', 'purpose'],
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-28 04:27:15,620:INFO:Creating final display dataframe.
2024-06-28 04:27:25,875:INFO:Setup _display_container:                     Description             Value
0                    Session id              1207
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (466285, 80)
6   Transformed train set shape      (326399, 80)
7    Transformed test set shape      (139886, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b030
2024-06-28 04:27:26,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:26,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:26,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:26,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 04:27:26,409:INFO:setup() successfully completed in 21.79s...............
2024-06-28 04:27:26,425:INFO:Initializing compare_models()
2024-06-28 04:27:26,425:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-28 04:27:26,425:INFO:Checking exceptions
2024-06-28 04:27:26,725:INFO:Preparing display monitor
2024-06-28 04:27:26,759:INFO:Initializing Logistic Regression
2024-06-28 04:27:26,759:INFO:Total runtime is 0.0 minutes
2024-06-28 04:27:26,775:INFO:SubProcess create_model() called ==================================
2024-06-28 04:27:26,775:INFO:Initializing create_model()
2024-06-28 04:27:26,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:27:26,775:INFO:Checking exceptions
2024-06-28 04:27:26,775:INFO:Importing libraries
2024-06-28 04:27:26,775:INFO:Copying training dataset
2024-06-28 04:27:27,292:INFO:Defining folds
2024-06-28 04:27:27,292:INFO:Declaring metric variables
2024-06-28 04:27:27,292:INFO:Importing untrained model
2024-06-28 04:27:27,311:INFO:Logistic Regression Imported successfully
2024-06-28 04:27:27,311:INFO:Starting cross validation
2024-06-28 04:27:27,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 04:30:14,882:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:30:15,367:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:30:15,532:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:30:16,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:30:16,274:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:16,636:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:16,762:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:16,910:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,166:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,199:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,332:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,449:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,741:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,782:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:17,922:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:30:18,311:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:49,618:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:32:50,195:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:32:50,617:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:32:50,951:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:51,429:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:32:51,484:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:51,510:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:51,868:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:52,068:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:52,086:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:52,454:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:52,553:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:52,652:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:53,035:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:53,168:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:32:53,802:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:24,466:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:34:24,768:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 04:34:25,265:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:25,533:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:25,585:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:25,876:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:25,926:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:26,176:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:34:26,672:INFO:Calculating mean and std
2024-06-28 04:34:26,672:INFO:Creating metrics dataframe
2024-06-28 04:34:26,672:INFO:Uploading results into container
2024-06-28 04:34:26,672:INFO:Uploading model into container now
2024-06-28 04:34:26,672:INFO:_master_model_container: 1
2024-06-28 04:34:26,672:INFO:_display_container: 2
2024-06-28 04:34:26,683:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1207, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-28 04:34:26,683:INFO:create_model() successfully completed......................................
2024-06-28 04:34:26,800:INFO:SubProcess create_model() end ==================================
2024-06-28 04:34:26,800:INFO:Creating metrics dataframe
2024-06-28 04:34:26,800:INFO:Initializing K Neighbors Classifier
2024-06-28 04:34:26,800:INFO:Total runtime is 7.000667540232341 minutes
2024-06-28 04:34:26,816:INFO:SubProcess create_model() called ==================================
2024-06-28 04:34:26,817:INFO:Initializing create_model()
2024-06-28 04:34:26,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:34:26,817:INFO:Checking exceptions
2024-06-28 04:34:26,818:INFO:Importing libraries
2024-06-28 04:34:26,818:INFO:Copying training dataset
2024-06-28 04:34:27,300:INFO:Defining folds
2024-06-28 04:34:27,300:INFO:Declaring metric variables
2024-06-28 04:34:27,321:INFO:Importing untrained model
2024-06-28 04:34:27,328:INFO:K Neighbors Classifier Imported successfully
2024-06-28 04:34:27,350:INFO:Starting cross validation
2024-06-28 04:34:27,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 04:41:22,640:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:22,839:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:23,240:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:23,306:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:23,523:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:23,523:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:23,873:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:23,940:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:24,164:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:24,191:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:24,540:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:41:24,840:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:20,527:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:20,819:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:21,249:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:21,497:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:21,764:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:21,926:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:22,047:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:22,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:22,431:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:22,693:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:23,100:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:48:23,331:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:28,823:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:28,947:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:29,170:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:29,284:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:29,532:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:29,636:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:30,229:INFO:Calculating mean and std
2024-06-28 04:52:30,231:INFO:Creating metrics dataframe
2024-06-28 04:52:30,241:INFO:Uploading results into container
2024-06-28 04:52:30,242:INFO:Uploading model into container now
2024-06-28 04:52:30,242:INFO:_master_model_container: 2
2024-06-28 04:52:30,242:INFO:_display_container: 2
2024-06-28 04:52:30,242:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-06-28 04:52:30,242:INFO:create_model() successfully completed......................................
2024-06-28 04:52:30,348:INFO:SubProcess create_model() end ==================================
2024-06-28 04:52:30,348:INFO:Creating metrics dataframe
2024-06-28 04:52:30,348:INFO:Initializing Naive Bayes
2024-06-28 04:52:30,348:INFO:Total runtime is 25.05980227390925 minutes
2024-06-28 04:52:30,348:INFO:SubProcess create_model() called ==================================
2024-06-28 04:52:30,348:INFO:Initializing create_model()
2024-06-28 04:52:30,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:52:30,348:INFO:Checking exceptions
2024-06-28 04:52:30,348:INFO:Importing libraries
2024-06-28 04:52:30,348:INFO:Copying training dataset
2024-06-28 04:52:30,864:INFO:Defining folds
2024-06-28 04:52:30,865:INFO:Declaring metric variables
2024-06-28 04:52:30,869:INFO:Importing untrained model
2024-06-28 04:52:30,869:INFO:Naive Bayes Imported successfully
2024-06-28 04:52:30,883:INFO:Starting cross validation
2024-06-28 04:52:30,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 04:52:44,686:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:44,705:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:44,736:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:44,853:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:45,320:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:45,374:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:45,390:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:45,520:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:45,970:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:46,022:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:46,054:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:46,188:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:59,975:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:52:59,991:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:00,090:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:00,127:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:00,691:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:00,708:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:00,758:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:00,791:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:01,347:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:01,360:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:01,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:01,447:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:10,444:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:10,514:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:10,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:10,866:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:11,131:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:11,220:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:11,797:INFO:Calculating mean and std
2024-06-28 04:53:11,801:INFO:Creating metrics dataframe
2024-06-28 04:53:11,830:INFO:Uploading results into container
2024-06-28 04:53:11,833:INFO:Uploading model into container now
2024-06-28 04:53:11,835:INFO:_master_model_container: 3
2024-06-28 04:53:11,835:INFO:_display_container: 2
2024-06-28 04:53:11,835:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-06-28 04:53:11,835:INFO:create_model() successfully completed......................................
2024-06-28 04:53:11,928:INFO:SubProcess create_model() end ==================================
2024-06-28 04:53:11,928:INFO:Creating metrics dataframe
2024-06-28 04:53:11,945:INFO:Initializing Decision Tree Classifier
2024-06-28 04:53:11,945:INFO:Total runtime is 25.753089702129362 minutes
2024-06-28 04:53:11,945:INFO:SubProcess create_model() called ==================================
2024-06-28 04:53:11,945:INFO:Initializing create_model()
2024-06-28 04:53:11,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:53:11,945:INFO:Checking exceptions
2024-06-28 04:53:11,945:INFO:Importing libraries
2024-06-28 04:53:11,945:INFO:Copying training dataset
2024-06-28 04:53:12,579:INFO:Defining folds
2024-06-28 04:53:12,579:INFO:Declaring metric variables
2024-06-28 04:53:12,594:INFO:Importing untrained model
2024-06-28 04:53:12,599:INFO:Decision Tree Classifier Imported successfully
2024-06-28 04:53:12,614:INFO:Starting cross validation
2024-06-28 04:53:12,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 04:53:58,597:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:58,928:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:59,227:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:59,303:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:59,544:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:59,861:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:53:59,928:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:00,278:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:00,649:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:00,803:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:01,464:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:02,151:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:44,899:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:45,510:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:46,177:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:46,328:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:47,010:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:47,314:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:47,726:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:47,994:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:48,067:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:48,661:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:48,744:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:54:49,404:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:17,231:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:17,580:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:17,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:18,716:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:18,995:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:19,261:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:19,742:INFO:Calculating mean and std
2024-06-28 04:55:19,742:INFO:Creating metrics dataframe
2024-06-28 04:55:19,742:INFO:Uploading results into container
2024-06-28 04:55:19,742:INFO:Uploading model into container now
2024-06-28 04:55:19,742:INFO:_master_model_container: 4
2024-06-28 04:55:19,742:INFO:_display_container: 2
2024-06-28 04:55:19,757:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1207, splitter='best')
2024-06-28 04:55:19,757:INFO:create_model() successfully completed......................................
2024-06-28 04:55:19,855:INFO:SubProcess create_model() end ==================================
2024-06-28 04:55:19,855:INFO:Creating metrics dataframe
2024-06-28 04:55:19,872:INFO:Initializing SVM - Linear Kernel
2024-06-28 04:55:19,872:INFO:Total runtime is 27.885203770796455 minutes
2024-06-28 04:55:19,872:INFO:SubProcess create_model() called ==================================
2024-06-28 04:55:19,872:INFO:Initializing create_model()
2024-06-28 04:55:19,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:55:19,872:INFO:Checking exceptions
2024-06-28 04:55:19,872:INFO:Importing libraries
2024-06-28 04:55:19,872:INFO:Copying training dataset
2024-06-28 04:55:20,386:INFO:Defining folds
2024-06-28 04:55:20,386:INFO:Declaring metric variables
2024-06-28 04:55:20,404:INFO:Importing untrained model
2024-06-28 04:55:20,410:INFO:SVM - Linear Kernel Imported successfully
2024-06-28 04:55:20,422:INFO:Starting cross validation
2024-06-28 04:55:20,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 04:55:47,202:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:47,626:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:47,764:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:48,169:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:48,347:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:48,716:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:51,121:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:51,735:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:55:52,383:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:03,754:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:04,295:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:04,939:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:22,126:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:22,676:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:23,243:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:23,576:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:24,160:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:24,730:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:25,844:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:26,493:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:27,112:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:31,891:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:32,413:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:32,915:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:43,837:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:44,175:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:44,537:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:44,578:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:44,919:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:45,233:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:56:45,713:INFO:Calculating mean and std
2024-06-28 04:56:45,717:INFO:Creating metrics dataframe
2024-06-28 04:56:45,726:INFO:Uploading results into container
2024-06-28 04:56:45,728:INFO:Uploading model into container now
2024-06-28 04:56:45,728:INFO:_master_model_container: 5
2024-06-28 04:56:45,728:INFO:_display_container: 2
2024-06-28 04:56:45,728:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1207, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-06-28 04:56:45,728:INFO:create_model() successfully completed......................................
2024-06-28 04:56:45,817:INFO:SubProcess create_model() end ==================================
2024-06-28 04:56:45,833:INFO:Creating metrics dataframe
2024-06-28 04:56:45,900:INFO:Initializing Ridge Classifier
2024-06-28 04:56:45,900:INFO:Total runtime is 29.31901133060455 minutes
2024-06-28 04:56:45,900:INFO:SubProcess create_model() called ==================================
2024-06-28 04:56:45,900:INFO:Initializing create_model()
2024-06-28 04:56:45,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:56:45,900:INFO:Checking exceptions
2024-06-28 04:56:45,900:INFO:Importing libraries
2024-06-28 04:56:45,900:INFO:Copying training dataset
2024-06-28 04:56:46,433:INFO:Defining folds
2024-06-28 04:56:46,433:INFO:Declaring metric variables
2024-06-28 04:56:46,447:INFO:Importing untrained model
2024-06-28 04:56:46,451:INFO:Ridge Classifier Imported successfully
2024-06-28 04:56:46,451:INFO:Starting cross validation
2024-06-28 04:56:46,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 04:57:00,199:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:00,259:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:00,298:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:00,307:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:00,908:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:00,909:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:00,957:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:01,009:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:01,542:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:01,613:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:01,617:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:01,658:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:15,077:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:15,166:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:15,377:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:15,447:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:15,716:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:15,793:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:16,014:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:16,104:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:16,361:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:16,461:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:16,645:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:16,762:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:25,163:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:25,299:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:25,516:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:25,630:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:25,855:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:25,970:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 04:57:26,549:INFO:Calculating mean and std
2024-06-28 04:57:26,566:INFO:Creating metrics dataframe
2024-06-28 04:57:26,588:INFO:Uploading results into container
2024-06-28 04:57:26,590:INFO:Uploading model into container now
2024-06-28 04:57:26,594:INFO:_master_model_container: 6
2024-06-28 04:57:26,595:INFO:_display_container: 2
2024-06-28 04:57:26,597:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1207, solver='auto',
                tol=0.0001)
2024-06-28 04:57:26,598:INFO:create_model() successfully completed......................................
2024-06-28 04:57:26,698:INFO:SubProcess create_model() end ==================================
2024-06-28 04:57:26,698:INFO:Creating metrics dataframe
2024-06-28 04:57:26,721:INFO:Initializing Random Forest Classifier
2024-06-28 04:57:26,721:INFO:Total runtime is 29.999356210231777 minutes
2024-06-28 04:57:26,726:INFO:SubProcess create_model() called ==================================
2024-06-28 04:57:26,727:INFO:Initializing create_model()
2024-06-28 04:57:26,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 04:57:26,727:INFO:Checking exceptions
2024-06-28 04:57:26,727:INFO:Importing libraries
2024-06-28 04:57:26,727:INFO:Copying training dataset
2024-06-28 04:57:27,230:INFO:Defining folds
2024-06-28 04:57:27,231:INFO:Declaring metric variables
2024-06-28 04:57:27,235:INFO:Importing untrained model
2024-06-28 04:57:27,235:INFO:Random Forest Classifier Imported successfully
2024-06-28 04:57:27,250:INFO:Starting cross validation
2024-06-28 04:57:27,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:01:26,840:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:27,421:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:28,128:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:28,212:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:28,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:28,514:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:28,780:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:28,845:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:29,033:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:29,179:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:29,486:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:01:29,846:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:28,785:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:29,344:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:29,953:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:30,544:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:30,677:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:30,877:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:30,945:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:31,188:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:31,349:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:31,577:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:32,018:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:05:32,299:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:35,943:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:36,508:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:36,608:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:37,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:37,127:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:37,579:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:07:38,248:INFO:Calculating mean and std
2024-06-28 05:07:38,248:INFO:Creating metrics dataframe
2024-06-28 05:07:38,275:INFO:Uploading results into container
2024-06-28 05:07:38,281:INFO:Uploading model into container now
2024-06-28 05:07:38,285:INFO:_master_model_container: 7
2024-06-28 05:07:38,285:INFO:_display_container: 2
2024-06-28 05:07:38,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1207, verbose=0,
                       warm_start=False)
2024-06-28 05:07:38,285:INFO:create_model() successfully completed......................................
2024-06-28 05:07:38,402:INFO:SubProcess create_model() end ==================================
2024-06-28 05:07:38,402:INFO:Creating metrics dataframe
2024-06-28 05:07:38,410:INFO:Initializing Quadratic Discriminant Analysis
2024-06-28 05:07:38,410:INFO:Total runtime is 40.19418129920959 minutes
2024-06-28 05:07:38,410:INFO:SubProcess create_model() called ==================================
2024-06-28 05:07:38,410:INFO:Initializing create_model()
2024-06-28 05:07:38,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:07:38,410:INFO:Checking exceptions
2024-06-28 05:07:38,410:INFO:Importing libraries
2024-06-28 05:07:38,410:INFO:Copying training dataset
2024-06-28 05:07:38,927:INFO:Defining folds
2024-06-28 05:07:38,927:INFO:Declaring metric variables
2024-06-28 05:07:38,936:INFO:Importing untrained model
2024-06-28 05:07:38,944:INFO:Quadratic Discriminant Analysis Imported successfully
2024-06-28 05:07:38,946:INFO:Starting cross validation
2024-06-28 05:07:38,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:07:51,756:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:07:51,756:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:07:51,756:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:07:51,756:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:07,254:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,341:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,356:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,356:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,860:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,921:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,942:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:07,942:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:08,440:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:08,521:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:08,539:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:08,554:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:20,392:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:20,926:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:21,160:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:21,160:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:35,663:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,065:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,080:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,248:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,630:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,666:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,697:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:36,846:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:37,200:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:37,248:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:37,297:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:45,353:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:45,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-06-28 05:08:53,522:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:53,770:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:53,841:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:54,170:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:54,255:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:54,523:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:08:55,122:INFO:Calculating mean and std
2024-06-28 05:08:55,138:INFO:Creating metrics dataframe
2024-06-28 05:08:55,157:INFO:Uploading results into container
2024-06-28 05:08:55,160:INFO:Uploading model into container now
2024-06-28 05:08:55,163:INFO:_master_model_container: 8
2024-06-28 05:08:55,164:INFO:_display_container: 2
2024-06-28 05:08:55,164:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-06-28 05:08:55,164:INFO:create_model() successfully completed......................................
2024-06-28 05:08:55,271:INFO:SubProcess create_model() end ==================================
2024-06-28 05:08:55,271:INFO:Creating metrics dataframe
2024-06-28 05:08:55,271:INFO:Initializing Ada Boost Classifier
2024-06-28 05:08:55,271:INFO:Total runtime is 41.4751902381579 minutes
2024-06-28 05:08:55,287:INFO:SubProcess create_model() called ==================================
2024-06-28 05:08:55,287:INFO:Initializing create_model()
2024-06-28 05:08:55,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:08:55,287:INFO:Checking exceptions
2024-06-28 05:08:55,287:INFO:Importing libraries
2024-06-28 05:08:55,287:INFO:Copying training dataset
2024-06-28 05:08:55,788:INFO:Defining folds
2024-06-28 05:08:55,788:INFO:Declaring metric variables
2024-06-28 05:08:55,806:INFO:Importing untrained model
2024-06-28 05:08:55,808:INFO:Ada Boost Classifier Imported successfully
2024-06-28 05:08:55,822:INFO:Starting cross validation
2024-06-28 05:08:55,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:09:06,892:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:09:06,926:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:09:07,116:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:09:07,272:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:11:02,319:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:02,780:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:02,903:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:02,979:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:03,146:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:03,434:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:03,563:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:03,620:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:03,813:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:04,186:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:04,300:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:04,597:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:11:14,317:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:11:15,099:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:11:15,217:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:11:15,567:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:13:09,384:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:10,040:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:10,040:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:10,360:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:10,718:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:10,739:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:10,885:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:11,007:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:11,375:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:11,539:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:11,680:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:12,206:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:13:18,966:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:13:19,568:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-28 05:14:32,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:14:32,753:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:14:33,133:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:14:33,153:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:14:33,522:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:14:33,873:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:14:34,441:INFO:Calculating mean and std
2024-06-28 05:14:34,452:INFO:Creating metrics dataframe
2024-06-28 05:14:34,480:INFO:Uploading results into container
2024-06-28 05:14:34,486:INFO:Uploading model into container now
2024-06-28 05:14:34,486:INFO:_master_model_container: 9
2024-06-28 05:14:34,486:INFO:_display_container: 2
2024-06-28 05:14:34,486:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1207)
2024-06-28 05:14:34,486:INFO:create_model() successfully completed......................................
2024-06-28 05:14:34,601:INFO:SubProcess create_model() end ==================================
2024-06-28 05:14:34,601:INFO:Creating metrics dataframe
2024-06-28 05:14:34,601:INFO:Initializing Gradient Boosting Classifier
2024-06-28 05:14:34,601:INFO:Total runtime is 47.1306916753451 minutes
2024-06-28 05:14:34,617:INFO:SubProcess create_model() called ==================================
2024-06-28 05:14:34,617:INFO:Initializing create_model()
2024-06-28 05:14:34,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:14:34,617:INFO:Checking exceptions
2024-06-28 05:14:34,617:INFO:Importing libraries
2024-06-28 05:14:34,617:INFO:Copying training dataset
2024-06-28 05:14:35,118:INFO:Defining folds
2024-06-28 05:14:35,118:INFO:Declaring metric variables
2024-06-28 05:14:35,118:INFO:Importing untrained model
2024-06-28 05:14:35,135:INFO:Gradient Boosting Classifier Imported successfully
2024-06-28 05:14:35,150:INFO:Starting cross validation
2024-06-28 05:14:35,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:23:23,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:24,451:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:25,079:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:25,663:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:25,996:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:26,354:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:26,697:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:27,035:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:27,334:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:27,870:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:28,611:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:23:29,268:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:49,790:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:50,386:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:51,036:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:51,986:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:52,536:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:52,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:53,143:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:53,278:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:53,787:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:53,988:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:54,687:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:32:55,271:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:33,484:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:33,856:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:34,084:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:34,232:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:34,446:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:34,795:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:35,294:INFO:Calculating mean and std
2024-06-28 05:38:35,299:INFO:Creating metrics dataframe
2024-06-28 05:38:35,307:INFO:Uploading results into container
2024-06-28 05:38:35,308:INFO:Uploading model into container now
2024-06-28 05:38:35,308:INFO:_master_model_container: 10
2024-06-28 05:38:35,309:INFO:_display_container: 2
2024-06-28 05:38:35,310:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-28 05:38:35,310:INFO:create_model() successfully completed......................................
2024-06-28 05:38:35,402:INFO:SubProcess create_model() end ==================================
2024-06-28 05:38:35,417:INFO:Creating metrics dataframe
2024-06-28 05:38:35,418:INFO:Initializing Linear Discriminant Analysis
2024-06-28 05:38:35,418:INFO:Total runtime is 71.14431599775949 minutes
2024-06-28 05:38:35,418:INFO:SubProcess create_model() called ==================================
2024-06-28 05:38:35,418:INFO:Initializing create_model()
2024-06-28 05:38:35,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:38:35,435:INFO:Checking exceptions
2024-06-28 05:38:35,435:INFO:Importing libraries
2024-06-28 05:38:35,435:INFO:Copying training dataset
2024-06-28 05:38:35,935:INFO:Defining folds
2024-06-28 05:38:35,935:INFO:Declaring metric variables
2024-06-28 05:38:35,954:INFO:Importing untrained model
2024-06-28 05:38:35,954:INFO:Linear Discriminant Analysis Imported successfully
2024-06-28 05:38:35,969:INFO:Starting cross validation
2024-06-28 05:38:35,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:38:58,893:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:58,977:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:59,510:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:38:59,643:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:00,223:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:00,360:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:09,099:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:09,166:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:09,799:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:09,847:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:10,480:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:10,530:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:24,935:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:25,126:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:25,619:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:25,796:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:26,269:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:26,435:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:36,022:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:36,106:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:36,689:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:36,787:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:37,406:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:37,474:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:47,576:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:47,654:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:47,908:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:47,992:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:48,303:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:48,410:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:39:49,053:INFO:Calculating mean and std
2024-06-28 05:39:49,053:INFO:Creating metrics dataframe
2024-06-28 05:39:49,062:INFO:Uploading results into container
2024-06-28 05:39:49,063:INFO:Uploading model into container now
2024-06-28 05:39:49,063:INFO:_master_model_container: 11
2024-06-28 05:39:49,063:INFO:_display_container: 2
2024-06-28 05:39:49,063:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-28 05:39:49,063:INFO:create_model() successfully completed......................................
2024-06-28 05:39:49,160:INFO:SubProcess create_model() end ==================================
2024-06-28 05:39:49,176:INFO:Creating metrics dataframe
2024-06-28 05:39:49,176:INFO:Initializing Extra Trees Classifier
2024-06-28 05:39:49,176:INFO:Total runtime is 72.37361613512039 minutes
2024-06-28 05:39:49,193:INFO:SubProcess create_model() called ==================================
2024-06-28 05:39:49,193:INFO:Initializing create_model()
2024-06-28 05:39:49,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:39:49,193:INFO:Checking exceptions
2024-06-28 05:39:49,193:INFO:Importing libraries
2024-06-28 05:39:49,193:INFO:Copying training dataset
2024-06-28 05:39:49,793:INFO:Defining folds
2024-06-28 05:39:49,793:INFO:Declaring metric variables
2024-06-28 05:39:49,798:INFO:Importing untrained model
2024-06-28 05:39:49,798:INFO:Extra Trees Classifier Imported successfully
2024-06-28 05:39:49,813:INFO:Starting cross validation
2024-06-28 05:39:49,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:43:08,777:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:09,465:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:09,704:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:09,813:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,044:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,177:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,344:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,453:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,680:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,811:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:10,996:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:43:11,371:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:43,736:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:44,611:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:44,973:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:45,786:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:45,886:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:46,080:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:46,235:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:46,452:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:46,521:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:46,896:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:47,160:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:46:47,690:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:30,485:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:31,231:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:31,369:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:31,747:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:31,871:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:32,358:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:48:33,002:INFO:Calculating mean and std
2024-06-28 05:48:33,003:INFO:Creating metrics dataframe
2024-06-28 05:48:33,003:INFO:Uploading results into container
2024-06-28 05:48:33,003:INFO:Uploading model into container now
2024-06-28 05:48:33,003:INFO:_master_model_container: 12
2024-06-28 05:48:33,003:INFO:_display_container: 2
2024-06-28 05:48:33,003:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1207, verbose=0,
                     warm_start=False)
2024-06-28 05:48:33,011:INFO:create_model() successfully completed......................................
2024-06-28 05:48:33,103:INFO:SubProcess create_model() end ==================================
2024-06-28 05:48:33,103:INFO:Creating metrics dataframe
2024-06-28 05:48:33,120:INFO:Initializing Light Gradient Boosting Machine
2024-06-28 05:48:33,120:INFO:Total runtime is 81.10600073734919 minutes
2024-06-28 05:48:33,136:INFO:SubProcess create_model() called ==================================
2024-06-28 05:48:33,136:INFO:Initializing create_model()
2024-06-28 05:48:33,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:48:33,136:INFO:Checking exceptions
2024-06-28 05:48:33,136:INFO:Importing libraries
2024-06-28 05:48:33,136:INFO:Copying training dataset
2024-06-28 05:48:33,637:INFO:Defining folds
2024-06-28 05:48:33,637:INFO:Declaring metric variables
2024-06-28 05:48:33,653:INFO:Importing untrained model
2024-06-28 05:48:33,657:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-28 05:48:33,672:INFO:Starting cross validation
2024-06-28 05:48:33,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:49:08,064:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:08,119:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:08,785:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:08,866:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:09,499:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:09,570:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:12,300:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:12,350:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:13,047:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:13,071:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:13,757:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:13,805:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:42,929:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:42,995:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:43,582:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:43,649:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:44,269:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:44,308:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:46,036:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:46,327:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:46,862:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:47,126:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:47,812:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:49:48,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:04,702:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:05,193:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:05,789:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:05,884:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:06,249:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:06,544:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:07,026:INFO:Calculating mean and std
2024-06-28 05:50:07,026:INFO:Creating metrics dataframe
2024-06-28 05:50:07,026:INFO:Uploading results into container
2024-06-28 05:50:07,032:INFO:Uploading model into container now
2024-06-28 05:50:07,034:INFO:_master_model_container: 13
2024-06-28 05:50:07,034:INFO:_display_container: 2
2024-06-28 05:50:07,037:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1207, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 05:50:07,037:INFO:create_model() successfully completed......................................
2024-06-28 05:50:07,134:INFO:SubProcess create_model() end ==================================
2024-06-28 05:50:07,134:INFO:Creating metrics dataframe
2024-06-28 05:50:07,139:INFO:Initializing Dummy Classifier
2024-06-28 05:50:07,139:INFO:Total runtime is 82.67299920717875 minutes
2024-06-28 05:50:07,155:INFO:SubProcess create_model() called ==================================
2024-06-28 05:50:07,155:INFO:Initializing create_model()
2024-06-28 05:50:07,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBE91B290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:50:07,155:INFO:Checking exceptions
2024-06-28 05:50:07,155:INFO:Importing libraries
2024-06-28 05:50:07,155:INFO:Copying training dataset
2024-06-28 05:50:07,687:INFO:Defining folds
2024-06-28 05:50:07,687:INFO:Declaring metric variables
2024-06-28 05:50:07,687:INFO:Importing untrained model
2024-06-28 05:50:07,704:INFO:Dummy Classifier Imported successfully
2024-06-28 05:50:07,720:INFO:Starting cross validation
2024-06-28 05:50:07,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 05:50:19,865:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,063:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,092:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,121:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,497:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,724:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,740:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,773:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:20,873:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:21,101:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:21,123:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:21,140:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:21,195:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:21,373:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:21,425:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:21,475:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:34,473:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:34,686:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:34,737:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:34,878:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:35,101:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:35,357:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:35,389:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:35,483:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:35,530:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:35,733:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:35,743:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:35,773:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:35,905:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:36,007:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:36,037:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:36,189:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:45,916:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:46,117:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:46,285:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:46,448:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:46,481:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:46,648:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:46,686:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-06-28 05:50:46,843:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 05:50:47,415:INFO:Calculating mean and std
2024-06-28 05:50:47,415:INFO:Creating metrics dataframe
2024-06-28 05:50:47,415:INFO:Uploading results into container
2024-06-28 05:50:47,415:INFO:Uploading model into container now
2024-06-28 05:50:47,415:INFO:_master_model_container: 14
2024-06-28 05:50:47,415:INFO:_display_container: 2
2024-06-28 05:50:47,415:INFO:DummyClassifier(constant=None, random_state=1207, strategy='prior')
2024-06-28 05:50:47,415:INFO:create_model() successfully completed......................................
2024-06-28 05:50:47,533:INFO:SubProcess create_model() end ==================================
2024-06-28 05:50:47,533:INFO:Creating metrics dataframe
2024-06-28 05:50:47,567:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-28 05:50:47,587:INFO:Initializing create_model()
2024-06-28 05:50:47,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBB129BD90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1207, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:50:47,589:INFO:Checking exceptions
2024-06-28 05:50:47,591:INFO:Importing libraries
2024-06-28 05:50:47,591:INFO:Copying training dataset
2024-06-28 05:50:48,098:INFO:Defining folds
2024-06-28 05:50:48,098:INFO:Declaring metric variables
2024-06-28 05:50:48,098:INFO:Importing untrained model
2024-06-28 05:50:48,098:INFO:Declaring custom model
2024-06-28 05:50:48,098:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-28 05:50:48,098:INFO:Cross validation set to False
2024-06-28 05:50:48,098:INFO:Fitting Model
2024-06-28 05:50:54,367:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-28 05:50:54,384:INFO:[LightGBM] [Info] Number of positive: 289869, number of negative: 36530
2024-06-28 05:50:54,500:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092061 seconds.
2024-06-28 05:50:54,500:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-28 05:50:54,500:INFO:[LightGBM] [Info] Total Bins 5728
2024-06-28 05:50:54,500:INFO:[LightGBM] [Info] Number of data points in the train set: 326399, number of used features: 75
2024-06-28 05:50:54,517:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.888082 -> initscore=2.071295
2024-06-28 05:50:54,517:INFO:[LightGBM] [Info] Start training from score 2.071295
2024-06-28 05:51:01,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1207, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 05:51:01,487:INFO:create_model() successfully completed......................................
2024-06-28 05:51:01,691:INFO:_master_model_container: 14
2024-06-28 05:51:01,691:INFO:_display_container: 2
2024-06-28 05:51:01,692:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1207, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 05:51:01,693:INFO:compare_models() successfully completed......................................
2024-06-28 05:51:02,054:INFO:PyCaret ClassificationExperiment
2024-06-28 05:51:02,054:INFO:Logging name: clf-default-name
2024-06-28 05:51:02,054:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-28 05:51:02,054:INFO:version 3.3.2
2024-06-28 05:51:02,054:INFO:Initializing setup()
2024-06-28 05:51:02,054:INFO:self.USI: 2f19
2024-06-28 05:51:02,054:INFO:self._variable_keys: {'idx', 'logging_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X', '_available_plots', 'gpu_param', '_ml_usecase', 'data', 'fold_shuffle_param', 'y_train', 'y_test', 'pipeline', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'log_plots_param', 'X_train', 'X_test', 'n_jobs_param', 'seed', 'memory', 'fold_generator', 'USI', 'fix_imbalance', 'y'}
2024-06-28 05:51:02,054:INFO:Checking environment
2024-06-28 05:51:02,054:INFO:python_version: 3.11.7
2024-06-28 05:51:02,054:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-28 05:51:02,054:INFO:machine: AMD64
2024-06-28 05:51:02,054:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-28 05:51:02,054:INFO:Memory: svmem(total=12756160512, available=6371729408, percent=50.0, used=6384431104, free=6371729408)
2024-06-28 05:51:02,054:INFO:Physical Core: 2
2024-06-28 05:51:02,054:INFO:Logical Core: 4
2024-06-28 05:51:02,054:INFO:Checking libraries
2024-06-28 05:51:02,054:INFO:System:
2024-06-28 05:51:02,054:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-28 05:51:02,054:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-28 05:51:02,054:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-28 05:51:02,054:INFO:PyCaret required dependencies:
2024-06-28 05:51:02,054:INFO:                 pip: 24.0
2024-06-28 05:51:02,054:INFO:          setuptools: 69.5.1
2024-06-28 05:51:02,054:INFO:             pycaret: 3.3.2
2024-06-28 05:51:02,054:INFO:             IPython: 8.24.0
2024-06-28 05:51:02,054:INFO:          ipywidgets: 8.1.3
2024-06-28 05:51:02,054:INFO:                tqdm: 4.66.4
2024-06-28 05:51:02,054:INFO:               numpy: 1.26.4
2024-06-28 05:51:02,054:INFO:              pandas: 2.1.4
2024-06-28 05:51:02,054:INFO:              jinja2: 3.1.4
2024-06-28 05:51:02,054:INFO:               scipy: 1.11.4
2024-06-28 05:51:02,054:INFO:              joblib: 1.3.2
2024-06-28 05:51:02,054:INFO:             sklearn: 1.4.2
2024-06-28 05:51:02,054:INFO:                pyod: 2.0.1
2024-06-28 05:51:02,054:INFO:            imblearn: 0.12.3
2024-06-28 05:51:02,054:INFO:   category_encoders: 2.6.3
2024-06-28 05:51:02,054:INFO:            lightgbm: 4.4.0
2024-06-28 05:51:02,054:INFO:               numba: 0.60.0
2024-06-28 05:51:02,054:INFO:            requests: 2.32.3
2024-06-28 05:51:02,054:INFO:          matplotlib: 3.7.5
2024-06-28 05:51:02,054:INFO:          scikitplot: 0.3.7
2024-06-28 05:51:02,054:INFO:         yellowbrick: 1.5
2024-06-28 05:51:02,054:INFO:              plotly: 5.22.0
2024-06-28 05:51:02,054:INFO:    plotly-resampler: Not installed
2024-06-28 05:51:02,054:INFO:             kaleido: 0.2.1
2024-06-28 05:51:02,054:INFO:           schemdraw: 0.15
2024-06-28 05:51:02,054:INFO:         statsmodels: 0.14.2
2024-06-28 05:51:02,054:INFO:              sktime: 0.26.0
2024-06-28 05:51:02,054:INFO:               tbats: 1.1.3
2024-06-28 05:51:02,054:INFO:            pmdarima: 2.0.4
2024-06-28 05:51:02,054:INFO:              psutil: 5.9.8
2024-06-28 05:51:02,054:INFO:          markupsafe: 2.1.5
2024-06-28 05:51:02,054:INFO:             pickle5: Not installed
2024-06-28 05:51:02,054:INFO:         cloudpickle: 3.0.0
2024-06-28 05:51:02,054:INFO:         deprecation: 2.1.0
2024-06-28 05:51:02,054:INFO:              xxhash: 3.4.1
2024-06-28 05:51:02,054:INFO:           wurlitzer: Not installed
2024-06-28 05:51:02,054:INFO:PyCaret optional dependencies:
2024-06-28 05:51:02,054:INFO:                shap: 0.44.1
2024-06-28 05:51:02,054:INFO:           interpret: 0.6.2
2024-06-28 05:51:02,054:INFO:                umap: 0.5.6
2024-06-28 05:51:02,054:INFO:     ydata_profiling: 4.8.3
2024-06-28 05:51:02,054:INFO:  explainerdashboard: 0.4.7
2024-06-28 05:51:02,054:INFO:             autoviz: Not installed
2024-06-28 05:51:02,054:INFO:           fairlearn: 0.7.0
2024-06-28 05:51:02,054:INFO:          deepchecks: Not installed
2024-06-28 05:51:02,054:INFO:             xgboost: Not installed
2024-06-28 05:51:02,054:INFO:            catboost: Not installed
2024-06-28 05:51:02,054:INFO:              kmodes: Not installed
2024-06-28 05:51:02,054:INFO:             mlxtend: Not installed
2024-06-28 05:51:02,054:INFO:       statsforecast: Not installed
2024-06-28 05:51:02,054:INFO:        tune_sklearn: Not installed
2024-06-28 05:51:02,054:INFO:                 ray: Not installed
2024-06-28 05:51:02,054:INFO:            hyperopt: Not installed
2024-06-28 05:51:02,054:INFO:              optuna: Not installed
2024-06-28 05:51:02,054:INFO:               skopt: Not installed
2024-06-28 05:51:02,054:INFO:              mlflow: Not installed
2024-06-28 05:51:02,054:INFO:              gradio: Not installed
2024-06-28 05:51:02,054:INFO:             fastapi: Not installed
2024-06-28 05:51:02,054:INFO:             uvicorn: Not installed
2024-06-28 05:51:02,054:INFO:              m2cgen: Not installed
2024-06-28 05:51:02,054:INFO:           evidently: Not installed
2024-06-28 05:51:02,054:INFO:               fugue: Not installed
2024-06-28 05:51:02,054:INFO:           streamlit: Not installed
2024-06-28 05:51:02,054:INFO:             prophet: Not installed
2024-06-28 05:51:02,054:INFO:None
2024-06-28 05:51:02,054:INFO:Set up data.
2024-06-28 05:51:02,824:INFO:Set up folding strategy.
2024-06-28 05:51:02,824:INFO:Set up train/test split.
2024-06-28 05:51:03,804:INFO:Set up index.
2024-06-28 05:51:03,824:INFO:Assigning column types.
2024-06-28 05:51:04,223:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-28 05:51:04,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 05:51:04,287:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 05:51:04,333:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 05:51:04,386:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 05:51:04,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,417:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-28 05:51:04,480:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 05:51:04,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,574:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 05:51:04,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,622:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-28 05:51:04,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:04,804:INFO:Preparing preprocessing pipeline...
2024-06-28 05:51:04,856:INFO:Set up label encoding.
2024-06-28 05:51:04,856:INFO:Set up date feature engineering.
2024-06-28 05:51:04,856:INFO:Set up simple imputation.
2024-06-28 05:51:05,068:INFO:Set up encoding of ordinal features.
2024-06-28 05:51:05,271:INFO:Set up encoding of categorical features.
2024-06-28 05:51:05,291:INFO:Set up imbalanced handling.
2024-06-28 05:51:13,470:INFO:Finished creating preprocessing pipeline.
2024-06-28 05:51:13,501:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-06-28 05:51:13,501:INFO:Creating final display dataframe.
2024-06-28 05:51:52,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-06-28 05:51:53,753:INFO:Setup _display_container:                     Description             Value
0                    Session id              8934
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (719624, 80)
6   Transformed train set shape      (579738, 80)
7    Transformed test set shape      (139886, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2f19
2024-06-28 05:51:54,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:54,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:54,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:54,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 05:51:54,104:INFO:setup() successfully completed in 52.15s...............
2024-06-28 05:51:54,138:INFO:Initializing compare_models()
2024-06-28 05:51:54,138:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBBBC178D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FBBBC178D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-28 05:51:54,138:INFO:Checking exceptions
2024-06-28 05:51:54,451:INFO:Preparing display monitor
2024-06-28 05:51:54,504:INFO:Initializing Logistic Regression
2024-06-28 05:51:54,506:INFO:Total runtime is 2.132256825764974e-05 minutes
2024-06-28 05:51:54,513:INFO:SubProcess create_model() called ==================================
2024-06-28 05:51:54,513:INFO:Initializing create_model()
2024-06-28 05:51:54,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBBBC178D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBAF170D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 05:51:54,514:INFO:Checking exceptions
2024-06-28 05:51:54,514:INFO:Importing libraries
2024-06-28 05:51:54,514:INFO:Copying training dataset
2024-06-28 05:51:55,022:INFO:Defining folds
2024-06-28 05:51:55,022:INFO:Declaring metric variables
2024-06-28 05:51:55,022:INFO:Importing untrained model
2024-06-28 05:51:55,038:INFO:Logistic Regression Imported successfully
2024-06-28 05:51:55,038:INFO:Starting cross validation
2024-06-28 05:51:55,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 06:10:16,360:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:10:17,293:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:10:18,326:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:10:19,343:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:10:20,210:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:21,499:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:22,414:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:23,498:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:24,497:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:25,365:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:26,265:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:27,182:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:11:28,066:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\1369100065.py:9: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.countplot(data=df, x=categories[i], palette=palette) # Plot the i-th category

2024-06-28 06:19:21,480:INFO:PyCaret ClassificationExperiment
2024-06-28 06:19:21,491:INFO:Logging name: clf-default-name
2024-06-28 06:19:21,491:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-28 06:19:21,491:INFO:version 3.3.2
2024-06-28 06:19:21,491:INFO:Initializing setup()
2024-06-28 06:19:21,491:INFO:self.USI: 8fea
2024-06-28 06:19:21,491:INFO:self._variable_keys: {'idx', 'logging_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X', '_available_plots', 'gpu_param', '_ml_usecase', 'data', 'fold_shuffle_param', 'y_train', 'y_test', 'pipeline', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'log_plots_param', 'X_train', 'X_test', 'n_jobs_param', 'seed', 'memory', 'fold_generator', 'USI', 'fix_imbalance', 'y'}
2024-06-28 06:19:21,491:INFO:Checking environment
2024-06-28 06:19:21,491:INFO:python_version: 3.11.7
2024-06-28 06:19:21,491:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-28 06:19:21,491:INFO:machine: AMD64
2024-06-28 06:19:21,491:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-28 06:19:21,491:INFO:Memory: svmem(total=12756160512, available=5869764608, percent=54.0, used=6886395904, free=5869764608)
2024-06-28 06:19:21,491:INFO:Physical Core: 2
2024-06-28 06:19:21,491:INFO:Logical Core: 4
2024-06-28 06:19:21,491:INFO:Checking libraries
2024-06-28 06:19:21,491:INFO:System:
2024-06-28 06:19:21,491:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-28 06:19:21,491:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-28 06:19:21,491:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-28 06:19:21,491:INFO:PyCaret required dependencies:
2024-06-28 06:19:21,491:INFO:                 pip: 24.0
2024-06-28 06:19:21,491:INFO:          setuptools: 69.5.1
2024-06-28 06:19:21,491:INFO:             pycaret: 3.3.2
2024-06-28 06:19:21,491:INFO:             IPython: 8.24.0
2024-06-28 06:19:21,491:INFO:          ipywidgets: 8.1.3
2024-06-28 06:19:21,491:INFO:                tqdm: 4.66.4
2024-06-28 06:19:21,491:INFO:               numpy: 1.26.4
2024-06-28 06:19:21,491:INFO:              pandas: 2.1.4
2024-06-28 06:19:21,491:INFO:              jinja2: 3.1.4
2024-06-28 06:19:21,491:INFO:               scipy: 1.11.4
2024-06-28 06:19:21,491:INFO:              joblib: 1.3.2
2024-06-28 06:19:21,491:INFO:             sklearn: 1.4.2
2024-06-28 06:19:21,491:INFO:                pyod: 2.0.1
2024-06-28 06:19:21,491:INFO:            imblearn: 0.12.3
2024-06-28 06:19:21,491:INFO:   category_encoders: 2.6.3
2024-06-28 06:19:21,491:INFO:            lightgbm: 4.4.0
2024-06-28 06:19:21,491:INFO:               numba: 0.60.0
2024-06-28 06:19:21,491:INFO:            requests: 2.32.3
2024-06-28 06:19:21,491:INFO:          matplotlib: 3.7.5
2024-06-28 06:19:21,491:INFO:          scikitplot: 0.3.7
2024-06-28 06:19:21,491:INFO:         yellowbrick: 1.5
2024-06-28 06:19:21,491:INFO:              plotly: 5.22.0
2024-06-28 06:19:21,491:INFO:    plotly-resampler: Not installed
2024-06-28 06:19:21,491:INFO:             kaleido: 0.2.1
2024-06-28 06:19:21,491:INFO:           schemdraw: 0.15
2024-06-28 06:19:21,491:INFO:         statsmodels: 0.14.2
2024-06-28 06:19:21,491:INFO:              sktime: 0.26.0
2024-06-28 06:19:21,491:INFO:               tbats: 1.1.3
2024-06-28 06:19:21,491:INFO:            pmdarima: 2.0.4
2024-06-28 06:19:21,491:INFO:              psutil: 5.9.8
2024-06-28 06:19:21,491:INFO:          markupsafe: 2.1.5
2024-06-28 06:19:21,491:INFO:             pickle5: Not installed
2024-06-28 06:19:21,491:INFO:         cloudpickle: 3.0.0
2024-06-28 06:19:21,491:INFO:         deprecation: 2.1.0
2024-06-28 06:19:21,491:INFO:              xxhash: 3.4.1
2024-06-28 06:19:21,491:INFO:           wurlitzer: Not installed
2024-06-28 06:19:21,491:INFO:PyCaret optional dependencies:
2024-06-28 06:19:21,491:INFO:                shap: 0.44.1
2024-06-28 06:19:21,491:INFO:           interpret: 0.6.2
2024-06-28 06:19:21,491:INFO:                umap: 0.5.6
2024-06-28 06:19:21,491:INFO:     ydata_profiling: 4.8.3
2024-06-28 06:19:21,491:INFO:  explainerdashboard: 0.4.7
2024-06-28 06:19:21,491:INFO:             autoviz: Not installed
2024-06-28 06:19:21,491:INFO:           fairlearn: 0.7.0
2024-06-28 06:19:21,491:INFO:          deepchecks: Not installed
2024-06-28 06:19:21,491:INFO:             xgboost: Not installed
2024-06-28 06:19:21,491:INFO:            catboost: Not installed
2024-06-28 06:19:21,491:INFO:              kmodes: Not installed
2024-06-28 06:19:21,491:INFO:             mlxtend: Not installed
2024-06-28 06:19:21,491:INFO:       statsforecast: Not installed
2024-06-28 06:19:21,491:INFO:        tune_sklearn: Not installed
2024-06-28 06:19:21,491:INFO:                 ray: Not installed
2024-06-28 06:19:21,491:INFO:            hyperopt: Not installed
2024-06-28 06:19:21,491:INFO:              optuna: Not installed
2024-06-28 06:19:21,491:INFO:               skopt: Not installed
2024-06-28 06:19:21,491:INFO:              mlflow: Not installed
2024-06-28 06:19:21,491:INFO:              gradio: Not installed
2024-06-28 06:19:21,491:INFO:             fastapi: Not installed
2024-06-28 06:19:21,491:INFO:             uvicorn: Not installed
2024-06-28 06:19:21,491:INFO:              m2cgen: Not installed
2024-06-28 06:19:21,491:INFO:           evidently: Not installed
2024-06-28 06:19:21,491:INFO:               fugue: Not installed
2024-06-28 06:19:21,491:INFO:           streamlit: Not installed
2024-06-28 06:19:21,491:INFO:             prophet: Not installed
2024-06-28 06:19:21,491:INFO:None
2024-06-28 06:19:21,491:INFO:Set up data.
2024-06-28 06:19:22,159:INFO:Set up folding strategy.
2024-06-28 06:19:22,159:INFO:Set up train/test split.
2024-06-28 06:19:23,076:INFO:Set up index.
2024-06-28 06:19:23,092:INFO:Assigning column types.
2024-06-28 06:19:23,492:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-28 06:19:23,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 06:19:23,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 06:19:23,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 06:19:23,625:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 06:19:23,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,659:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-28 06:19:23,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 06:19:23,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 06:19:23,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,842:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-28 06:19:23,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:23,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:24,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:24,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:24,025:INFO:Preparing preprocessing pipeline...
2024-06-28 06:19:24,076:INFO:Set up label encoding.
2024-06-28 06:19:24,076:INFO:Set up date feature engineering.
2024-06-28 06:19:24,076:INFO:Set up simple imputation.
2024-06-28 06:19:24,276:INFO:Set up encoding of ordinal features.
2024-06-28 06:19:24,493:INFO:Set up encoding of categorical features.
2024-06-28 06:19:31,329:INFO:Finished creating preprocessing pipeline.
2024-06-28 06:19:31,362:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['grade', 'emp_length',
                                             'home_ownership',
                                             'verification_status', 'purpose'],
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-28 06:19:31,362:INFO:Creating final display dataframe.
2024-06-28 06:19:41,099:INFO:Setup _display_container:                     Description             Value
0                    Session id              6703
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (466285, 80)
6   Transformed train set shape      (326399, 80)
7    Transformed test set shape      (139886, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              8fea
2024-06-28 06:19:41,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:41,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:41,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:41,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 06:19:41,314:INFO:setup() successfully completed in 19.91s...............
2024-06-28 06:19:42,248:INFO:Initializing compare_models()
2024-06-28 06:19:42,248:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, include=['lr', 'dt', 'rf', 'gbc', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, 'include': ['lr', 'dt', 'rf', 'gbc', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-28 06:19:42,248:INFO:Checking exceptions
2024-06-28 06:19:42,655:INFO:Preparing display monitor
2024-06-28 06:19:42,710:INFO:Initializing Logistic Regression
2024-06-28 06:19:42,711:INFO:Total runtime is 1.6971429189046225e-05 minutes
2024-06-28 06:19:42,720:INFO:SubProcess create_model() called ==================================
2024-06-28 06:19:42,721:INFO:Initializing create_model()
2024-06-28 06:19:42,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB9D4DF7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 06:19:42,722:INFO:Checking exceptions
2024-06-28 06:19:42,722:INFO:Importing libraries
2024-06-28 06:19:42,722:INFO:Copying training dataset
2024-06-28 06:19:43,225:INFO:Defining folds
2024-06-28 06:19:43,225:INFO:Declaring metric variables
2024-06-28 06:19:43,225:INFO:Importing untrained model
2024-06-28 06:19:43,240:INFO:Logistic Regression Imported successfully
2024-06-28 06:19:43,256:INFO:Starting cross validation
2024-06-28 06:19:43,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 06:23:12,308:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:23:12,886:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:23:13,187:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:23:13,254:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:23:13,676:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,157:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,237:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,437:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,761:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,804:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:14,967:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:15,014:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:15,319:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:15,524:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:23:15,587:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:53,041:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:25:54,381:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:25:54,468:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:55,047:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:55,617:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:55,660:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:55,809:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:25:56,257:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:56,258:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:25:56,911:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:57,065:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:57,509:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:57,642:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:58,136:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:58,249:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:25:58,715:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:35,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:27:35,408:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 06:27:35,941:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:36,146:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:36,248:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:36,453:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:36,546:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:36,763:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:27:37,325:INFO:Calculating mean and std
2024-06-28 06:27:37,325:INFO:Creating metrics dataframe
2024-06-28 06:27:37,343:INFO:Uploading results into container
2024-06-28 06:27:37,343:INFO:Uploading model into container now
2024-06-28 06:27:37,343:INFO:_master_model_container: 1
2024-06-28 06:27:37,343:INFO:_display_container: 2
2024-06-28 06:27:37,343:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6703, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-28 06:27:37,343:INFO:create_model() successfully completed......................................
2024-06-28 06:27:37,775:INFO:SubProcess create_model() end ==================================
2024-06-28 06:27:37,775:INFO:Creating metrics dataframe
2024-06-28 06:27:37,793:INFO:Initializing Decision Tree Classifier
2024-06-28 06:27:37,793:INFO:Total runtime is 7.91804035504659 minutes
2024-06-28 06:27:37,799:INFO:SubProcess create_model() called ==================================
2024-06-28 06:27:37,799:INFO:Initializing create_model()
2024-06-28 06:27:37,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB9D4DF7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 06:27:37,800:INFO:Checking exceptions
2024-06-28 06:27:37,800:INFO:Importing libraries
2024-06-28 06:27:37,800:INFO:Copying training dataset
2024-06-28 06:27:38,359:INFO:Defining folds
2024-06-28 06:27:38,359:INFO:Declaring metric variables
2024-06-28 06:27:38,359:INFO:Importing untrained model
2024-06-28 06:27:38,376:INFO:Decision Tree Classifier Imported successfully
2024-06-28 06:27:38,392:INFO:Starting cross validation
2024-06-28 06:27:38,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 06:28:24,465:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:25,075:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:25,778:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:26,432:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:26,779:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:26,779:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:27,092:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:27,418:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:27,428:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:27,729:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:28,094:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:28:28,098:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:12,341:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:12,924:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:13,530:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:15,642:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:16,125:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:16,325:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:16,759:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:16,799:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:16,975:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:17,359:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:17,425:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:17,976:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:44,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:44,500:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:44,824:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:48,036:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:48,287:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:48,545:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:29:49,007:INFO:Calculating mean and std
2024-06-28 06:29:49,007:INFO:Creating metrics dataframe
2024-06-28 06:29:49,007:INFO:Uploading results into container
2024-06-28 06:29:49,007:INFO:Uploading model into container now
2024-06-28 06:29:49,007:INFO:_master_model_container: 2
2024-06-28 06:29:49,007:INFO:_display_container: 2
2024-06-28 06:29:49,007:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6703, splitter='best')
2024-06-28 06:29:49,007:INFO:create_model() successfully completed......................................
2024-06-28 06:29:49,203:INFO:SubProcess create_model() end ==================================
2024-06-28 06:29:49,203:INFO:Creating metrics dataframe
2024-06-28 06:29:49,219:INFO:Initializing Random Forest Classifier
2024-06-28 06:29:49,219:INFO:Total runtime is 10.10848227739334 minutes
2024-06-28 06:29:49,219:INFO:SubProcess create_model() called ==================================
2024-06-28 06:29:49,219:INFO:Initializing create_model()
2024-06-28 06:29:49,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB9D4DF7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 06:29:49,219:INFO:Checking exceptions
2024-06-28 06:29:49,219:INFO:Importing libraries
2024-06-28 06:29:49,219:INFO:Copying training dataset
2024-06-28 06:29:49,767:INFO:Defining folds
2024-06-28 06:29:49,768:INFO:Declaring metric variables
2024-06-28 06:29:49,770:INFO:Importing untrained model
2024-06-28 06:29:49,770:INFO:Random Forest Classifier Imported successfully
2024-06-28 06:29:49,786:INFO:Starting cross validation
2024-06-28 06:29:49,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 06:34:09,123:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:09,123:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:09,865:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:10,410:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:10,445:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:10,620:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:10,880:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:11,189:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:11,189:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:11,474:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:12,056:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:34:12,580:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:31,617:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:32,729:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:32,979:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:33,266:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:33,823:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:33,919:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:34,179:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:34,263:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:34,554:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:34,834:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:34,924:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:38:35,546:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:38,779:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:39,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:40,183:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:40,427:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:40,855:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:41,157:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:40:41,808:INFO:Calculating mean and std
2024-06-28 06:40:41,825:INFO:Creating metrics dataframe
2024-06-28 06:40:41,825:INFO:Uploading results into container
2024-06-28 06:40:41,839:INFO:Uploading model into container now
2024-06-28 06:40:41,840:INFO:_master_model_container: 3
2024-06-28 06:40:41,840:INFO:_display_container: 2
2024-06-28 06:40:41,842:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6703, verbose=0,
                       warm_start=False)
2024-06-28 06:40:41,842:INFO:create_model() successfully completed......................................
2024-06-28 06:40:42,039:INFO:SubProcess create_model() end ==================================
2024-06-28 06:40:42,039:INFO:Creating metrics dataframe
2024-06-28 06:40:42,056:INFO:Initializing Gradient Boosting Classifier
2024-06-28 06:40:42,056:INFO:Total runtime is 20.98908676703771 minutes
2024-06-28 06:40:42,056:INFO:SubProcess create_model() called ==================================
2024-06-28 06:40:42,056:INFO:Initializing create_model()
2024-06-28 06:40:42,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB9D4DF7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 06:40:42,056:INFO:Checking exceptions
2024-06-28 06:40:42,056:INFO:Importing libraries
2024-06-28 06:40:42,056:INFO:Copying training dataset
2024-06-28 06:40:42,556:INFO:Defining folds
2024-06-28 06:40:42,572:INFO:Declaring metric variables
2024-06-28 06:40:42,578:INFO:Importing untrained model
2024-06-28 06:40:42,584:INFO:Gradient Boosting Classifier Imported successfully
2024-06-28 06:40:42,589:INFO:Starting cross validation
2024-06-28 06:40:42,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 06:49:24,134:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:24,586:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:24,682:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:24,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:25,215:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:25,315:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:25,465:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:25,648:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:25,867:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:25,966:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:26,283:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:49:27,036:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:03,439:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:03,756:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:04,072:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:04,205:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:04,384:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:04,723:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:04,840:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:05,006:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:05,457:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:06,788:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:07,409:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 06:58:08,007:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:43,230:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:43,263:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:43,555:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:43,586:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:43,901:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:43,951:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:03:44,503:INFO:Calculating mean and std
2024-06-28 07:03:44,503:INFO:Creating metrics dataframe
2024-06-28 07:03:44,519:INFO:Uploading results into container
2024-06-28 07:03:44,519:INFO:Uploading model into container now
2024-06-28 07:03:44,519:INFO:_master_model_container: 4
2024-06-28 07:03:44,519:INFO:_display_container: 2
2024-06-28 07:03:44,519:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6703, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-28 07:03:44,519:INFO:create_model() successfully completed......................................
2024-06-28 07:03:44,722:INFO:SubProcess create_model() end ==================================
2024-06-28 07:03:44,722:INFO:Creating metrics dataframe
2024-06-28 07:03:44,738:INFO:Initializing Light Gradient Boosting Machine
2024-06-28 07:03:44,738:INFO:Total runtime is 44.03379011551539 minutes
2024-06-28 07:03:44,738:INFO:SubProcess create_model() called ==================================
2024-06-28 07:03:44,738:INFO:Initializing create_model()
2024-06-28 07:03:44,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB9D4DF7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 07:03:44,738:INFO:Checking exceptions
2024-06-28 07:03:44,738:INFO:Importing libraries
2024-06-28 07:03:44,738:INFO:Copying training dataset
2024-06-28 07:03:45,222:INFO:Defining folds
2024-06-28 07:03:45,222:INFO:Declaring metric variables
2024-06-28 07:03:45,238:INFO:Importing untrained model
2024-06-28 07:03:45,238:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-28 07:03:45,253:INFO:Starting cross validation
2024-06-28 07:03:45,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 07:04:15,621:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:16,213:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:16,806:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:18,848:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:19,519:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:20,189:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:22,187:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:22,791:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:23,447:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:25,028:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:25,709:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:26,385:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:49,839:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:50,296:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:50,521:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:50,914:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:51,139:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:51,536:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:55,834:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:56,577:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:57,024:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:57,251:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:57,684:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:04:58,475:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:11,718:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:12,276:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:12,701:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:12,770:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:13,029:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:13,348:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:05:13,845:INFO:Calculating mean and std
2024-06-28 07:05:13,849:INFO:Creating metrics dataframe
2024-06-28 07:05:13,863:INFO:Uploading results into container
2024-06-28 07:05:13,865:INFO:Uploading model into container now
2024-06-28 07:05:13,867:INFO:_master_model_container: 5
2024-06-28 07:05:13,867:INFO:_display_container: 2
2024-06-28 07:05:13,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 07:05:13,869:INFO:create_model() successfully completed......................................
2024-06-28 07:05:14,040:INFO:SubProcess create_model() end ==================================
2024-06-28 07:05:14,040:INFO:Creating metrics dataframe
2024-06-28 07:05:14,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-28 07:05:14,070:INFO:Initializing create_model()
2024-06-28 07:05:14,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 07:05:14,071:INFO:Checking exceptions
2024-06-28 07:05:14,073:INFO:Importing libraries
2024-06-28 07:05:14,073:INFO:Copying training dataset
2024-06-28 07:05:14,567:INFO:Defining folds
2024-06-28 07:05:14,567:INFO:Declaring metric variables
2024-06-28 07:05:14,568:INFO:Importing untrained model
2024-06-28 07:05:14,568:INFO:Declaring custom model
2024-06-28 07:05:14,568:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-28 07:05:14,571:INFO:Cross validation set to False
2024-06-28 07:05:14,571:INFO:Fitting Model
2024-06-28 07:05:22,153:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-28 07:05:22,170:INFO:[LightGBM] [Info] Number of positive: 289869, number of negative: 36530
2024-06-28 07:05:22,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099577 seconds.
2024-06-28 07:05:22,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-28 07:05:22,295:INFO:[LightGBM] [Info] Total Bins 5721
2024-06-28 07:05:22,295:INFO:[LightGBM] [Info] Number of data points in the train set: 326399, number of used features: 75
2024-06-28 07:05:22,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.888082 -> initscore=2.071295
2024-06-28 07:05:22,295:INFO:[LightGBM] [Info] Start training from score 2.071295
2024-06-28 07:05:28,039:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 07:05:28,039:INFO:create_model() successfully completed......................................
2024-06-28 07:05:28,289:INFO:_master_model_container: 5
2024-06-28 07:05:28,289:INFO:_display_container: 2
2024-06-28 07:05:28,289:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 07:05:28,289:INFO:compare_models() successfully completed......................................
2024-06-28 07:05:28,307:INFO:Initializing plot_model()
2024-06-28 07:05:28,307:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-28 07:05:28,307:INFO:Checking exceptions
2024-06-28 07:05:28,510:INFO:Preloading libraries
2024-06-28 07:05:28,524:INFO:Copying training dataset
2024-06-28 07:05:28,524:INFO:Plot type: confusion_matrix
2024-06-28 07:05:30,816:INFO:Fitting Model
2024-06-28 07:05:30,816:INFO:Scoring test/hold-out set
2024-06-28 07:05:31,975:INFO:Visual Rendered Successfully
2024-06-28 07:05:32,178:INFO:plot_model() successfully completed......................................
2024-06-28 07:05:32,197:INFO:Initializing plot_model()
2024-06-28 07:05:32,197:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-28 07:05:32,197:INFO:Checking exceptions
2024-06-28 07:05:32,369:INFO:Preloading libraries
2024-06-28 07:05:32,397:INFO:Copying training dataset
2024-06-28 07:05:32,397:INFO:Plot type: auc
2024-06-28 07:05:34,685:INFO:Fitting Model
2024-06-28 07:05:34,701:INFO:Scoring test/hold-out set
2024-06-28 07:05:36,259:INFO:Visual Rendered Successfully
2024-06-28 07:05:36,492:INFO:plot_model() successfully completed......................................
2024-06-28 07:05:36,511:INFO:Initializing evaluate_model()
2024-06-28 07:05:36,524:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-28 07:05:36,811:INFO:Initializing plot_model()
2024-06-28 07:05:36,811:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-28 07:05:36,811:INFO:Checking exceptions
2024-06-28 07:05:36,994:INFO:Preloading libraries
2024-06-28 07:05:37,010:INFO:Copying training dataset
2024-06-28 07:05:37,010:INFO:Plot type: pipeline
2024-06-28 07:05:38,393:INFO:Visual Rendered Successfully
2024-06-28 07:05:38,590:INFO:plot_model() successfully completed......................................
2024-06-28 07:05:38,858:INFO:PyCaret ClassificationExperiment
2024-06-28 07:05:38,858:INFO:Logging name: clf-default-name
2024-06-28 07:05:38,858:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-28 07:05:38,858:INFO:version 3.3.2
2024-06-28 07:05:38,858:INFO:Initializing setup()
2024-06-28 07:05:38,858:INFO:self.USI: 2dfd
2024-06-28 07:05:38,858:INFO:self._variable_keys: {'idx', 'logging_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'X', '_available_plots', 'gpu_param', '_ml_usecase', 'data', 'fold_shuffle_param', 'y_train', 'y_test', 'pipeline', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'log_plots_param', 'X_train', 'X_test', 'n_jobs_param', 'seed', 'memory', 'fold_generator', 'USI', 'fix_imbalance', 'y'}
2024-06-28 07:05:38,858:INFO:Checking environment
2024-06-28 07:05:38,858:INFO:python_version: 3.11.7
2024-06-28 07:05:38,858:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-28 07:05:38,858:INFO:machine: AMD64
2024-06-28 07:05:38,858:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-28 07:05:38,858:INFO:Memory: svmem(total=12756160512, available=6360596480, percent=50.1, used=6395564032, free=6360596480)
2024-06-28 07:05:38,858:INFO:Physical Core: 2
2024-06-28 07:05:38,858:INFO:Logical Core: 4
2024-06-28 07:05:38,858:INFO:Checking libraries
2024-06-28 07:05:38,858:INFO:System:
2024-06-28 07:05:38,858:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-28 07:05:38,858:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-28 07:05:38,858:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-28 07:05:38,858:INFO:PyCaret required dependencies:
2024-06-28 07:05:38,858:INFO:                 pip: 24.0
2024-06-28 07:05:38,858:INFO:          setuptools: 69.5.1
2024-06-28 07:05:38,858:INFO:             pycaret: 3.3.2
2024-06-28 07:05:38,858:INFO:             IPython: 8.24.0
2024-06-28 07:05:38,858:INFO:          ipywidgets: 8.1.3
2024-06-28 07:05:38,858:INFO:                tqdm: 4.66.4
2024-06-28 07:05:38,858:INFO:               numpy: 1.26.4
2024-06-28 07:05:38,858:INFO:              pandas: 2.1.4
2024-06-28 07:05:38,858:INFO:              jinja2: 3.1.4
2024-06-28 07:05:38,858:INFO:               scipy: 1.11.4
2024-06-28 07:05:38,858:INFO:              joblib: 1.3.2
2024-06-28 07:05:38,858:INFO:             sklearn: 1.4.2
2024-06-28 07:05:38,858:INFO:                pyod: 2.0.1
2024-06-28 07:05:38,858:INFO:            imblearn: 0.12.3
2024-06-28 07:05:38,858:INFO:   category_encoders: 2.6.3
2024-06-28 07:05:38,858:INFO:            lightgbm: 4.4.0
2024-06-28 07:05:38,858:INFO:               numba: 0.60.0
2024-06-28 07:05:38,858:INFO:            requests: 2.32.3
2024-06-28 07:05:38,858:INFO:          matplotlib: 3.7.5
2024-06-28 07:05:38,858:INFO:          scikitplot: 0.3.7
2024-06-28 07:05:38,858:INFO:         yellowbrick: 1.5
2024-06-28 07:05:38,858:INFO:              plotly: 5.22.0
2024-06-28 07:05:38,858:INFO:    plotly-resampler: Not installed
2024-06-28 07:05:38,858:INFO:             kaleido: 0.2.1
2024-06-28 07:05:38,858:INFO:           schemdraw: 0.15
2024-06-28 07:05:38,858:INFO:         statsmodels: 0.14.2
2024-06-28 07:05:38,858:INFO:              sktime: 0.26.0
2024-06-28 07:05:38,858:INFO:               tbats: 1.1.3
2024-06-28 07:05:38,858:INFO:            pmdarima: 2.0.4
2024-06-28 07:05:38,858:INFO:              psutil: 5.9.8
2024-06-28 07:05:38,858:INFO:          markupsafe: 2.1.5
2024-06-28 07:05:38,858:INFO:             pickle5: Not installed
2024-06-28 07:05:38,858:INFO:         cloudpickle: 3.0.0
2024-06-28 07:05:38,858:INFO:         deprecation: 2.1.0
2024-06-28 07:05:38,858:INFO:              xxhash: 3.4.1
2024-06-28 07:05:38,858:INFO:           wurlitzer: Not installed
2024-06-28 07:05:38,858:INFO:PyCaret optional dependencies:
2024-06-28 07:05:38,858:INFO:                shap: 0.44.1
2024-06-28 07:05:38,858:INFO:           interpret: 0.6.2
2024-06-28 07:05:38,858:INFO:                umap: 0.5.6
2024-06-28 07:05:38,858:INFO:     ydata_profiling: 4.8.3
2024-06-28 07:05:38,858:INFO:  explainerdashboard: 0.4.7
2024-06-28 07:05:38,858:INFO:             autoviz: Not installed
2024-06-28 07:05:38,858:INFO:           fairlearn: 0.7.0
2024-06-28 07:05:38,858:INFO:          deepchecks: Not installed
2024-06-28 07:05:38,858:INFO:             xgboost: Not installed
2024-06-28 07:05:38,858:INFO:            catboost: Not installed
2024-06-28 07:05:38,858:INFO:              kmodes: Not installed
2024-06-28 07:05:38,858:INFO:             mlxtend: Not installed
2024-06-28 07:05:38,858:INFO:       statsforecast: Not installed
2024-06-28 07:05:38,858:INFO:        tune_sklearn: Not installed
2024-06-28 07:05:38,858:INFO:                 ray: Not installed
2024-06-28 07:05:38,858:INFO:            hyperopt: Not installed
2024-06-28 07:05:38,858:INFO:              optuna: Not installed
2024-06-28 07:05:38,858:INFO:               skopt: Not installed
2024-06-28 07:05:38,858:INFO:              mlflow: Not installed
2024-06-28 07:05:38,858:INFO:              gradio: Not installed
2024-06-28 07:05:38,858:INFO:             fastapi: Not installed
2024-06-28 07:05:38,858:INFO:             uvicorn: Not installed
2024-06-28 07:05:38,858:INFO:              m2cgen: Not installed
2024-06-28 07:05:38,858:INFO:           evidently: Not installed
2024-06-28 07:05:38,858:INFO:               fugue: Not installed
2024-06-28 07:05:38,858:INFO:           streamlit: Not installed
2024-06-28 07:05:38,858:INFO:             prophet: Not installed
2024-06-28 07:05:38,858:INFO:None
2024-06-28 07:05:38,858:INFO:Set up data.
2024-06-28 07:05:39,547:INFO:Set up folding strategy.
2024-06-28 07:05:39,547:INFO:Set up train/test split.
2024-06-28 07:05:40,396:INFO:Set up index.
2024-06-28 07:05:40,427:INFO:Assigning column types.
2024-06-28 07:05:40,802:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-28 07:05:40,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 07:05:40,861:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 07:05:40,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:40,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:40,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-28 07:05:40,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 07:05:40,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:40,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:40,986:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-28 07:05:41,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 07:05:41,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-28 07:05:41,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,178:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-28 07:05:41,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:05:41,381:INFO:Preparing preprocessing pipeline...
2024-06-28 07:05:41,422:INFO:Set up label encoding.
2024-06-28 07:05:41,422:INFO:Set up date feature engineering.
2024-06-28 07:05:41,422:INFO:Set up simple imputation.
2024-06-28 07:05:41,645:INFO:Set up encoding of ordinal features.
2024-06-28 07:05:41,849:INFO:Set up encoding of categorical features.
2024-06-28 07:05:41,864:INFO:Set up imbalanced handling.
2024-06-28 07:05:50,965:INFO:Finished creating preprocessing pipeline.
2024-06-28 07:05:51,001:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-06-28 07:05:51,001:INFO:Creating final display dataframe.
2024-06-28 07:06:33,105:INFO:Setup _display_container:                     Description             Value
0                    Session id              7030
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (719624, 80)
6   Transformed train set shape      (579738, 80)
7    Transformed test set shape      (139886, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              2dfd
2024-06-28 07:06:33,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:06:33,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:06:33,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:06:33,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-28 07:06:33,363:INFO:setup() successfully completed in 54.57s...............
2024-06-28 07:06:34,072:INFO:Initializing compare_models()
2024-06-28 07:06:34,072:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, include=['lr', 'dt', 'rf', 'gbc', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, 'include': ['lr', 'dt', 'rf', 'gbc', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-28 07:06:34,072:INFO:Checking exceptions
2024-06-28 07:06:34,431:INFO:Preparing display monitor
2024-06-28 07:06:34,503:INFO:Initializing Logistic Regression
2024-06-28 07:06:34,503:INFO:Total runtime is 1.6669432322184246e-05 minutes
2024-06-28 07:06:34,513:INFO:SubProcess create_model() called ==================================
2024-06-28 07:06:34,514:INFO:Initializing create_model()
2024-06-28 07:06:34,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBAD970D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 07:06:34,515:INFO:Checking exceptions
2024-06-28 07:06:34,515:INFO:Importing libraries
2024-06-28 07:06:34,515:INFO:Copying training dataset
2024-06-28 07:06:35,147:INFO:Defining folds
2024-06-28 07:06:35,147:INFO:Declaring metric variables
2024-06-28 07:06:35,164:INFO:Importing untrained model
2024-06-28 07:06:35,169:INFO:Logistic Regression Imported successfully
2024-06-28 07:06:35,180:INFO:Starting cross validation
2024-06-28 07:06:35,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 07:11:58,930:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:12:00,688:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:01,230:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:12:01,273:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:12:01,378:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:02,012:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:02,088:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:12:02,672:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:02,722:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:03,409:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:03,419:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:03,459:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:04,069:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:04,084:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:04,098:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:12:04,708:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:37,942:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:17:39,385:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:39,935:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:40,169:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:17:40,285:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:17:40,471:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:41,491:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:41,512:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:42,110:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:42,136:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:42,764:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:42,792:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:43,307:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:17:44,590:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:45,229:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:17:45,840:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:45,614:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:20:46,451:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:46,848:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:47,162:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-28 07:20:47,189:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:47,897:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:48,156:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:48,424:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:20:48,910:INFO:Calculating mean and std
2024-06-28 07:20:48,910:INFO:Creating metrics dataframe
2024-06-28 07:20:48,910:INFO:Uploading results into container
2024-06-28 07:20:48,910:INFO:Uploading model into container now
2024-06-28 07:20:48,910:INFO:_master_model_container: 1
2024-06-28 07:20:48,910:INFO:_display_container: 2
2024-06-28 07:20:48,925:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7030, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-28 07:20:48,925:INFO:create_model() successfully completed......................................
2024-06-28 07:20:49,113:INFO:SubProcess create_model() end ==================================
2024-06-28 07:20:49,113:INFO:Creating metrics dataframe
2024-06-28 07:20:49,113:INFO:Initializing Decision Tree Classifier
2024-06-28 07:20:49,113:INFO:Total runtime is 14.243507305781046 minutes
2024-06-28 07:20:49,128:INFO:SubProcess create_model() called ==================================
2024-06-28 07:20:49,128:INFO:Initializing create_model()
2024-06-28 07:20:49,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBAD970D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 07:20:49,128:INFO:Checking exceptions
2024-06-28 07:20:49,128:INFO:Importing libraries
2024-06-28 07:20:49,128:INFO:Copying training dataset
2024-06-28 07:20:49,667:INFO:Defining folds
2024-06-28 07:20:49,667:INFO:Declaring metric variables
2024-06-28 07:20:49,683:INFO:Importing untrained model
2024-06-28 07:20:49,683:INFO:Decision Tree Classifier Imported successfully
2024-06-28 07:20:49,701:INFO:Starting cross validation
2024-06-28 07:20:49,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 07:22:25,598:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:26,220:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:26,566:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:26,602:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:26,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:26,917:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:27,474:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:27,541:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:27,792:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:27,857:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:28,214:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:22:28,450:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:09,505:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:09,994:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:10,392:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:10,429:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:10,736:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:11,144:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:11,212:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:11,237:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:11,511:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:11,883:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:11,929:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:24:12,668:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:21,327:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:21,707:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:22,085:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:22,875:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:23,149:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:23,407:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:25:23,955:INFO:Calculating mean and std
2024-06-28 07:25:23,959:INFO:Creating metrics dataframe
2024-06-28 07:25:23,965:INFO:Uploading results into container
2024-06-28 07:25:23,966:INFO:Uploading model into container now
2024-06-28 07:25:23,966:INFO:_master_model_container: 2
2024-06-28 07:25:23,966:INFO:_display_container: 2
2024-06-28 07:25:23,967:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7030, splitter='best')
2024-06-28 07:25:23,967:INFO:create_model() successfully completed......................................
2024-06-28 07:25:24,158:INFO:SubProcess create_model() end ==================================
2024-06-28 07:25:24,158:INFO:Creating metrics dataframe
2024-06-28 07:25:24,175:INFO:Initializing Random Forest Classifier
2024-06-28 07:25:24,175:INFO:Total runtime is 18.82787392139435 minutes
2024-06-28 07:25:24,179:INFO:SubProcess create_model() called ==================================
2024-06-28 07:25:24,180:INFO:Initializing create_model()
2024-06-28 07:25:24,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBAD970D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 07:25:24,180:INFO:Checking exceptions
2024-06-28 07:25:24,180:INFO:Importing libraries
2024-06-28 07:25:24,181:INFO:Copying training dataset
2024-06-28 07:25:24,691:INFO:Defining folds
2024-06-28 07:25:24,691:INFO:Declaring metric variables
2024-06-28 07:25:24,691:INFO:Importing untrained model
2024-06-28 07:25:24,708:INFO:Random Forest Classifier Imported successfully
2024-06-28 07:25:24,708:INFO:Starting cross validation
2024-06-28 07:25:24,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 07:33:05,255:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:06,531:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:07,726:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:07,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:08,004:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:08,077:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:08,358:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:08,614:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:08,699:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:09,096:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:09,475:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:33:09,577:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:53,442:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:54,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:55,626:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:57,741:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:58,103:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:58,615:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:59,134:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:40:59,817:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:41:00,582:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:41:01,076:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:41:01,881:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:41:02,518:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:49,052:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:49,605:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:50,090:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:53,270:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:53,576:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:53,907:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 07:44:54,679:INFO:Calculating mean and std
2024-06-28 07:44:54,690:INFO:Creating metrics dataframe
2024-06-28 07:44:54,698:INFO:Uploading results into container
2024-06-28 07:44:54,701:INFO:Uploading model into container now
2024-06-28 07:44:54,701:INFO:_master_model_container: 3
2024-06-28 07:44:54,701:INFO:_display_container: 2
2024-06-28 07:44:54,701:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7030, verbose=0,
                       warm_start=False)
2024-06-28 07:44:54,701:INFO:create_model() successfully completed......................................
2024-06-28 07:44:54,901:INFO:SubProcess create_model() end ==================================
2024-06-28 07:44:54,901:INFO:Creating metrics dataframe
2024-06-28 07:44:54,917:INFO:Initializing Gradient Boosting Classifier
2024-06-28 07:44:54,917:INFO:Total runtime is 38.34024392366409 minutes
2024-06-28 07:44:54,917:INFO:SubProcess create_model() called ==================================
2024-06-28 07:44:54,917:INFO:Initializing create_model()
2024-06-28 07:44:54,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBAD970D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 07:44:54,917:INFO:Checking exceptions
2024-06-28 07:44:54,917:INFO:Importing libraries
2024-06-28 07:44:54,917:INFO:Copying training dataset
2024-06-28 07:44:55,425:INFO:Defining folds
2024-06-28 07:44:55,425:INFO:Declaring metric variables
2024-06-28 07:44:55,425:INFO:Importing untrained model
2024-06-28 07:44:55,425:INFO:Gradient Boosting Classifier Imported successfully
2024-06-28 07:44:55,440:INFO:Starting cross validation
2024-06-28 07:44:55,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 08:10:49,775:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:50,309:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:50,427:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:50,883:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:51,070:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:51,666:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:54,120:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:54,661:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:54,826:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:55,220:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:55,387:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:10:55,998:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:37,372:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:37,940:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:38,539:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:43,150:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:43,796:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:44,424:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:47,242:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:47,908:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:48,476:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:52,444:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:53,080:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:34:53,712:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:19,590:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:19,957:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:20,294:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:20,695:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:21,006:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:21,264:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:50:21,731:INFO:Calculating mean and std
2024-06-28 08:50:21,740:INFO:Creating metrics dataframe
2024-06-28 08:50:21,756:INFO:Uploading results into container
2024-06-28 08:50:21,758:INFO:Uploading model into container now
2024-06-28 08:50:21,759:INFO:_master_model_container: 4
2024-06-28 08:50:21,759:INFO:_display_container: 2
2024-06-28 08:50:21,760:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7030, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-28 08:50:21,760:INFO:create_model() successfully completed......................................
2024-06-28 08:50:22,039:INFO:SubProcess create_model() end ==================================
2024-06-28 08:50:22,039:INFO:Creating metrics dataframe
2024-06-28 08:50:22,066:INFO:Initializing Light Gradient Boosting Machine
2024-06-28 08:50:22,067:INFO:Total runtime is 103.79272277355194 minutes
2024-06-28 08:50:22,073:INFO:SubProcess create_model() called ==================================
2024-06-28 08:50:22,073:INFO:Initializing create_model()
2024-06-28 08:50:22,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FBBAD970D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 08:50:22,073:INFO:Checking exceptions
2024-06-28 08:50:22,073:INFO:Importing libraries
2024-06-28 08:50:22,073:INFO:Copying training dataset
2024-06-28 08:50:22,605:INFO:Defining folds
2024-06-28 08:50:22,606:INFO:Declaring metric variables
2024-06-28 08:50:22,606:INFO:Importing untrained model
2024-06-28 08:50:22,615:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-28 08:50:22,625:INFO:Starting cross validation
2024-06-28 08:50:22,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-28 08:51:20,830:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:51:21,836:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:51:22,326:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:51:22,759:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:51:23,132:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:51:23,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:12,476:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:12,477:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:13,118:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:13,120:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:13,713:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:13,734:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:29,879:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:29,879:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:30,550:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:30,569:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:31,245:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:52:31,272:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:22,346:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:22,501:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:22,994:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:23,143:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:23,606:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:23,745:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:31,926:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:31,946:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:32,426:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:32,457:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:32,919:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:32,970:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:53:33,649:INFO:Calculating mean and std
2024-06-28 08:53:33,649:INFO:Creating metrics dataframe
2024-06-28 08:53:33,665:INFO:Uploading results into container
2024-06-28 08:53:33,665:INFO:Uploading model into container now
2024-06-28 08:53:33,665:INFO:_master_model_container: 5
2024-06-28 08:53:33,665:INFO:_display_container: 2
2024-06-28 08:53:33,665:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 08:53:33,665:INFO:create_model() successfully completed......................................
2024-06-28 08:53:33,868:INFO:SubProcess create_model() end ==================================
2024-06-28 08:53:33,868:INFO:Creating metrics dataframe
2024-06-28 08:53:33,884:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-28 08:53:33,884:INFO:Initializing create_model()
2024-06-28 08:53:33,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-28 08:53:33,899:INFO:Checking exceptions
2024-06-28 08:53:33,899:INFO:Importing libraries
2024-06-28 08:53:33,899:INFO:Copying training dataset
2024-06-28 08:53:34,356:INFO:Defining folds
2024-06-28 08:53:34,356:INFO:Declaring metric variables
2024-06-28 08:53:34,356:INFO:Importing untrained model
2024-06-28 08:53:34,356:INFO:Declaring custom model
2024-06-28 08:53:34,356:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-28 08:53:34,372:INFO:Cross validation set to False
2024-06-28 08:53:34,372:INFO:Fitting Model
2024-06-28 08:53:51,029:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-28 08:53:51,089:INFO:[LightGBM] [Info] Number of positive: 289869, number of negative: 289869
2024-06-28 08:53:51,516:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169976 seconds.
2024-06-28 08:53:51,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-28 08:53:51,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-28 08:53:51,516:INFO:[LightGBM] [Info] Total Bins 16700
2024-06-28 08:53:51,516:INFO:[LightGBM] [Info] Number of data points in the train set: 579738, number of used features: 75
2024-06-28 08:53:51,516:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-28 08:53:58,904:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 08:53:58,904:INFO:create_model() successfully completed......................................
2024-06-28 08:53:59,124:INFO:_master_model_container: 5
2024-06-28 08:53:59,124:INFO:_display_container: 2
2024-06-28 08:53:59,124:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-28 08:53:59,124:INFO:compare_models() successfully completed......................................
2024-06-28 08:53:59,179:INFO:Initializing plot_model()
2024-06-28 08:53:59,179:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-28 08:53:59,179:INFO:Checking exceptions
2024-06-28 08:53:59,367:INFO:Preloading libraries
2024-06-28 08:53:59,383:INFO:Copying training dataset
2024-06-28 08:53:59,383:INFO:Plot type: confusion_matrix
2024-06-28 08:54:06,456:INFO:Fitting Model
2024-06-28 08:54:06,463:INFO:Scoring test/hold-out set
2024-06-28 08:54:07,562:INFO:Visual Rendered Successfully
2024-06-28 08:54:07,765:INFO:plot_model() successfully completed......................................
2024-06-28 08:54:07,795:INFO:Initializing plot_model()
2024-06-28 08:54:07,795:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-28 08:54:07,795:INFO:Checking exceptions
2024-06-28 08:54:07,951:INFO:Preloading libraries
2024-06-28 08:54:07,966:INFO:Copying training dataset
2024-06-28 08:54:07,966:INFO:Plot type: auc
2024-06-28 08:54:10,589:INFO:Fitting Model
2024-06-28 08:54:10,589:INFO:Scoring test/hold-out set
2024-06-28 08:54:12,502:INFO:Visual Rendered Successfully
2024-06-28 08:54:12,707:INFO:plot_model() successfully completed......................................
2024-06-28 08:54:12,737:INFO:Initializing evaluate_model()
2024-06-28 08:54:12,737:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-28 08:54:12,965:INFO:Initializing plot_model()
2024-06-28 08:54:12,966:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-28 08:54:12,967:INFO:Checking exceptions
2024-06-28 08:54:13,151:INFO:Preloading libraries
2024-06-28 08:54:13,170:INFO:Copying training dataset
2024-06-28 08:54:13,170:INFO:Plot type: pipeline
2024-06-28 08:54:13,460:INFO:Visual Rendered Successfully
2024-06-28 08:54:13,632:INFO:plot_model() successfully completed......................................
2024-06-28 08:54:13,667:INFO:Initializing predict_model()
2024-06-28 08:54:13,667:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB82E9F600>)
2024-06-28 08:54:13,667:INFO:Checking exceptions
2024-06-28 08:54:13,667:INFO:Preloading libraries
2024-06-28 08:54:17,156:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:54:18,422:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 08:54:19,672:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-28 09:11:34,959:INFO:Initializing plot_model()
2024-06-28 09:11:34,960:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FBDD0E0650>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7030, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-28 09:11:34,961:INFO:Checking exceptions
2024-06-28 09:11:35,173:INFO:Preloading libraries
2024-06-28 09:11:35,205:INFO:Copying training dataset
2024-06-28 09:11:35,205:INFO:Plot type: feature
2024-06-28 09:11:35,330:WARNING:No coef_ found. Trying feature_importances_
2024-06-28 09:11:36,585:INFO:Visual Rendered Successfully
2024-06-28 09:11:36,767:INFO:plot_model() successfully completed......................................
2024-06-28 09:11:42,966:INFO:Initializing plot_model()
2024-06-28 09:11:42,966:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB99472490>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6703, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-28 09:11:42,967:INFO:Checking exceptions
2024-06-28 09:11:43,320:INFO:Preloading libraries
2024-06-28 09:11:43,335:INFO:Copying training dataset
2024-06-28 09:11:43,335:INFO:Plot type: feature
2024-06-28 09:11:43,335:WARNING:No coef_ found. Trying feature_importances_
2024-06-28 09:11:46,421:INFO:Visual Rendered Successfully
2024-06-28 09:11:46,646:INFO:plot_model() successfully completed......................................
2024-06-28 09:15:33,855:WARNING:C:\Users\USER\AppData\Local\Temp\ipykernel_15384\3684246786.py:2: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='purpose',y=res['selisih'].sort_values(ascending=False),data=res[res['status']=='bad'],palette='viridis')

2024-06-29 06:06:14,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:06:14,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:06:14,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:06:14,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:06:23,249:INFO:PyCaret ClassificationExperiment
2024-06-29 06:06:23,249:INFO:Logging name: clf-default-name
2024-06-29 06:06:23,249:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-29 06:06:23,249:INFO:version 3.3.2
2024-06-29 06:06:23,249:INFO:Initializing setup()
2024-06-29 06:06:23,249:INFO:self.USI: 604d
2024-06-29 06:06:23,249:INFO:self._variable_keys: {'y_test', 'X', 'fix_imbalance', 'memory', 'fold_shuffle_param', 'idx', 'gpu_param', 'target_param', 'data', 'pipeline', 'log_plots_param', 'USI', 'X_test', 'exp_id', 'html_param', 'is_multiclass', '_available_plots', '_ml_usecase', 'y_train', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'seed', 'gpu_n_jobs_param', 'y', 'X_train', 'fold_groups_param', 'logging_param'}
2024-06-29 06:06:23,249:INFO:Checking environment
2024-06-29 06:06:23,249:INFO:python_version: 3.11.7
2024-06-29 06:06:23,249:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-29 06:06:23,249:INFO:machine: AMD64
2024-06-29 06:06:23,249:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-29 06:06:23,249:INFO:Memory: svmem(total=12756160512, available=6802939904, percent=46.7, used=5953220608, free=6802939904)
2024-06-29 06:06:23,249:INFO:Physical Core: 2
2024-06-29 06:06:23,249:INFO:Logical Core: 4
2024-06-29 06:06:23,249:INFO:Checking libraries
2024-06-29 06:06:23,249:INFO:System:
2024-06-29 06:06:23,249:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-29 06:06:23,249:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-29 06:06:23,249:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-29 06:06:23,249:INFO:PyCaret required dependencies:
2024-06-29 06:06:23,750:INFO:                 pip: 24.0
2024-06-29 06:06:23,750:INFO:          setuptools: 69.5.1
2024-06-29 06:06:23,750:INFO:             pycaret: 3.3.2
2024-06-29 06:06:23,750:INFO:             IPython: 8.24.0
2024-06-29 06:06:23,750:INFO:          ipywidgets: 8.1.3
2024-06-29 06:06:23,750:INFO:                tqdm: 4.66.4
2024-06-29 06:06:23,750:INFO:               numpy: 1.26.4
2024-06-29 06:06:23,750:INFO:              pandas: 2.1.4
2024-06-29 06:06:23,750:INFO:              jinja2: 3.1.4
2024-06-29 06:06:23,750:INFO:               scipy: 1.11.4
2024-06-29 06:06:23,750:INFO:              joblib: 1.3.2
2024-06-29 06:06:23,750:INFO:             sklearn: 1.4.2
2024-06-29 06:06:23,750:INFO:                pyod: 2.0.1
2024-06-29 06:06:23,750:INFO:            imblearn: 0.12.3
2024-06-29 06:06:23,750:INFO:   category_encoders: 2.6.3
2024-06-29 06:06:23,750:INFO:            lightgbm: 4.4.0
2024-06-29 06:06:23,750:INFO:               numba: 0.60.0
2024-06-29 06:06:23,750:INFO:            requests: 2.32.3
2024-06-29 06:06:23,750:INFO:          matplotlib: 3.7.5
2024-06-29 06:06:23,750:INFO:          scikitplot: 0.3.7
2024-06-29 06:06:23,750:INFO:         yellowbrick: 1.5
2024-06-29 06:06:23,750:INFO:              plotly: 5.22.0
2024-06-29 06:06:23,750:INFO:    plotly-resampler: Not installed
2024-06-29 06:06:23,750:INFO:             kaleido: 0.2.1
2024-06-29 06:06:23,750:INFO:           schemdraw: 0.15
2024-06-29 06:06:23,750:INFO:         statsmodels: 0.14.2
2024-06-29 06:06:23,750:INFO:              sktime: 0.26.0
2024-06-29 06:06:23,750:INFO:               tbats: 1.1.3
2024-06-29 06:06:23,750:INFO:            pmdarima: 2.0.4
2024-06-29 06:06:23,750:INFO:              psutil: 5.9.8
2024-06-29 06:06:23,750:INFO:          markupsafe: 2.1.5
2024-06-29 06:06:23,750:INFO:             pickle5: Not installed
2024-06-29 06:06:23,750:INFO:         cloudpickle: 3.0.0
2024-06-29 06:06:23,750:INFO:         deprecation: 2.1.0
2024-06-29 06:06:23,750:INFO:              xxhash: 3.4.1
2024-06-29 06:06:23,750:INFO:           wurlitzer: Not installed
2024-06-29 06:06:23,750:INFO:PyCaret optional dependencies:
2024-06-29 06:06:23,766:INFO:                shap: 0.44.1
2024-06-29 06:06:23,766:INFO:           interpret: 0.6.2
2024-06-29 06:06:23,766:INFO:                umap: 0.5.6
2024-06-29 06:06:23,766:INFO:     ydata_profiling: 4.8.3
2024-06-29 06:06:23,766:INFO:  explainerdashboard: 0.4.7
2024-06-29 06:06:23,766:INFO:             autoviz: Not installed
2024-06-29 06:06:23,766:INFO:           fairlearn: 0.7.0
2024-06-29 06:06:23,766:INFO:          deepchecks: Not installed
2024-06-29 06:06:23,766:INFO:             xgboost: Not installed
2024-06-29 06:06:23,766:INFO:            catboost: Not installed
2024-06-29 06:06:23,766:INFO:              kmodes: Not installed
2024-06-29 06:06:23,766:INFO:             mlxtend: Not installed
2024-06-29 06:06:23,766:INFO:       statsforecast: Not installed
2024-06-29 06:06:23,766:INFO:        tune_sklearn: Not installed
2024-06-29 06:06:23,766:INFO:                 ray: Not installed
2024-06-29 06:06:23,766:INFO:            hyperopt: Not installed
2024-06-29 06:06:23,766:INFO:              optuna: Not installed
2024-06-29 06:06:23,766:INFO:               skopt: Not installed
2024-06-29 06:06:23,766:INFO:              mlflow: Not installed
2024-06-29 06:06:23,766:INFO:              gradio: Not installed
2024-06-29 06:06:23,766:INFO:             fastapi: Not installed
2024-06-29 06:06:23,766:INFO:             uvicorn: Not installed
2024-06-29 06:06:23,766:INFO:              m2cgen: Not installed
2024-06-29 06:06:23,766:INFO:           evidently: Not installed
2024-06-29 06:06:23,766:INFO:               fugue: Not installed
2024-06-29 06:06:23,766:INFO:           streamlit: Not installed
2024-06-29 06:06:23,766:INFO:             prophet: Not installed
2024-06-29 06:06:23,766:INFO:None
2024-06-29 06:06:23,766:INFO:Set up data.
2024-06-29 06:06:24,484:INFO:Set up folding strategy.
2024-06-29 06:06:24,484:INFO:Set up train/test split.
2024-06-29 06:06:25,283:INFO:Set up index.
2024-06-29 06:06:25,322:INFO:Assigning column types.
2024-06-29 06:06:25,683:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-29 06:06:25,750:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 06:06:25,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:06:25,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:25,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:25,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 06:06:25,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:06:26,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,017:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-29 06:06:26,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:06:26,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,152:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:06:26,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,184:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-29 06:06:26,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:26,370:INFO:Preparing preprocessing pipeline...
2024-06-29 06:06:26,450:INFO:Set up label encoding.
2024-06-29 06:06:26,450:INFO:Set up date feature engineering.
2024-06-29 06:06:26,450:INFO:Set up simple imputation.
2024-06-29 06:06:26,686:INFO:Set up encoding of ordinal features.
2024-06-29 06:06:26,906:INFO:Set up encoding of categorical features.
2024-06-29 06:06:35,554:INFO:Finished creating preprocessing pipeline.
2024-06-29 06:06:35,587:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['grade', 'emp_length',
                                             'home_ownership',
                                             'verification_status', 'purpose'],
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-29 06:06:35,587:INFO:Creating final display dataframe.
2024-06-29 06:06:46,158:INFO:Setup _display_container:                     Description             Value
0                    Session id               839
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (466285, 80)
6   Transformed train set shape      (373028, 80)
7    Transformed test set shape       (93257, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              604d
2024-06-29 06:06:46,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:46,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:46,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:46,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:06:46,992:INFO:setup() successfully completed in 23.83s...............
2024-06-29 06:06:47,011:INFO:Initializing compare_models()
2024-06-29 06:06:47,012:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-29 06:06:47,012:INFO:Checking exceptions
2024-06-29 06:06:47,399:INFO:Preparing display monitor
2024-06-29 06:06:47,443:INFO:Initializing Logistic Regression
2024-06-29 06:06:47,443:INFO:Total runtime is 0.0 minutes
2024-06-29 06:06:47,443:INFO:SubProcess create_model() called ==================================
2024-06-29 06:06:47,443:INFO:Initializing create_model()
2024-06-29 06:06:47,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9355DB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:06:47,443:INFO:Checking exceptions
2024-06-29 06:06:47,443:INFO:Importing libraries
2024-06-29 06:06:47,443:INFO:Copying training dataset
2024-06-29 06:06:48,058:INFO:Defining folds
2024-06-29 06:06:48,058:INFO:Declaring metric variables
2024-06-29 06:06:48,058:INFO:Importing untrained model
2024-06-29 06:06:48,058:INFO:Logistic Regression Imported successfully
2024-06-29 06:06:48,074:INFO:Starting cross validation
2024-06-29 06:06:48,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 06:09:52,133:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:09:53,612:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:54,206:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:54,697:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:09:54,787:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:09:54,837:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:55,072:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:09:56,106:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:56,239:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:56,488:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:56,825:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:56,923:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:57,221:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:57,571:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:57,638:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:09:57,972:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:48,002:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:12:49,481:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:50,114:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:50,470:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:12:50,780:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:50,814:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:12:51,941:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:52,180:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:12:52,230:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:52,664:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:52,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:53,401:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:53,597:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:53,680:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:54,421:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:12:55,090:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:34,681:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:14:34,857:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-29 06:14:35,603:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:35,765:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:36,006:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:36,165:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:36,402:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:36,555:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:14:37,194:INFO:Calculating mean and std
2024-06-29 06:14:37,201:INFO:Creating metrics dataframe
2024-06-29 06:14:37,201:INFO:Uploading results into container
2024-06-29 06:14:37,220:INFO:Uploading model into container now
2024-06-29 06:14:37,223:INFO:_master_model_container: 1
2024-06-29 06:14:37,223:INFO:_display_container: 2
2024-06-29 06:14:37,225:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=839, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-29 06:14:37,226:INFO:create_model() successfully completed......................................
2024-06-29 06:14:37,349:INFO:SubProcess create_model() end ==================================
2024-06-29 06:14:37,349:INFO:Creating metrics dataframe
2024-06-29 06:14:37,368:INFO:Initializing Decision Tree Classifier
2024-06-29 06:14:37,368:INFO:Total runtime is 7.832085311412811 minutes
2024-06-29 06:14:37,368:INFO:SubProcess create_model() called ==================================
2024-06-29 06:14:37,368:INFO:Initializing create_model()
2024-06-29 06:14:37,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9355DB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:14:37,368:INFO:Checking exceptions
2024-06-29 06:14:37,368:INFO:Importing libraries
2024-06-29 06:14:37,368:INFO:Copying training dataset
2024-06-29 06:14:37,982:INFO:Defining folds
2024-06-29 06:14:37,982:INFO:Declaring metric variables
2024-06-29 06:14:37,982:INFO:Importing untrained model
2024-06-29 06:14:38,000:INFO:Decision Tree Classifier Imported successfully
2024-06-29 06:14:38,000:INFO:Starting cross validation
2024-06-29 06:14:38,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 06:15:35,742:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:36,120:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:36,258:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:36,487:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:36,603:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:36,980:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:37,070:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:37,322:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:37,459:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:37,804:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:37,907:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:15:38,137:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:33,409:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:34,122:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:34,822:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:35,996:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:36,565:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:36,796:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:37,389:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:37,693:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:38,106:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:38,292:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:39,093:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:16:39,817:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:14,692:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:15,119:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:15,571:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:16,231:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:16,636:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:17,072:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:17:17,882:INFO:Calculating mean and std
2024-06-29 06:17:17,882:INFO:Creating metrics dataframe
2024-06-29 06:17:17,891:INFO:Uploading results into container
2024-06-29 06:17:17,893:INFO:Uploading model into container now
2024-06-29 06:17:17,895:INFO:_master_model_container: 2
2024-06-29 06:17:17,895:INFO:_display_container: 2
2024-06-29 06:17:17,897:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=839, splitter='best')
2024-06-29 06:17:17,897:INFO:create_model() successfully completed......................................
2024-06-29 06:17:18,007:INFO:SubProcess create_model() end ==================================
2024-06-29 06:17:18,007:INFO:Creating metrics dataframe
2024-06-29 06:17:18,020:INFO:Initializing Random Forest Classifier
2024-06-29 06:17:18,020:INFO:Total runtime is 10.509620106220245 minutes
2024-06-29 06:17:18,020:INFO:SubProcess create_model() called ==================================
2024-06-29 06:17:18,020:INFO:Initializing create_model()
2024-06-29 06:17:18,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9355DB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:17:18,020:INFO:Checking exceptions
2024-06-29 06:17:18,020:INFO:Importing libraries
2024-06-29 06:17:18,020:INFO:Copying training dataset
2024-06-29 06:17:18,640:INFO:Defining folds
2024-06-29 06:17:18,640:INFO:Declaring metric variables
2024-06-29 06:17:18,654:INFO:Importing untrained model
2024-06-29 06:17:18,654:INFO:Random Forest Classifier Imported successfully
2024-06-29 06:17:18,670:INFO:Starting cross validation
2024-06-29 06:17:18,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 06:22:07,684:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:08,423:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:08,877:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:08,951:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:09,271:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:09,351:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:09,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:09,751:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:10,074:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:10,118:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:10,449:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:22:10,936:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:54,548:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:55,904:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:56,028:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:57,331:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:57,476:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:57,581:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:57,835:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:58,265:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:58,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:58,665:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:59,259:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:26:59,494:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:30,340:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:31,359:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:31,605:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:32,218:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:32,470:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:33,319:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:29:34,646:INFO:Calculating mean and std
2024-06-29 06:29:34,652:INFO:Creating metrics dataframe
2024-06-29 06:29:34,658:INFO:Uploading results into container
2024-06-29 06:29:34,661:INFO:Uploading model into container now
2024-06-29 06:29:34,663:INFO:_master_model_container: 3
2024-06-29 06:29:34,663:INFO:_display_container: 2
2024-06-29 06:29:34,663:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=839, verbose=0,
                       warm_start=False)
2024-06-29 06:29:34,663:INFO:create_model() successfully completed......................................
2024-06-29 06:29:34,818:INFO:SubProcess create_model() end ==================================
2024-06-29 06:29:34,818:INFO:Creating metrics dataframe
2024-06-29 06:29:34,835:INFO:Initializing Light Gradient Boosting Machine
2024-06-29 06:29:34,835:INFO:Total runtime is 22.789868183930714 minutes
2024-06-29 06:29:34,851:INFO:SubProcess create_model() called ==================================
2024-06-29 06:29:34,852:INFO:Initializing create_model()
2024-06-29 06:29:34,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9355DB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:29:34,852:INFO:Checking exceptions
2024-06-29 06:29:34,852:INFO:Importing libraries
2024-06-29 06:29:34,853:INFO:Copying training dataset
2024-06-29 06:29:35,938:INFO:Defining folds
2024-06-29 06:29:35,938:INFO:Declaring metric variables
2024-06-29 06:29:35,954:INFO:Importing untrained model
2024-06-29 06:29:35,954:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-29 06:29:35,985:INFO:Starting cross validation
2024-06-29 06:29:35,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 06:30:14,147:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:14,198:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:14,498:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:14,931:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:15,006:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:15,293:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:15,720:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:15,798:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:16,082:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:18,349:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:19,183:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:20,116:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:52,294:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:53,067:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:53,913:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:54,597:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:55,639:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:56,550:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:56,594:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:56,629:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:57,464:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:57,596:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:58,265:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:30:58,436:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:19,388:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:19,965:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:20,144:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:20,679:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:20,826:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:21,326:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:31:22,228:INFO:Calculating mean and std
2024-06-29 06:31:22,229:INFO:Creating metrics dataframe
2024-06-29 06:31:22,237:INFO:Uploading results into container
2024-06-29 06:31:22,239:INFO:Uploading model into container now
2024-06-29 06:31:22,240:INFO:_master_model_container: 4
2024-06-29 06:31:22,240:INFO:_display_container: 2
2024-06-29 06:31:22,241:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-29 06:31:22,241:INFO:create_model() successfully completed......................................
2024-06-29 06:31:22,372:INFO:SubProcess create_model() end ==================================
2024-06-29 06:31:22,372:INFO:Creating metrics dataframe
2024-06-29 06:31:22,397:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-29 06:31:22,407:INFO:Initializing create_model()
2024-06-29 06:31:22,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:31:22,407:INFO:Checking exceptions
2024-06-29 06:31:22,420:INFO:Importing libraries
2024-06-29 06:31:22,420:INFO:Copying training dataset
2024-06-29 06:31:23,254:INFO:Defining folds
2024-06-29 06:31:23,254:INFO:Declaring metric variables
2024-06-29 06:31:23,254:INFO:Importing untrained model
2024-06-29 06:31:23,254:INFO:Declaring custom model
2024-06-29 06:31:23,254:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-29 06:31:23,254:INFO:Cross validation set to False
2024-06-29 06:31:23,254:INFO:Fitting Model
2024-06-29 06:31:31,856:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-29 06:31:31,875:INFO:[LightGBM] [Info] Number of positive: 331279, number of negative: 41749
2024-06-29 06:31:31,991:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103703 seconds.
2024-06-29 06:31:31,991:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-29 06:31:32,008:INFO:[LightGBM] [Info] Total Bins 5723
2024-06-29 06:31:32,009:INFO:[LightGBM] [Info] Number of data points in the train set: 373028, number of used features: 75
2024-06-29 06:31:32,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.888081 -> initscore=2.071285
2024-06-29 06:31:32,013:INFO:[LightGBM] [Info] Start training from score 2.071285
2024-06-29 06:31:37,727:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-29 06:31:37,727:INFO:create_model() successfully completed......................................
2024-06-29 06:31:37,903:INFO:_master_model_container: 4
2024-06-29 06:31:37,903:INFO:_display_container: 2
2024-06-29 06:31:37,903:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-29 06:31:37,908:INFO:compare_models() successfully completed......................................
2024-06-29 06:31:37,980:INFO:Initializing plot_model()
2024-06-29 06:31:37,980:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-29 06:31:37,980:INFO:Checking exceptions
2024-06-29 06:31:38,230:INFO:Preloading libraries
2024-06-29 06:31:38,243:INFO:Copying training dataset
2024-06-29 06:31:38,246:INFO:Plot type: confusion_matrix
2024-06-29 06:31:43,612:INFO:Fitting Model
2024-06-29 06:31:43,612:INFO:Scoring test/hold-out set
2024-06-29 06:31:44,565:INFO:Visual Rendered Successfully
2024-06-29 06:31:44,695:INFO:plot_model() successfully completed......................................
2024-06-29 06:31:44,715:INFO:Initializing plot_model()
2024-06-29 06:31:44,716:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-29 06:31:44,716:INFO:Checking exceptions
2024-06-29 06:31:44,928:INFO:Preloading libraries
2024-06-29 06:31:44,947:INFO:Copying training dataset
2024-06-29 06:31:44,947:INFO:Plot type: auc
2024-06-29 06:31:47,212:INFO:Fitting Model
2024-06-29 06:31:47,212:INFO:Scoring test/hold-out set
2024-06-29 06:31:48,229:INFO:Visual Rendered Successfully
2024-06-29 06:31:48,329:INFO:plot_model() successfully completed......................................
2024-06-29 06:31:48,346:INFO:Initializing evaluate_model()
2024-06-29 06:31:48,346:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 06:31:48,622:INFO:Initializing plot_model()
2024-06-29 06:31:48,622:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9C052750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=839, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 06:31:48,622:INFO:Checking exceptions
2024-06-29 06:31:48,825:INFO:Preloading libraries
2024-06-29 06:31:48,841:INFO:Copying training dataset
2024-06-29 06:31:48,841:INFO:Plot type: pipeline
2024-06-29 06:31:49,992:INFO:Visual Rendered Successfully
2024-06-29 06:31:50,085:INFO:plot_model() successfully completed......................................
2024-06-29 06:31:50,344:INFO:PyCaret ClassificationExperiment
2024-06-29 06:31:50,344:INFO:Logging name: clf-default-name
2024-06-29 06:31:50,344:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-29 06:31:50,344:INFO:version 3.3.2
2024-06-29 06:31:50,344:INFO:Initializing setup()
2024-06-29 06:31:50,344:INFO:self.USI: 24f2
2024-06-29 06:31:50,344:INFO:self._variable_keys: {'y_test', 'X', 'fix_imbalance', 'memory', 'fold_shuffle_param', 'idx', 'gpu_param', 'target_param', 'data', 'pipeline', 'log_plots_param', 'USI', 'X_test', 'exp_id', 'html_param', 'is_multiclass', '_available_plots', '_ml_usecase', 'y_train', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'seed', 'gpu_n_jobs_param', 'y', 'X_train', 'fold_groups_param', 'logging_param'}
2024-06-29 06:31:50,344:INFO:Checking environment
2024-06-29 06:31:50,344:INFO:python_version: 3.11.7
2024-06-29 06:31:50,344:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-29 06:31:50,344:INFO:machine: AMD64
2024-06-29 06:31:50,344:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-29 06:31:50,360:INFO:Memory: svmem(total=12756160512, available=6857396224, percent=46.2, used=5898764288, free=6857396224)
2024-06-29 06:31:50,360:INFO:Physical Core: 2
2024-06-29 06:31:50,360:INFO:Logical Core: 4
2024-06-29 06:31:50,360:INFO:Checking libraries
2024-06-29 06:31:50,360:INFO:System:
2024-06-29 06:31:50,360:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-29 06:31:50,360:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-29 06:31:50,360:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-29 06:31:50,360:INFO:PyCaret required dependencies:
2024-06-29 06:31:50,360:INFO:                 pip: 24.0
2024-06-29 06:31:50,360:INFO:          setuptools: 69.5.1
2024-06-29 06:31:50,360:INFO:             pycaret: 3.3.2
2024-06-29 06:31:50,360:INFO:             IPython: 8.24.0
2024-06-29 06:31:50,360:INFO:          ipywidgets: 8.1.3
2024-06-29 06:31:50,360:INFO:                tqdm: 4.66.4
2024-06-29 06:31:50,360:INFO:               numpy: 1.26.4
2024-06-29 06:31:50,360:INFO:              pandas: 2.1.4
2024-06-29 06:31:50,360:INFO:              jinja2: 3.1.4
2024-06-29 06:31:50,360:INFO:               scipy: 1.11.4
2024-06-29 06:31:50,360:INFO:              joblib: 1.3.2
2024-06-29 06:31:50,360:INFO:             sklearn: 1.4.2
2024-06-29 06:31:50,360:INFO:                pyod: 2.0.1
2024-06-29 06:31:50,360:INFO:            imblearn: 0.12.3
2024-06-29 06:31:50,360:INFO:   category_encoders: 2.6.3
2024-06-29 06:31:50,360:INFO:            lightgbm: 4.4.0
2024-06-29 06:31:50,360:INFO:               numba: 0.60.0
2024-06-29 06:31:50,360:INFO:            requests: 2.32.3
2024-06-29 06:31:50,360:INFO:          matplotlib: 3.7.5
2024-06-29 06:31:50,360:INFO:          scikitplot: 0.3.7
2024-06-29 06:31:50,360:INFO:         yellowbrick: 1.5
2024-06-29 06:31:50,360:INFO:              plotly: 5.22.0
2024-06-29 06:31:50,360:INFO:    plotly-resampler: Not installed
2024-06-29 06:31:50,360:INFO:             kaleido: 0.2.1
2024-06-29 06:31:50,360:INFO:           schemdraw: 0.15
2024-06-29 06:31:50,360:INFO:         statsmodels: 0.14.2
2024-06-29 06:31:50,360:INFO:              sktime: 0.26.0
2024-06-29 06:31:50,360:INFO:               tbats: 1.1.3
2024-06-29 06:31:50,360:INFO:            pmdarima: 2.0.4
2024-06-29 06:31:50,360:INFO:              psutil: 5.9.8
2024-06-29 06:31:50,360:INFO:          markupsafe: 2.1.5
2024-06-29 06:31:50,360:INFO:             pickle5: Not installed
2024-06-29 06:31:50,360:INFO:         cloudpickle: 3.0.0
2024-06-29 06:31:50,360:INFO:         deprecation: 2.1.0
2024-06-29 06:31:50,360:INFO:              xxhash: 3.4.1
2024-06-29 06:31:50,360:INFO:           wurlitzer: Not installed
2024-06-29 06:31:50,360:INFO:PyCaret optional dependencies:
2024-06-29 06:31:50,360:INFO:                shap: 0.44.1
2024-06-29 06:31:50,360:INFO:           interpret: 0.6.2
2024-06-29 06:31:50,360:INFO:                umap: 0.5.6
2024-06-29 06:31:50,360:INFO:     ydata_profiling: 4.8.3
2024-06-29 06:31:50,360:INFO:  explainerdashboard: 0.4.7
2024-06-29 06:31:50,360:INFO:             autoviz: Not installed
2024-06-29 06:31:50,360:INFO:           fairlearn: 0.7.0
2024-06-29 06:31:50,360:INFO:          deepchecks: Not installed
2024-06-29 06:31:50,360:INFO:             xgboost: Not installed
2024-06-29 06:31:50,360:INFO:            catboost: Not installed
2024-06-29 06:31:50,360:INFO:              kmodes: Not installed
2024-06-29 06:31:50,360:INFO:             mlxtend: Not installed
2024-06-29 06:31:50,360:INFO:       statsforecast: Not installed
2024-06-29 06:31:50,360:INFO:        tune_sklearn: Not installed
2024-06-29 06:31:50,360:INFO:                 ray: Not installed
2024-06-29 06:31:50,360:INFO:            hyperopt: Not installed
2024-06-29 06:31:50,360:INFO:              optuna: Not installed
2024-06-29 06:31:50,360:INFO:               skopt: Not installed
2024-06-29 06:31:50,360:INFO:              mlflow: Not installed
2024-06-29 06:31:50,360:INFO:              gradio: Not installed
2024-06-29 06:31:50,360:INFO:             fastapi: Not installed
2024-06-29 06:31:50,360:INFO:             uvicorn: Not installed
2024-06-29 06:31:50,360:INFO:              m2cgen: Not installed
2024-06-29 06:31:50,360:INFO:           evidently: Not installed
2024-06-29 06:31:50,360:INFO:               fugue: Not installed
2024-06-29 06:31:50,360:INFO:           streamlit: Not installed
2024-06-29 06:31:50,360:INFO:             prophet: Not installed
2024-06-29 06:31:50,360:INFO:None
2024-06-29 06:31:50,360:INFO:Set up GPU usage.
2024-06-29 06:31:50,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:50,360:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-29 06:31:50,360:INFO:Set up data.
2024-06-29 06:31:51,040:INFO:Set up folding strategy.
2024-06-29 06:31:51,040:INFO:Set up train/test split.
2024-06-29 06:31:51,804:INFO:Set up index.
2024-06-29 06:31:51,820:INFO:Assigning column types.
2024-06-29 06:31:52,195:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-29 06:31:52,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:52,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 06:31:52,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:52,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:52,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:31:52,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:52,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:52,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:31:52,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:03,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:03,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:03,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 06:32:03,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:03,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:03,424:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:32:03,424:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:03,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:03,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:03,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,135:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-29 06:32:04,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:32:04,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 06:32:04,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,652:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-29 06:32:04,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:04,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:04,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:05,001:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:05,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:05,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:05,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:32:05,174:INFO:Preparing preprocessing pipeline...
2024-06-29 06:32:05,235:INFO:Set up label encoding.
2024-06-29 06:32:05,235:INFO:Set up date feature engineering.
2024-06-29 06:32:05,235:INFO:Set up simple imputation.
2024-06-29 06:32:05,477:INFO:Set up encoding of ordinal features.
2024-06-29 06:32:05,685:INFO:Set up encoding of categorical features.
2024-06-29 06:32:05,702:INFO:Set up imbalanced handling.
2024-06-29 06:32:05,702:INFO:Set up feature normalization.
2024-06-29 06:32:30,016:INFO:Finished creating preprocessing pipeline.
2024-06-29 06:32:30,043:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-06-29 06:32:30,043:INFO:Creating final display dataframe.
2024-06-29 06:32:59,753:INFO:Setup _display_container:                     Description             Value
0                    Session id              3251
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (755815, 80)
6   Transformed train set shape      (662558, 80)
7    Transformed test set shape       (93257, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method            onehot
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU              True
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              24f2
2024-06-29 06:32:59,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:59,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:59,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:59,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:59,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:59,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:32:59,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:33:01,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:33:01,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:33:01,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:33:01,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:33:01,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:33:01,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:33:01,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 06:33:01,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:33:01,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 06:33:01,937:INFO:setup() successfully completed in 71.67s...............
2024-06-29 06:33:01,954:INFO:Initializing compare_models()
2024-06-29 06:33:01,954:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9F8E1410>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9F8E1410>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-29 06:33:01,954:INFO:Checking exceptions
2024-06-29 06:33:02,283:INFO:Preparing display monitor
2024-06-29 06:33:02,322:INFO:Initializing Logistic Regression
2024-06-29 06:33:02,322:INFO:Total runtime is 0.0 minutes
2024-06-29 06:33:02,334:INFO:SubProcess create_model() called ==================================
2024-06-29 06:33:02,334:INFO:Initializing create_model()
2024-06-29 06:33:02,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9F8E1410>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9C051550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:33:02,335:INFO:Checking exceptions
2024-06-29 06:33:02,335:INFO:Importing libraries
2024-06-29 06:33:02,335:INFO:Copying training dataset
2024-06-29 06:33:02,918:INFO:Defining folds
2024-06-29 06:33:02,918:INFO:Declaring metric variables
2024-06-29 06:33:02,918:INFO:Importing untrained model
2024-06-29 06:33:02,934:INFO:Logistic Regression Imported successfully
2024-06-29 06:33:02,934:INFO:Starting cross validation
2024-06-29 06:33:02,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-29 06:33:36,818:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:33:37,132:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:33:37,466:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:34:11,544:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:34:11,861:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:34:12,161:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:34:48,190:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:34:48,490:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:34:48,806:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:35:21,434:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:35:21,753:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:35:22,068:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:35:57,013:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:35:57,313:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:35:57,637:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:36:34,575:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:36:34,892:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:36:35,210:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:37:10,154:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:37:10,554:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:37:10,875:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:37:51,318:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:37:51,618:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:37:51,935:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:38:29,943:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:38:30,248:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:38:30,581:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:39:09,815:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:39:10,128:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:39:10,444:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:39:10,878:INFO:Calculating mean and std
2024-06-29 06:39:10,878:INFO:Creating metrics dataframe
2024-06-29 06:39:10,878:INFO:Uploading results into container
2024-06-29 06:39:10,878:INFO:Uploading model into container now
2024-06-29 06:39:10,878:INFO:_master_model_container: 1
2024-06-29 06:39:10,878:INFO:_display_container: 2
2024-06-29 06:39:10,878:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3251, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-29 06:39:10,878:INFO:create_model() successfully completed......................................
2024-06-29 06:39:10,995:INFO:SubProcess create_model() end ==================================
2024-06-29 06:39:10,995:INFO:Creating metrics dataframe
2024-06-29 06:39:11,011:INFO:Initializing Decision Tree Classifier
2024-06-29 06:39:11,011:INFO:Total runtime is 6.144827890396118 minutes
2024-06-29 06:39:11,011:INFO:SubProcess create_model() called ==================================
2024-06-29 06:39:11,011:INFO:Initializing create_model()
2024-06-29 06:39:11,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9F8E1410>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9C051550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:39:11,011:INFO:Checking exceptions
2024-06-29 06:39:11,011:INFO:Importing libraries
2024-06-29 06:39:11,011:INFO:Copying training dataset
2024-06-29 06:39:11,579:INFO:Defining folds
2024-06-29 06:39:11,579:INFO:Declaring metric variables
2024-06-29 06:39:11,579:INFO:Importing untrained model
2024-06-29 06:39:11,579:INFO:Decision Tree Classifier Imported successfully
2024-06-29 06:39:11,595:INFO:Starting cross validation
2024-06-29 06:39:11,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-29 06:39:57,419:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:39:57,727:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:39:58,044:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:40:45,276:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:40:45,577:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:40:45,893:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:41:33,676:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:41:33,993:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:41:34,310:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:42:22,324:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:42:22,637:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:42:22,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:43:11,877:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:43:12,211:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:43:12,544:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:44:05,114:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:44:05,531:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:44:05,912:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:44:58,461:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:44:58,786:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:44:59,095:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:45:51,852:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:45:52,230:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:45:52,582:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:46:43,617:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:46:43,931:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:46:44,266:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:47:38,109:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:47:38,525:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:47:39,026:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:47:39,628:INFO:Calculating mean and std
2024-06-29 06:47:39,630:INFO:Creating metrics dataframe
2024-06-29 06:47:39,636:INFO:Uploading results into container
2024-06-29 06:47:39,637:INFO:Uploading model into container now
2024-06-29 06:47:39,638:INFO:_master_model_container: 2
2024-06-29 06:47:39,638:INFO:_display_container: 2
2024-06-29 06:47:39,641:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3251, splitter='best')
2024-06-29 06:47:39,641:INFO:create_model() successfully completed......................................
2024-06-29 06:47:39,766:INFO:SubProcess create_model() end ==================================
2024-06-29 06:47:39,766:INFO:Creating metrics dataframe
2024-06-29 06:47:39,785:INFO:Initializing Random Forest Classifier
2024-06-29 06:47:39,785:INFO:Total runtime is 14.624390260378519 minutes
2024-06-29 06:47:39,792:INFO:SubProcess create_model() called ==================================
2024-06-29 06:47:39,793:INFO:Initializing create_model()
2024-06-29 06:47:39,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BC9F8E1410>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC9C051550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 06:47:39,793:INFO:Checking exceptions
2024-06-29 06:47:39,793:INFO:Importing libraries
2024-06-29 06:47:39,793:INFO:Copying training dataset
2024-06-29 06:47:40,531:INFO:Defining folds
2024-06-29 06:47:40,531:INFO:Declaring metric variables
2024-06-29 06:47:40,542:INFO:Importing untrained model
2024-06-29 06:47:40,549:INFO:Random Forest Classifier Imported successfully
2024-06-29 06:47:40,569:INFO:Starting cross validation
2024-06-29 06:47:40,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-06-29 06:50:13,001:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:50:13,368:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:50:13,702:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:52:43,235:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:52:43,686:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:52:44,068:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:55:03,115:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:55:03,448:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:55:03,782:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:57:24,579:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:57:24,896:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:57:25,232:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:59:40,808:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:59:41,142:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 06:59:41,458:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:01:58,621:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:01:59,005:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:01:59,338:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:04:17,701:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:04:18,035:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:04:18,354:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:06:03,667:INFO:PyCaret ClassificationExperiment
2024-06-29 07:06:03,667:INFO:Logging name: clf-default-name
2024-06-29 07:06:03,667:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-29 07:06:03,667:INFO:version 3.3.2
2024-06-29 07:06:03,667:INFO:Initializing setup()
2024-06-29 07:06:03,667:INFO:self.USI: 7212
2024-06-29 07:06:03,667:INFO:self._variable_keys: {'y_test', 'X', 'fix_imbalance', 'memory', 'fold_shuffle_param', 'idx', 'gpu_param', 'target_param', 'data', 'pipeline', 'log_plots_param', 'USI', 'X_test', 'exp_id', 'html_param', 'is_multiclass', '_available_plots', '_ml_usecase', 'y_train', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'seed', 'gpu_n_jobs_param', 'y', 'X_train', 'fold_groups_param', 'logging_param'}
2024-06-29 07:06:03,667:INFO:Checking environment
2024-06-29 07:06:03,667:INFO:python_version: 3.11.7
2024-06-29 07:06:03,667:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-29 07:06:03,667:INFO:machine: AMD64
2024-06-29 07:06:03,667:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-29 07:06:03,672:INFO:Memory: svmem(total=12756160512, available=6669451264, percent=47.7, used=6086709248, free=6669451264)
2024-06-29 07:06:03,672:INFO:Physical Core: 2
2024-06-29 07:06:03,672:INFO:Logical Core: 4
2024-06-29 07:06:03,672:INFO:Checking libraries
2024-06-29 07:06:03,672:INFO:System:
2024-06-29 07:06:03,672:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-29 07:06:03,672:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-29 07:06:03,672:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-29 07:06:03,672:INFO:PyCaret required dependencies:
2024-06-29 07:06:03,672:INFO:                 pip: 24.0
2024-06-29 07:06:03,672:INFO:          setuptools: 69.5.1
2024-06-29 07:06:03,672:INFO:             pycaret: 3.3.2
2024-06-29 07:06:03,672:INFO:             IPython: 8.24.0
2024-06-29 07:06:03,672:INFO:          ipywidgets: 8.1.3
2024-06-29 07:06:03,672:INFO:                tqdm: 4.66.4
2024-06-29 07:06:03,672:INFO:               numpy: 1.26.4
2024-06-29 07:06:03,672:INFO:              pandas: 2.1.4
2024-06-29 07:06:03,672:INFO:              jinja2: 3.1.4
2024-06-29 07:06:03,672:INFO:               scipy: 1.11.4
2024-06-29 07:06:03,672:INFO:              joblib: 1.3.2
2024-06-29 07:06:03,672:INFO:             sklearn: 1.4.2
2024-06-29 07:06:03,672:INFO:                pyod: 2.0.1
2024-06-29 07:06:03,672:INFO:            imblearn: 0.12.3
2024-06-29 07:06:03,672:INFO:   category_encoders: 2.6.3
2024-06-29 07:06:03,672:INFO:            lightgbm: 4.4.0
2024-06-29 07:06:03,672:INFO:               numba: 0.60.0
2024-06-29 07:06:03,672:INFO:            requests: 2.32.3
2024-06-29 07:06:03,672:INFO:          matplotlib: 3.7.5
2024-06-29 07:06:03,672:INFO:          scikitplot: 0.3.7
2024-06-29 07:06:03,672:INFO:         yellowbrick: 1.5
2024-06-29 07:06:03,672:INFO:              plotly: 5.22.0
2024-06-29 07:06:03,672:INFO:    plotly-resampler: Not installed
2024-06-29 07:06:03,672:INFO:             kaleido: 0.2.1
2024-06-29 07:06:03,672:INFO:           schemdraw: 0.15
2024-06-29 07:06:03,672:INFO:         statsmodels: 0.14.2
2024-06-29 07:06:03,672:INFO:              sktime: 0.26.0
2024-06-29 07:06:03,672:INFO:               tbats: 1.1.3
2024-06-29 07:06:03,672:INFO:            pmdarima: 2.0.4
2024-06-29 07:06:03,672:INFO:              psutil: 5.9.8
2024-06-29 07:06:03,672:INFO:          markupsafe: 2.1.5
2024-06-29 07:06:03,672:INFO:             pickle5: Not installed
2024-06-29 07:06:03,672:INFO:         cloudpickle: 3.0.0
2024-06-29 07:06:03,672:INFO:         deprecation: 2.1.0
2024-06-29 07:06:03,672:INFO:              xxhash: 3.4.1
2024-06-29 07:06:03,672:INFO:           wurlitzer: Not installed
2024-06-29 07:06:03,672:INFO:PyCaret optional dependencies:
2024-06-29 07:06:03,672:INFO:                shap: 0.44.1
2024-06-29 07:06:03,672:INFO:           interpret: 0.6.2
2024-06-29 07:06:03,672:INFO:                umap: 0.5.6
2024-06-29 07:06:03,672:INFO:     ydata_profiling: 4.8.3
2024-06-29 07:06:03,672:INFO:  explainerdashboard: 0.4.7
2024-06-29 07:06:03,672:INFO:             autoviz: Not installed
2024-06-29 07:06:03,672:INFO:           fairlearn: 0.7.0
2024-06-29 07:06:03,672:INFO:          deepchecks: Not installed
2024-06-29 07:06:03,672:INFO:             xgboost: Not installed
2024-06-29 07:06:03,672:INFO:            catboost: Not installed
2024-06-29 07:06:03,672:INFO:              kmodes: Not installed
2024-06-29 07:06:03,672:INFO:             mlxtend: Not installed
2024-06-29 07:06:03,672:INFO:       statsforecast: Not installed
2024-06-29 07:06:03,672:INFO:        tune_sklearn: Not installed
2024-06-29 07:06:03,672:INFO:                 ray: Not installed
2024-06-29 07:06:03,672:INFO:            hyperopt: Not installed
2024-06-29 07:06:03,672:INFO:              optuna: Not installed
2024-06-29 07:06:03,672:INFO:               skopt: Not installed
2024-06-29 07:06:03,672:INFO:              mlflow: Not installed
2024-06-29 07:06:03,672:INFO:              gradio: Not installed
2024-06-29 07:06:03,672:INFO:             fastapi: Not installed
2024-06-29 07:06:03,672:INFO:             uvicorn: Not installed
2024-06-29 07:06:03,672:INFO:              m2cgen: Not installed
2024-06-29 07:06:03,672:INFO:           evidently: Not installed
2024-06-29 07:06:03,672:INFO:               fugue: Not installed
2024-06-29 07:06:03,672:INFO:           streamlit: Not installed
2024-06-29 07:06:03,672:INFO:             prophet: Not installed
2024-06-29 07:06:03,672:INFO:None
2024-06-29 07:06:03,672:INFO:Set up GPU usage.
2024-06-29 07:06:03,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:03,672:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-06-29 07:06:03,672:INFO:Set up data.
2024-06-29 07:06:04,438:INFO:Set up folding strategy.
2024-06-29 07:06:04,438:INFO:Set up train/test split.
2024-06-29 07:06:05,387:INFO:Set up index.
2024-06-29 07:06:05,424:INFO:Assigning column types.
2024-06-29 07:06:05,788:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-29 07:06:05,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:05,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 07:06:05,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:05,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:05,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:06:05,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:05,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:05,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:05,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:07,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:07,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 07:06:07,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,407:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:06:07,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,476:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:07,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:07,641:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-29 07:06:07,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:06:07,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:07,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:07,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:07,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:06:08,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:08,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:08,222:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-29 07:06:08,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:08,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:08,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-29 07:06:08,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:08,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:06:08,774:INFO:Preparing preprocessing pipeline...
2024-06-29 07:06:08,858:INFO:Set up label encoding.
2024-06-29 07:06:08,858:INFO:Set up date feature engineering.
2024-06-29 07:06:08,858:INFO:Set up simple imputation.
2024-06-29 07:06:09,108:INFO:Set up encoding of ordinal features.
2024-06-29 07:06:09,319:INFO:Set up encoding of categorical features.
2024-06-29 07:06:09,325:INFO:Set up imbalanced handling.
2024-06-29 07:06:09,325:INFO:Set up feature normalization.
2024-06-29 07:06:34,854:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-06-29 07:06:34,931:INFO:Finished creating preprocessing pipeline.
2024-06-29 07:06:34,967:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-06-29 07:06:34,967:INFO:Creating final display dataframe.
2024-06-29 07:07:00,281:INFO:PyCaret ClassificationExperiment
2024-06-29 07:07:00,281:INFO:Logging name: clf-default-name
2024-06-29 07:07:00,281:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-29 07:07:00,281:INFO:version 3.3.2
2024-06-29 07:07:00,281:INFO:Initializing setup()
2024-06-29 07:07:00,281:INFO:self.USI: 785d
2024-06-29 07:07:00,281:INFO:self._variable_keys: {'y_test', 'X', 'fix_imbalance', 'memory', 'fold_shuffle_param', 'idx', 'gpu_param', 'target_param', 'data', 'pipeline', 'log_plots_param', 'USI', 'X_test', 'exp_id', 'html_param', 'is_multiclass', '_available_plots', '_ml_usecase', 'y_train', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'seed', 'gpu_n_jobs_param', 'y', 'X_train', 'fold_groups_param', 'logging_param'}
2024-06-29 07:07:00,281:INFO:Checking environment
2024-06-29 07:07:00,281:INFO:python_version: 3.11.7
2024-06-29 07:07:00,281:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-29 07:07:00,282:INFO:machine: AMD64
2024-06-29 07:07:00,282:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-29 07:07:00,284:INFO:Memory: svmem(total=12756160512, available=5144367104, percent=59.7, used=7611793408, free=5144367104)
2024-06-29 07:07:00,284:INFO:Physical Core: 2
2024-06-29 07:07:00,284:INFO:Logical Core: 4
2024-06-29 07:07:00,284:INFO:Checking libraries
2024-06-29 07:07:00,284:INFO:System:
2024-06-29 07:07:00,284:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-29 07:07:00,284:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-29 07:07:00,284:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-29 07:07:00,284:INFO:PyCaret required dependencies:
2024-06-29 07:07:00,284:INFO:                 pip: 24.0
2024-06-29 07:07:00,284:INFO:          setuptools: 69.5.1
2024-06-29 07:07:00,285:INFO:             pycaret: 3.3.2
2024-06-29 07:07:00,285:INFO:             IPython: 8.24.0
2024-06-29 07:07:00,285:INFO:          ipywidgets: 8.1.3
2024-06-29 07:07:00,285:INFO:                tqdm: 4.66.4
2024-06-29 07:07:00,285:INFO:               numpy: 1.26.4
2024-06-29 07:07:00,285:INFO:              pandas: 2.1.4
2024-06-29 07:07:00,285:INFO:              jinja2: 3.1.4
2024-06-29 07:07:00,285:INFO:               scipy: 1.11.4
2024-06-29 07:07:00,285:INFO:              joblib: 1.3.2
2024-06-29 07:07:00,285:INFO:             sklearn: 1.4.2
2024-06-29 07:07:00,285:INFO:                pyod: 2.0.1
2024-06-29 07:07:00,285:INFO:            imblearn: 0.12.3
2024-06-29 07:07:00,285:INFO:   category_encoders: 2.6.3
2024-06-29 07:07:00,285:INFO:            lightgbm: 4.4.0
2024-06-29 07:07:00,286:INFO:               numba: 0.60.0
2024-06-29 07:07:00,286:INFO:            requests: 2.32.3
2024-06-29 07:07:00,286:INFO:          matplotlib: 3.7.5
2024-06-29 07:07:00,286:INFO:          scikitplot: 0.3.7
2024-06-29 07:07:00,286:INFO:         yellowbrick: 1.5
2024-06-29 07:07:00,286:INFO:              plotly: 5.22.0
2024-06-29 07:07:00,286:INFO:    plotly-resampler: Not installed
2024-06-29 07:07:00,286:INFO:             kaleido: 0.2.1
2024-06-29 07:07:00,286:INFO:           schemdraw: 0.15
2024-06-29 07:07:00,286:INFO:         statsmodels: 0.14.2
2024-06-29 07:07:00,286:INFO:              sktime: 0.26.0
2024-06-29 07:07:00,286:INFO:               tbats: 1.1.3
2024-06-29 07:07:00,286:INFO:            pmdarima: 2.0.4
2024-06-29 07:07:00,286:INFO:              psutil: 5.9.8
2024-06-29 07:07:00,287:INFO:          markupsafe: 2.1.5
2024-06-29 07:07:00,287:INFO:             pickle5: Not installed
2024-06-29 07:07:00,287:INFO:         cloudpickle: 3.0.0
2024-06-29 07:07:00,287:INFO:         deprecation: 2.1.0
2024-06-29 07:07:00,287:INFO:              xxhash: 3.4.1
2024-06-29 07:07:00,287:INFO:           wurlitzer: Not installed
2024-06-29 07:07:00,287:INFO:PyCaret optional dependencies:
2024-06-29 07:07:00,287:INFO:                shap: 0.44.1
2024-06-29 07:07:00,287:INFO:           interpret: 0.6.2
2024-06-29 07:07:00,287:INFO:                umap: 0.5.6
2024-06-29 07:07:00,287:INFO:     ydata_profiling: 4.8.3
2024-06-29 07:07:00,287:INFO:  explainerdashboard: 0.4.7
2024-06-29 07:07:00,287:INFO:             autoviz: Not installed
2024-06-29 07:07:00,288:INFO:           fairlearn: 0.7.0
2024-06-29 07:07:00,288:INFO:          deepchecks: Not installed
2024-06-29 07:07:00,288:INFO:             xgboost: Not installed
2024-06-29 07:07:00,288:INFO:            catboost: Not installed
2024-06-29 07:07:00,288:INFO:              kmodes: Not installed
2024-06-29 07:07:00,288:INFO:             mlxtend: Not installed
2024-06-29 07:07:00,288:INFO:       statsforecast: Not installed
2024-06-29 07:07:00,288:INFO:        tune_sklearn: Not installed
2024-06-29 07:07:00,288:INFO:                 ray: Not installed
2024-06-29 07:07:00,288:INFO:            hyperopt: Not installed
2024-06-29 07:07:00,288:INFO:              optuna: Not installed
2024-06-29 07:07:00,288:INFO:               skopt: Not installed
2024-06-29 07:07:00,288:INFO:              mlflow: Not installed
2024-06-29 07:07:00,288:INFO:              gradio: Not installed
2024-06-29 07:07:00,289:INFO:             fastapi: Not installed
2024-06-29 07:07:00,289:INFO:             uvicorn: Not installed
2024-06-29 07:07:00,289:INFO:              m2cgen: Not installed
2024-06-29 07:07:00,289:INFO:           evidently: Not installed
2024-06-29 07:07:00,289:INFO:               fugue: Not installed
2024-06-29 07:07:00,290:INFO:           streamlit: Not installed
2024-06-29 07:07:00,290:INFO:             prophet: Not installed
2024-06-29 07:07:00,290:INFO:None
2024-06-29 07:07:00,290:INFO:Set up data.
2024-06-29 07:07:01,090:INFO:Set up folding strategy.
2024-06-29 07:07:01,090:INFO:Set up train/test split.
2024-06-29 07:07:02,042:INFO:Set up index.
2024-06-29 07:07:02,073:INFO:Assigning column types.
2024-06-29 07:07:02,458:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-29 07:07:02,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 07:07:02,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:07:02,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-29 07:07:02,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:07:02,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,653:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-29 07:07:02,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:07:02,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-29 07:07:02,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,837:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-29 07:07:02,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:02,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:03,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:03,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:07:03,023:INFO:Preparing preprocessing pipeline...
2024-06-29 07:07:03,092:INFO:Set up label encoding.
2024-06-29 07:07:03,092:INFO:Set up date feature engineering.
2024-06-29 07:07:03,092:INFO:Set up simple imputation.
2024-06-29 07:07:03,324:INFO:Set up encoding of ordinal features.
2024-06-29 07:07:03,556:INFO:Set up encoding of categorical features.
2024-06-29 07:07:03,556:INFO:Set up imbalanced handling.
2024-06-29 07:07:03,556:INFO:Set up feature normalization.
2024-06-29 07:07:28,233:INFO:Finished creating preprocessing pipeline.
2024-06-29 07:07:28,283:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-06-29 07:07:28,283:INFO:Creating final display dataframe.
2024-06-29 07:08:03,494:INFO:Setup _display_container:                     Description             Value
0                    Session id              6854
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (755815, 80)
6   Transformed train set shape      (662558, 80)
7    Transformed test set shape       (93257, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method            onehot
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              785d
2024-06-29 07:08:03,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:08:03,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:08:03,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:08:03,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-29 07:08:03,828:INFO:setup() successfully completed in 63.71s...............
2024-06-29 07:10:33,159:INFO:Initializing compare_models()
2024-06-29 07:10:33,159:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-29 07:10:33,160:INFO:Checking exceptions
2024-06-29 07:10:33,528:INFO:Preparing display monitor
2024-06-29 07:10:33,579:INFO:Initializing Logistic Regression
2024-06-29 07:10:33,579:INFO:Total runtime is 0.0 minutes
2024-06-29 07:10:33,587:INFO:SubProcess create_model() called ==================================
2024-06-29 07:10:33,587:INFO:Initializing create_model()
2024-06-29 07:10:33,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCA1FAE6D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 07:10:33,587:INFO:Checking exceptions
2024-06-29 07:10:33,587:INFO:Importing libraries
2024-06-29 07:10:33,587:INFO:Copying training dataset
2024-06-29 07:10:34,414:INFO:Defining folds
2024-06-29 07:10:34,414:INFO:Declaring metric variables
2024-06-29 07:10:34,414:INFO:Importing untrained model
2024-06-29 07:10:34,430:INFO:Logistic Regression Imported successfully
2024-06-29 07:10:34,446:INFO:Starting cross validation
2024-06-29 07:10:34,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 07:13:05,491:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:06,185:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:06,480:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:06,863:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:07,130:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:07,833:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:09,799:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:10,523:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:11,384:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:11,970:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:12,803:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:13:13,599:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:48,097:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:48,720:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:49,348:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:54,387:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:55,233:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:55,233:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:55,645:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:56,116:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:56,150:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:56,477:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:56,983:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:14:57,367:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:52,688:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:53,238:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:53,823:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:57,087:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:57,404:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:57,744:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:15:58,314:INFO:Calculating mean and std
2024-06-29 07:15:58,314:INFO:Creating metrics dataframe
2024-06-29 07:15:58,321:INFO:Uploading results into container
2024-06-29 07:15:58,321:INFO:Uploading model into container now
2024-06-29 07:15:58,321:INFO:_master_model_container: 1
2024-06-29 07:15:58,321:INFO:_display_container: 2
2024-06-29 07:15:58,321:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6854, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-29 07:15:58,321:INFO:create_model() successfully completed......................................
2024-06-29 07:16:00,071:INFO:SubProcess create_model() end ==================================
2024-06-29 07:16:00,071:INFO:Creating metrics dataframe
2024-06-29 07:16:00,071:INFO:Initializing Decision Tree Classifier
2024-06-29 07:16:00,071:INFO:Total runtime is 5.441532174746196 minutes
2024-06-29 07:16:00,088:INFO:SubProcess create_model() called ==================================
2024-06-29 07:16:00,088:INFO:Initializing create_model()
2024-06-29 07:16:00,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCA1FAE6D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 07:16:00,088:INFO:Checking exceptions
2024-06-29 07:16:00,088:INFO:Importing libraries
2024-06-29 07:16:00,088:INFO:Copying training dataset
2024-06-29 07:16:00,788:INFO:Defining folds
2024-06-29 07:16:00,788:INFO:Declaring metric variables
2024-06-29 07:16:00,800:INFO:Importing untrained model
2024-06-29 07:16:00,811:INFO:Decision Tree Classifier Imported successfully
2024-06-29 07:16:00,822:INFO:Starting cross validation
2024-06-29 07:16:00,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 07:17:58,273:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:17:58,961:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:17:59,069:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:17:59,778:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:17:59,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:00,546:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:00,599:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:01,420:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:01,451:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:02,281:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:02,300:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:18:03,262:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:51,016:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:51,827:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:52,450:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:52,616:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:53,216:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:54,006:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:57,501:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:58,288:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:19:59,041:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:20:00,471:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:20:01,428:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:20:02,407:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:09,425:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:09,875:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:10,349:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:12,048:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:12,367:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:12,710:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:21:13,264:INFO:Calculating mean and std
2024-06-29 07:21:13,264:INFO:Creating metrics dataframe
2024-06-29 07:21:13,277:INFO:Uploading results into container
2024-06-29 07:21:13,277:INFO:Uploading model into container now
2024-06-29 07:21:13,277:INFO:_master_model_container: 2
2024-06-29 07:21:13,277:INFO:_display_container: 2
2024-06-29 07:21:13,283:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6854, splitter='best')
2024-06-29 07:21:13,284:INFO:create_model() successfully completed......................................
2024-06-29 07:21:13,460:INFO:SubProcess create_model() end ==================================
2024-06-29 07:21:13,460:INFO:Creating metrics dataframe
2024-06-29 07:21:13,477:INFO:Initializing Random Forest Classifier
2024-06-29 07:21:13,477:INFO:Total runtime is 10.664954614639282 minutes
2024-06-29 07:21:13,477:INFO:SubProcess create_model() called ==================================
2024-06-29 07:21:13,477:INFO:Initializing create_model()
2024-06-29 07:21:13,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCA1FAE6D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 07:21:13,477:INFO:Checking exceptions
2024-06-29 07:21:13,477:INFO:Importing libraries
2024-06-29 07:21:13,477:INFO:Copying training dataset
2024-06-29 07:21:14,109:INFO:Defining folds
2024-06-29 07:21:14,109:INFO:Declaring metric variables
2024-06-29 07:21:14,115:INFO:Importing untrained model
2024-06-29 07:21:14,115:INFO:Random Forest Classifier Imported successfully
2024-06-29 07:21:14,130:INFO:Starting cross validation
2024-06-29 07:21:14,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 07:29:59,778:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:01,471:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:01,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:02,004:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:02,297:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:02,415:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:02,763:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:02,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:03,105:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:03,612:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:03,673:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:30:04,105:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:45,089:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:46,176:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:47,429:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:47,868:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:49,265:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:49,650:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:49,989:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:50,166:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:50,467:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:50,747:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:51,361:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:38:51,645:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:16,008:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:16,672:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:17,420:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:19,576:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:19,960:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:20,310:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:43:20,850:INFO:Calculating mean and std
2024-06-29 07:43:20,852:INFO:Creating metrics dataframe
2024-06-29 07:43:20,864:INFO:Uploading results into container
2024-06-29 07:43:20,865:INFO:Uploading model into container now
2024-06-29 07:43:20,865:INFO:_master_model_container: 3
2024-06-29 07:43:20,865:INFO:_display_container: 2
2024-06-29 07:43:20,865:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6854, verbose=0,
                       warm_start=False)
2024-06-29 07:43:20,865:INFO:create_model() successfully completed......................................
2024-06-29 07:43:21,035:INFO:SubProcess create_model() end ==================================
2024-06-29 07:43:21,035:INFO:Creating metrics dataframe
2024-06-29 07:43:21,052:INFO:Initializing Light Gradient Boosting Machine
2024-06-29 07:43:21,052:INFO:Total runtime is 32.79121381044388 minutes
2024-06-29 07:43:21,052:INFO:SubProcess create_model() called ==================================
2024-06-29 07:43:21,052:INFO:Initializing create_model()
2024-06-29 07:43:21,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCA1FAE6D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 07:43:21,052:INFO:Checking exceptions
2024-06-29 07:43:21,052:INFO:Importing libraries
2024-06-29 07:43:21,052:INFO:Copying training dataset
2024-06-29 07:43:21,669:INFO:Defining folds
2024-06-29 07:43:21,670:INFO:Declaring metric variables
2024-06-29 07:43:21,676:INFO:Importing untrained model
2024-06-29 07:43:21,676:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-29 07:43:21,688:INFO:Starting cross validation
2024-06-29 07:43:21,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-29 07:44:56,321:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:56,373:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:56,401:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:56,501:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:57,151:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:57,184:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:57,230:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:57,301:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:57,982:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:58,001:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:58,047:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:44:58,132:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:34,046:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:34,101:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:34,233:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:34,267:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:34,899:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:34,960:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:35,025:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:35,102:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:35,723:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:35,754:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:35,853:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:46:35,932:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:43,123:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:43,184:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:43,816:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:43,846:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:44,418:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:44,449:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:47:45,403:INFO:Calculating mean and std
2024-06-29 07:47:45,414:INFO:Creating metrics dataframe
2024-06-29 07:47:45,427:INFO:Uploading results into container
2024-06-29 07:47:45,431:INFO:Uploading model into container now
2024-06-29 07:47:45,433:INFO:_master_model_container: 4
2024-06-29 07:47:45,434:INFO:_display_container: 2
2024-06-29 07:47:45,437:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-29 07:47:45,437:INFO:create_model() successfully completed......................................
2024-06-29 07:47:45,904:INFO:SubProcess create_model() end ==================================
2024-06-29 07:47:45,904:INFO:Creating metrics dataframe
2024-06-29 07:47:45,950:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-29 07:47:46,013:INFO:Initializing create_model()
2024-06-29 07:47:46,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-29 07:47:46,015:INFO:Checking exceptions
2024-06-29 07:47:46,024:INFO:Importing libraries
2024-06-29 07:47:46,026:INFO:Copying training dataset
2024-06-29 07:47:47,507:INFO:Defining folds
2024-06-29 07:47:47,508:INFO:Declaring metric variables
2024-06-29 07:47:47,508:INFO:Importing untrained model
2024-06-29 07:47:47,508:INFO:Declaring custom model
2024-06-29 07:47:47,508:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-29 07:47:47,562:INFO:Cross validation set to False
2024-06-29 07:47:47,562:INFO:Fitting Model
2024-06-29 07:48:25,452:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-29 07:48:25,457:INFO:[LightGBM] [Info] Number of positive: 331279, number of negative: 331279
2024-06-29 07:48:26,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.295831 seconds.
2024-06-29 07:48:26,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-29 07:48:26,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-29 07:48:26,279:INFO:[LightGBM] [Info] Total Bins 16691
2024-06-29 07:48:26,281:INFO:[LightGBM] [Info] Number of data points in the train set: 662558, number of used features: 75
2024-06-29 07:48:26,281:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-29 07:48:37,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-29 07:48:37,678:INFO:create_model() successfully completed......................................
2024-06-29 07:48:38,092:INFO:_master_model_container: 4
2024-06-29 07:48:38,092:INFO:_display_container: 2
2024-06-29 07:48:38,093:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-29 07:48:38,093:INFO:compare_models() successfully completed......................................
2024-06-29 07:48:38,209:INFO:Initializing plot_model()
2024-06-29 07:48:38,209:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-29 07:48:38,209:INFO:Checking exceptions
2024-06-29 07:48:38,662:INFO:Preloading libraries
2024-06-29 07:48:38,686:INFO:Copying training dataset
2024-06-29 07:48:38,686:INFO:Plot type: confusion_matrix
2024-06-29 07:48:49,340:INFO:Fitting Model
2024-06-29 07:48:49,366:INFO:Scoring test/hold-out set
2024-06-29 07:48:51,615:INFO:Visual Rendered Successfully
2024-06-29 07:48:52,023:INFO:plot_model() successfully completed......................................
2024-06-29 07:48:52,113:INFO:Initializing plot_model()
2024-06-29 07:48:52,113:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-29 07:48:52,116:INFO:Checking exceptions
2024-06-29 07:48:52,588:INFO:Preloading libraries
2024-06-29 07:48:52,611:INFO:Copying training dataset
2024-06-29 07:48:52,611:INFO:Plot type: auc
2024-06-29 07:48:57,557:INFO:Fitting Model
2024-06-29 07:48:57,602:INFO:Scoring test/hold-out set
2024-06-29 07:48:59,374:INFO:Visual Rendered Successfully
2024-06-29 07:48:59,725:INFO:plot_model() successfully completed......................................
2024-06-29 07:48:59,772:INFO:Initializing evaluate_model()
2024-06-29 07:48:59,773:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 07:49:00,214:INFO:Initializing plot_model()
2024-06-29 07:49:00,215:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 07:49:00,218:INFO:Checking exceptions
2024-06-29 07:49:00,617:INFO:Preloading libraries
2024-06-29 07:49:00,636:INFO:Copying training dataset
2024-06-29 07:49:00,636:INFO:Plot type: pipeline
2024-06-29 07:49:01,654:INFO:Visual Rendered Successfully
2024-06-29 07:49:02,096:INFO:plot_model() successfully completed......................................
2024-06-29 07:49:02,198:INFO:Initializing predict_model()
2024-06-29 07:49:02,199:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BC98074540>)
2024-06-29 07:49:02,199:INFO:Checking exceptions
2024-06-29 07:49:02,199:INFO:Preloading libraries
2024-06-29 07:49:07,727:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:49:09,705:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 07:49:10,893:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 08:13:13,014:INFO:Initializing plot_model()
2024-06-29 08:13:13,015:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:13:13,015:INFO:Checking exceptions
2024-06-29 08:13:13,232:INFO:Preloading libraries
2024-06-29 08:13:13,247:INFO:Copying training dataset
2024-06-29 08:13:13,247:INFO:Plot type: feature
2024-06-29 08:13:13,247:WARNING:No coef_ found. Trying feature_importances_
2024-06-29 08:13:14,376:INFO:Visual Rendered Successfully
2024-06-29 08:13:14,538:INFO:plot_model() successfully completed......................................
2024-06-29 08:13:50,292:INFO:Initializing evaluate_model()
2024-06-29 08:13:50,292:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 08:13:50,668:INFO:Initializing plot_model()
2024-06-29 08:13:50,669:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:13:50,669:INFO:Checking exceptions
2024-06-29 08:14:01,064:INFO:Initializing plot_model()
2024-06-29 08:14:01,064:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:14:01,064:INFO:Checking exceptions
2024-06-29 08:14:51,742:INFO:Initializing evaluate_model()
2024-06-29 08:14:51,743:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 08:14:52,122:INFO:Initializing plot_model()
2024-06-29 08:14:52,123:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:14:52,123:INFO:Checking exceptions
2024-06-29 08:14:54,453:INFO:Initializing plot_model()
2024-06-29 08:14:54,453:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=lr, plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:14:54,453:INFO:Checking exceptions
2024-06-29 08:17:49,048:INFO:Initializing evaluate_model()
2024-06-29 08:17:49,048:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 08:17:49,386:INFO:Initializing plot_model()
2024-06-29 08:17:49,387:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:17:49,387:INFO:Checking exceptions
2024-06-29 08:17:49,620:INFO:Preloading libraries
2024-06-29 08:17:49,636:INFO:Copying training dataset
2024-06-29 08:17:49,636:INFO:Plot type: pipeline
2024-06-29 08:17:49,969:INFO:Visual Rendered Successfully
2024-06-29 08:17:50,340:INFO:plot_model() successfully completed......................................
2024-06-29 08:18:04,444:INFO:Initializing evaluate_model()
2024-06-29 08:18:04,444:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=lr, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 08:19:22,374:INFO:Initializing evaluate_model()
2024-06-29 08:19:22,375:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-06-29 08:19:22,652:INFO:Initializing plot_model()
2024-06-29 08:19:22,654:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-06-29 08:19:22,654:INFO:Checking exceptions
2024-06-29 08:19:22,853:INFO:Preloading libraries
2024-06-29 08:19:22,868:INFO:Copying training dataset
2024-06-29 08:19:22,868:INFO:Plot type: pipeline
2024-06-29 08:19:23,200:INFO:Visual Rendered Successfully
2024-06-29 08:19:23,384:INFO:plot_model() successfully completed......................................
2024-06-29 08:19:30,260:INFO:Initializing predict_model()
2024-06-29 08:19:30,260:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BC96E56F20>)
2024-06-29 08:19:30,260:INFO:Checking exceptions
2024-06-29 08:19:30,261:INFO:Preloading libraries
2024-06-29 08:19:33,054:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 08:19:33,951:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 08:19:34,854:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-29 08:25:53,667:INFO:Initializing plot_model()
2024-06-29 08:25:53,667:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCA2B4C050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6854, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-29 08:25:53,668:INFO:Checking exceptions
2024-06-29 08:25:54,072:INFO:Preloading libraries
2024-06-29 08:25:54,085:INFO:Copying training dataset
2024-06-29 08:25:54,085:INFO:Plot type: feature
2024-06-29 08:25:54,085:WARNING:No coef_ found. Trying feature_importances_
2024-06-29 08:25:55,549:INFO:Visual Rendered Successfully
2024-06-29 08:25:55,749:INFO:plot_model() successfully completed......................................
2024-06-30 11:52:27,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-30 11:52:27,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-30 11:52:27,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-30 11:52:27,558:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-30 11:52:39,927:INFO:PyCaret ClassificationExperiment
2024-06-30 11:52:39,927:INFO:Logging name: clf-default-name
2024-06-30 11:52:39,927:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-30 11:52:39,927:INFO:version 3.3.2
2024-06-30 11:52:39,927:INFO:Initializing setup()
2024-06-30 11:52:39,927:INFO:self.USI: bf42
2024-06-30 11:52:39,928:INFO:self._variable_keys: {'memory', '_available_plots', 'fold_groups_param', 'X_test', 'exp_name_log', 'is_multiclass', 'pipeline', 'gpu_param', 'log_plots_param', 'data', '_ml_usecase', 'fold_generator', 'html_param', 'y_test', 'target_param', 'idx', 'USI', 'seed', 'X', 'fix_imbalance', 'gpu_n_jobs_param', 'X_train', 'fold_shuffle_param', 'exp_id', 'n_jobs_param', 'y', 'y_train', 'logging_param'}
2024-06-30 11:52:39,928:INFO:Checking environment
2024-06-30 11:52:39,928:INFO:python_version: 3.11.7
2024-06-30 11:52:39,928:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-30 11:52:39,928:INFO:machine: AMD64
2024-06-30 11:52:39,928:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-30 11:52:39,944:INFO:Memory: svmem(total=12756160512, available=5156651008, percent=59.6, used=7599509504, free=5156651008)
2024-06-30 11:52:39,944:INFO:Physical Core: 2
2024-06-30 11:52:39,944:INFO:Logical Core: 4
2024-06-30 11:52:39,944:INFO:Checking libraries
2024-06-30 11:52:39,944:INFO:System:
2024-06-30 11:52:39,944:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-30 11:52:39,944:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-30 11:52:39,944:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-30 11:52:39,944:INFO:PyCaret required dependencies:
2024-06-30 11:52:40,823:INFO:                 pip: 24.0
2024-06-30 11:52:40,823:INFO:          setuptools: 69.5.1
2024-06-30 11:52:40,823:INFO:             pycaret: 3.3.2
2024-06-30 11:52:40,823:INFO:             IPython: 8.24.0
2024-06-30 11:52:40,823:INFO:          ipywidgets: 8.1.3
2024-06-30 11:52:40,824:INFO:                tqdm: 4.66.4
2024-06-30 11:52:40,824:INFO:               numpy: 1.26.4
2024-06-30 11:52:40,824:INFO:              pandas: 2.1.4
2024-06-30 11:52:40,824:INFO:              jinja2: 3.1.4
2024-06-30 11:52:40,824:INFO:               scipy: 1.11.4
2024-06-30 11:52:40,824:INFO:              joblib: 1.3.2
2024-06-30 11:52:40,824:INFO:             sklearn: 1.4.2
2024-06-30 11:52:40,824:INFO:                pyod: 2.0.1
2024-06-30 11:52:40,824:INFO:            imblearn: 0.12.3
2024-06-30 11:52:40,824:INFO:   category_encoders: 2.6.3
2024-06-30 11:52:40,824:INFO:            lightgbm: 4.4.0
2024-06-30 11:52:40,824:INFO:               numba: 0.60.0
2024-06-30 11:52:40,825:INFO:            requests: 2.32.3
2024-06-30 11:52:40,825:INFO:          matplotlib: 3.7.5
2024-06-30 11:52:40,825:INFO:          scikitplot: 0.3.7
2024-06-30 11:52:40,825:INFO:         yellowbrick: 1.5
2024-06-30 11:52:40,825:INFO:              plotly: 5.22.0
2024-06-30 11:52:40,825:INFO:    plotly-resampler: Not installed
2024-06-30 11:52:40,825:INFO:             kaleido: 0.2.1
2024-06-30 11:52:40,825:INFO:           schemdraw: 0.15
2024-06-30 11:52:40,825:INFO:         statsmodels: 0.14.2
2024-06-30 11:52:40,825:INFO:              sktime: 0.26.0
2024-06-30 11:52:40,825:INFO:               tbats: 1.1.3
2024-06-30 11:52:40,826:INFO:            pmdarima: 2.0.4
2024-06-30 11:52:40,826:INFO:              psutil: 5.9.8
2024-06-30 11:52:40,826:INFO:          markupsafe: 2.1.5
2024-06-30 11:52:40,826:INFO:             pickle5: Not installed
2024-06-30 11:52:40,826:INFO:         cloudpickle: 3.0.0
2024-06-30 11:52:40,826:INFO:         deprecation: 2.1.0
2024-06-30 11:52:40,826:INFO:              xxhash: 3.4.1
2024-06-30 11:52:40,826:INFO:           wurlitzer: Not installed
2024-06-30 11:52:40,826:INFO:PyCaret optional dependencies:
2024-06-30 11:52:40,861:INFO:                shap: 0.44.1
2024-06-30 11:52:40,868:INFO:           interpret: 0.6.2
2024-06-30 11:52:40,868:INFO:                umap: 0.5.6
2024-06-30 11:52:40,868:INFO:     ydata_profiling: 4.8.3
2024-06-30 11:52:40,869:INFO:  explainerdashboard: 0.4.7
2024-06-30 11:52:40,869:INFO:             autoviz: Not installed
2024-06-30 11:52:40,869:INFO:           fairlearn: 0.7.0
2024-06-30 11:52:40,869:INFO:          deepchecks: Not installed
2024-06-30 11:52:40,869:INFO:             xgboost: Not installed
2024-06-30 11:52:40,869:INFO:            catboost: Not installed
2024-06-30 11:52:40,869:INFO:              kmodes: Not installed
2024-06-30 11:52:40,869:INFO:             mlxtend: Not installed
2024-06-30 11:52:40,869:INFO:       statsforecast: Not installed
2024-06-30 11:52:40,870:INFO:        tune_sklearn: Not installed
2024-06-30 11:52:40,870:INFO:                 ray: Not installed
2024-06-30 11:52:40,870:INFO:            hyperopt: Not installed
2024-06-30 11:52:40,870:INFO:              optuna: Not installed
2024-06-30 11:52:40,870:INFO:               skopt: Not installed
2024-06-30 11:52:40,870:INFO:              mlflow: Not installed
2024-06-30 11:52:40,870:INFO:              gradio: Not installed
2024-06-30 11:52:40,870:INFO:             fastapi: Not installed
2024-06-30 11:52:40,870:INFO:             uvicorn: Not installed
2024-06-30 11:52:40,870:INFO:              m2cgen: Not installed
2024-06-30 11:52:40,870:INFO:           evidently: Not installed
2024-06-30 11:52:40,871:INFO:               fugue: Not installed
2024-06-30 11:52:40,871:INFO:           streamlit: Not installed
2024-06-30 11:52:40,871:INFO:             prophet: Not installed
2024-06-30 11:52:40,871:INFO:None
2024-06-30 11:52:40,871:INFO:Set up data.
2024-06-30 11:52:42,290:INFO:Set up folding strategy.
2024-06-30 11:52:42,290:INFO:Set up train/test split.
2024-06-30 11:52:44,482:INFO:Set up index.
2024-06-30 11:52:44,534:INFO:Assigning column types.
2024-06-30 11:52:45,519:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-30 11:52:45,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-30 11:52:45,796:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 11:52:46,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-30 11:52:46,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 11:52:46,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,360:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-30 11:52:46,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 11:52:46,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 11:52:46,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:46,892:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-30 11:52:47,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:47,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:47,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:47,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:52:47,597:INFO:Preparing preprocessing pipeline...
2024-06-30 11:52:47,750:INFO:Set up label encoding.
2024-06-30 11:52:47,751:INFO:Set up date feature engineering.
2024-06-30 11:52:47,751:INFO:Set up simple imputation.
2024-06-30 11:52:48,294:INFO:Set up encoding of ordinal features.
2024-06-30 11:52:48,759:INFO:Set up encoding of categorical features.
2024-06-30 11:53:01,118:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:249: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2024-06-30 11:53:03,753:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:256: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2024-06-30 11:53:08,164:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-06-30 11:53:08,185:INFO:Finished creating preprocessing pipeline.
2024-06-30 11:53:08,331:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['grade', 'emp_length',
                                             'home_ownership',
                                             'verification_status', 'purpose'],
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-06-30 11:53:08,331:INFO:Creating final display dataframe.
2024-06-30 11:53:12,957:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.79s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-06-30 11:53:17,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-06-30 11:53:26,861:INFO:Setup _display_container:                     Description             Value
0                    Session id              2927
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (466285, 80)
6   Transformed train set shape      (373028, 80)
7    Transformed test set shape       (93257, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              bf42
2024-06-30 11:53:27,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:53:27,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:53:27,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:53:27,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 11:53:27,584:INFO:setup() successfully completed in 48.39s...............
2024-06-30 11:53:27,634:INFO:Initializing compare_models()
2024-06-30 11:53:27,634:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-30 11:53:27,634:INFO:Checking exceptions
2024-06-30 11:53:28,663:INFO:Preparing display monitor
2024-06-30 11:53:28,805:INFO:Initializing Logistic Regression
2024-06-30 11:53:28,805:INFO:Total runtime is 0.0 minutes
2024-06-30 11:53:28,822:INFO:SubProcess create_model() called ==================================
2024-06-30 11:53:28,822:INFO:Initializing create_model()
2024-06-30 11:53:28,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C39B7F99D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 11:53:28,823:INFO:Checking exceptions
2024-06-30 11:53:28,823:INFO:Importing libraries
2024-06-30 11:53:28,823:INFO:Copying training dataset
2024-06-30 11:53:31,331:INFO:Defining folds
2024-06-30 11:53:31,331:INFO:Declaring metric variables
2024-06-30 11:53:31,338:INFO:Importing untrained model
2024-06-30 11:53:31,355:INFO:Logistic Regression Imported successfully
2024-06-30 11:53:31,396:INFO:Starting cross validation
2024-06-30 11:53:31,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 12:00:52,694:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:00:54,527:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:00:54,915:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:00:57,971:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:00:58,155:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:00:59,398:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:00:59,617:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:01,175:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:02,542:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:02,727:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:03,530:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:04,817:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:05,392:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:05,906:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:06,923:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:01:09,786:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:07:53,941:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:07:55,485:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:07:56,490:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:07:59,178:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:00,790:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:01,896:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:02,137:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:03,706:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:04,909:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:05,065:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:06,568:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:07,920:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:08,099:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:08:13,064:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:15,132:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:08:17,479:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:11:56,305:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:11:59,028:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:12:00,530:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-06-30 12:12:00,767:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:12:02,404:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:12:03,023:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:12:04,715:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:12:05,860:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:12:07,522:INFO:Calculating mean and std
2024-06-30 12:12:07,534:INFO:Creating metrics dataframe
2024-06-30 12:12:07,542:INFO:Uploading results into container
2024-06-30 12:12:07,544:INFO:Uploading model into container now
2024-06-30 12:12:07,544:INFO:_master_model_container: 1
2024-06-30 12:12:07,545:INFO:_display_container: 2
2024-06-30 12:12:07,545:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2927, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-30 12:12:07,545:INFO:create_model() successfully completed......................................
2024-06-30 12:12:07,823:INFO:SubProcess create_model() end ==================================
2024-06-30 12:12:07,823:INFO:Creating metrics dataframe
2024-06-30 12:12:07,843:INFO:Initializing Decision Tree Classifier
2024-06-30 12:12:07,843:INFO:Total runtime is 18.6506374001503 minutes
2024-06-30 12:12:07,856:INFO:SubProcess create_model() called ==================================
2024-06-30 12:12:07,857:INFO:Initializing create_model()
2024-06-30 12:12:07,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C39B7F99D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 12:12:07,857:INFO:Checking exceptions
2024-06-30 12:12:07,857:INFO:Importing libraries
2024-06-30 12:12:07,857:INFO:Copying training dataset
2024-06-30 12:12:10,043:INFO:Defining folds
2024-06-30 12:12:10,043:INFO:Declaring metric variables
2024-06-30 12:12:10,055:INFO:Importing untrained model
2024-06-30 12:12:10,063:INFO:Decision Tree Classifier Imported successfully
2024-06-30 12:12:10,081:INFO:Starting cross validation
2024-06-30 12:12:10,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 12:14:42,643:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:46,012:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:48,093:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:48,630:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:48,841:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:50,913:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:51,381:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:53,359:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:54,083:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:54,378:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:56,143:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:14:59,280:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:22,346:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:25,346:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:26,835:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:28,989:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:30,251:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:31,516:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:33,218:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:34,240:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:37,197:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:38,826:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:42,077:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:17:44,680:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:05,262:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:06,868:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:08,588:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:09,549:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:11,100:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:12,326:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:19:14,334:INFO:Calculating mean and std
2024-06-30 12:19:14,336:INFO:Creating metrics dataframe
2024-06-30 12:19:14,341:INFO:Uploading results into container
2024-06-30 12:19:14,364:INFO:Uploading model into container now
2024-06-30 12:19:14,365:INFO:_master_model_container: 2
2024-06-30 12:19:14,365:INFO:_display_container: 2
2024-06-30 12:19:14,366:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2927, splitter='best')
2024-06-30 12:19:14,366:INFO:create_model() successfully completed......................................
2024-06-30 12:19:14,614:INFO:SubProcess create_model() end ==================================
2024-06-30 12:19:14,614:INFO:Creating metrics dataframe
2024-06-30 12:19:14,628:INFO:Initializing Random Forest Classifier
2024-06-30 12:19:14,628:INFO:Total runtime is 25.763723997275033 minutes
2024-06-30 12:19:14,665:INFO:SubProcess create_model() called ==================================
2024-06-30 12:19:14,665:INFO:Initializing create_model()
2024-06-30 12:19:14,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C39B7F99D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 12:19:14,666:INFO:Checking exceptions
2024-06-30 12:19:14,666:INFO:Importing libraries
2024-06-30 12:19:14,666:INFO:Copying training dataset
2024-06-30 12:19:16,850:INFO:Defining folds
2024-06-30 12:19:16,851:INFO:Declaring metric variables
2024-06-30 12:19:16,866:INFO:Importing untrained model
2024-06-30 12:19:16,879:INFO:Random Forest Classifier Imported successfully
2024-06-30 12:19:16,912:INFO:Starting cross validation
2024-06-30 12:19:16,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 12:32:09,836:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:11,177:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:14,224:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:14,748:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:15,372:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:15,406:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:17,456:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:18,507:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:18,697:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:18,922:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:22,447:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:32:22,650:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:08,499:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:09,692:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:11,412:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:12,510:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:12,511:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:13,064:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:14,376:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:15,261:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:15,371:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:15,967:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:17,044:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:45:18,226:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:51:56,755:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:51:57,690:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:51:58,546:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:51:59,188:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:52:00,201:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:52:00,921:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:52:03,003:INFO:Calculating mean and std
2024-06-30 12:52:03,007:INFO:Creating metrics dataframe
2024-06-30 12:52:03,020:INFO:Uploading results into container
2024-06-30 12:52:03,021:INFO:Uploading model into container now
2024-06-30 12:52:03,022:INFO:_master_model_container: 3
2024-06-30 12:52:03,022:INFO:_display_container: 2
2024-06-30 12:52:03,023:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2927, verbose=0,
                       warm_start=False)
2024-06-30 12:52:03,023:INFO:create_model() successfully completed......................................
2024-06-30 12:52:03,391:INFO:SubProcess create_model() end ==================================
2024-06-30 12:52:03,391:INFO:Creating metrics dataframe
2024-06-30 12:52:03,421:INFO:Initializing Light Gradient Boosting Machine
2024-06-30 12:52:03,421:INFO:Total runtime is 58.5769410888354 minutes
2024-06-30 12:52:03,431:INFO:SubProcess create_model() called ==================================
2024-06-30 12:52:03,432:INFO:Initializing create_model()
2024-06-30 12:52:03,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C39B7F99D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 12:52:03,432:INFO:Checking exceptions
2024-06-30 12:52:03,432:INFO:Importing libraries
2024-06-30 12:52:03,433:INFO:Copying training dataset
2024-06-30 12:52:05,921:INFO:Defining folds
2024-06-30 12:52:05,922:INFO:Declaring metric variables
2024-06-30 12:52:05,959:INFO:Importing untrained model
2024-06-30 12:52:05,967:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-30 12:52:06,018:INFO:Starting cross validation
2024-06-30 12:52:06,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 12:54:14,332:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:16,249:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:16,293:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:18,223:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:18,487:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:20,378:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:51,999:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:56,215:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:57,761:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:58,428:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:54:59,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:55:01,928:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:19,134:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:19,737:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:20,706:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:21,489:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:22,629:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:23,274:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:54,445:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:57,041:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:56:59,410:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:00,471:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:01,606:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:02,214:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:30,058:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:31,301:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:32,771:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:36,620:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:37,771:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:38,895:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 12:57:40,549:INFO:Calculating mean and std
2024-06-30 12:57:40,554:INFO:Creating metrics dataframe
2024-06-30 12:57:40,563:INFO:Uploading results into container
2024-06-30 12:57:40,564:INFO:Uploading model into container now
2024-06-30 12:57:40,565:INFO:_master_model_container: 4
2024-06-30 12:57:40,565:INFO:_display_container: 2
2024-06-30 12:57:40,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2927, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-30 12:57:40,569:INFO:create_model() successfully completed......................................
2024-06-30 12:57:40,869:INFO:SubProcess create_model() end ==================================
2024-06-30 12:57:40,869:INFO:Creating metrics dataframe
2024-06-30 12:57:40,957:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-30 12:57:40,980:INFO:Initializing create_model()
2024-06-30 12:57:40,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2927, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 12:57:40,980:INFO:Checking exceptions
2024-06-30 12:57:40,984:INFO:Importing libraries
2024-06-30 12:57:40,985:INFO:Copying training dataset
2024-06-30 12:57:43,343:INFO:Defining folds
2024-06-30 12:57:43,343:INFO:Declaring metric variables
2024-06-30 12:57:43,344:INFO:Importing untrained model
2024-06-30 12:57:43,344:INFO:Declaring custom model
2024-06-30 12:57:43,345:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-30 12:57:43,350:INFO:Cross validation set to False
2024-06-30 12:57:43,350:INFO:Fitting Model
2024-06-30 12:58:02,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-30 12:58:02,986:INFO:[LightGBM] [Info] Number of positive: 331279, number of negative: 41749
2024-06-30 12:58:03,491:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.403087 seconds.
2024-06-30 12:58:03,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-06-30 12:58:03,496:INFO:[LightGBM] [Info] Total Bins 5727
2024-06-30 12:58:03,498:INFO:[LightGBM] [Info] Number of data points in the train set: 373028, number of used features: 75
2024-06-30 12:58:03,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.888081 -> initscore=2.071285
2024-06-30 12:58:03,514:INFO:[LightGBM] [Info] Start training from score 2.071285
2024-06-30 12:58:20,329:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2927, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-30 12:58:20,329:INFO:create_model() successfully completed......................................
2024-06-30 12:58:20,813:INFO:_master_model_container: 4
2024-06-30 12:58:20,813:INFO:_display_container: 2
2024-06-30 12:58:20,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2927, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-30 12:58:20,814:INFO:compare_models() successfully completed......................................
2024-06-30 12:58:20,886:INFO:Initializing plot_model()
2024-06-30 12:58:20,886:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2927, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-30 12:58:20,886:INFO:Checking exceptions
2024-06-30 12:58:22,317:INFO:Preloading libraries
2024-06-30 12:58:22,763:INFO:Copying training dataset
2024-06-30 12:58:22,763:INFO:Plot type: confusion_matrix
2024-06-30 12:58:29,304:INFO:Fitting Model
2024-06-30 12:58:29,322:INFO:Scoring test/hold-out set
2024-06-30 12:58:32,267:INFO:Visual Rendered Successfully
2024-06-30 12:58:32,654:INFO:plot_model() successfully completed......................................
2024-06-30 12:58:32,696:INFO:Initializing plot_model()
2024-06-30 12:58:32,697:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B15C10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2927, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-30 12:58:32,697:INFO:Checking exceptions
2024-06-30 12:58:33,666:INFO:Preloading libraries
2024-06-30 12:58:33,788:INFO:Copying training dataset
2024-06-30 12:58:33,788:INFO:Plot type: auc
2024-06-30 12:58:42,670:INFO:Fitting Model
2024-06-30 12:58:42,690:INFO:Scoring test/hold-out set
2024-06-30 12:58:46,828:INFO:Visual Rendered Successfully
2024-06-30 12:58:47,105:INFO:plot_model() successfully completed......................................
2024-06-30 12:58:47,513:INFO:PyCaret ClassificationExperiment
2024-06-30 12:58:47,513:INFO:Logging name: clf-default-name
2024-06-30 12:58:47,514:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-30 12:58:47,514:INFO:version 3.3.2
2024-06-30 12:58:47,514:INFO:Initializing setup()
2024-06-30 12:58:47,514:INFO:self.USI: d097
2024-06-30 12:58:47,514:INFO:self._variable_keys: {'memory', '_available_plots', 'fold_groups_param', 'X_test', 'exp_name_log', 'is_multiclass', 'pipeline', 'gpu_param', 'log_plots_param', 'data', '_ml_usecase', 'fold_generator', 'html_param', 'y_test', 'target_param', 'idx', 'USI', 'seed', 'X', 'fix_imbalance', 'gpu_n_jobs_param', 'X_train', 'fold_shuffle_param', 'exp_id', 'n_jobs_param', 'y', 'y_train', 'logging_param'}
2024-06-30 12:58:47,514:INFO:Checking environment
2024-06-30 12:58:47,514:INFO:python_version: 3.11.7
2024-06-30 12:58:47,514:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-06-30 12:58:47,514:INFO:machine: AMD64
2024-06-30 12:58:47,515:INFO:platform: Windows-10-10.0.19045-SP0
2024-06-30 12:58:47,522:INFO:Memory: svmem(total=12756160512, available=5049073664, percent=60.4, used=7707086848, free=5049073664)
2024-06-30 12:58:47,522:INFO:Physical Core: 2
2024-06-30 12:58:47,522:INFO:Logical Core: 4
2024-06-30 12:58:47,522:INFO:Checking libraries
2024-06-30 12:58:47,522:INFO:System:
2024-06-30 12:58:47,522:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-06-30 12:58:47,522:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-06-30 12:58:47,523:INFO:   machine: Windows-10-10.0.19045-SP0
2024-06-30 12:58:47,523:INFO:PyCaret required dependencies:
2024-06-30 12:58:47,523:INFO:                 pip: 24.0
2024-06-30 12:58:47,523:INFO:          setuptools: 69.5.1
2024-06-30 12:58:47,524:INFO:             pycaret: 3.3.2
2024-06-30 12:58:47,524:INFO:             IPython: 8.24.0
2024-06-30 12:58:47,524:INFO:          ipywidgets: 8.1.3
2024-06-30 12:58:47,524:INFO:                tqdm: 4.66.4
2024-06-30 12:58:47,524:INFO:               numpy: 1.26.4
2024-06-30 12:58:47,524:INFO:              pandas: 2.1.4
2024-06-30 12:58:47,524:INFO:              jinja2: 3.1.4
2024-06-30 12:58:47,525:INFO:               scipy: 1.11.4
2024-06-30 12:58:47,525:INFO:              joblib: 1.3.2
2024-06-30 12:58:47,525:INFO:             sklearn: 1.4.2
2024-06-30 12:58:47,525:INFO:                pyod: 2.0.1
2024-06-30 12:58:47,525:INFO:            imblearn: 0.12.3
2024-06-30 12:58:47,525:INFO:   category_encoders: 2.6.3
2024-06-30 12:58:47,525:INFO:            lightgbm: 4.4.0
2024-06-30 12:58:47,525:INFO:               numba: 0.60.0
2024-06-30 12:58:47,525:INFO:            requests: 2.32.3
2024-06-30 12:58:47,526:INFO:          matplotlib: 3.7.5
2024-06-30 12:58:47,526:INFO:          scikitplot: 0.3.7
2024-06-30 12:58:47,526:INFO:         yellowbrick: 1.5
2024-06-30 12:58:47,526:INFO:              plotly: 5.22.0
2024-06-30 12:58:47,526:INFO:    plotly-resampler: Not installed
2024-06-30 12:58:47,545:INFO:             kaleido: 0.2.1
2024-06-30 12:58:47,545:INFO:           schemdraw: 0.15
2024-06-30 12:58:47,545:INFO:         statsmodels: 0.14.2
2024-06-30 12:58:47,545:INFO:              sktime: 0.26.0
2024-06-30 12:58:47,546:INFO:               tbats: 1.1.3
2024-06-30 12:58:47,546:INFO:            pmdarima: 2.0.4
2024-06-30 12:58:47,546:INFO:              psutil: 5.9.8
2024-06-30 12:58:47,546:INFO:          markupsafe: 2.1.5
2024-06-30 12:58:47,546:INFO:             pickle5: Not installed
2024-06-30 12:58:47,546:INFO:         cloudpickle: 3.0.0
2024-06-30 12:58:47,546:INFO:         deprecation: 2.1.0
2024-06-30 12:58:47,547:INFO:              xxhash: 3.4.1
2024-06-30 12:58:47,574:INFO:           wurlitzer: Not installed
2024-06-30 12:58:47,575:INFO:PyCaret optional dependencies:
2024-06-30 12:58:47,575:INFO:                shap: 0.44.1
2024-06-30 12:58:47,575:INFO:           interpret: 0.6.2
2024-06-30 12:58:47,576:INFO:                umap: 0.5.6
2024-06-30 12:58:47,576:INFO:     ydata_profiling: 4.8.3
2024-06-30 12:58:47,576:INFO:  explainerdashboard: 0.4.7
2024-06-30 12:58:47,576:INFO:             autoviz: Not installed
2024-06-30 12:58:47,576:INFO:           fairlearn: 0.7.0
2024-06-30 12:58:47,576:INFO:          deepchecks: Not installed
2024-06-30 12:58:47,576:INFO:             xgboost: Not installed
2024-06-30 12:58:47,576:INFO:            catboost: Not installed
2024-06-30 12:58:47,576:INFO:              kmodes: Not installed
2024-06-30 12:58:47,577:INFO:             mlxtend: Not installed
2024-06-30 12:58:47,577:INFO:       statsforecast: Not installed
2024-06-30 12:58:47,595:INFO:        tune_sklearn: Not installed
2024-06-30 12:58:47,595:INFO:                 ray: Not installed
2024-06-30 12:58:47,595:INFO:            hyperopt: Not installed
2024-06-30 12:58:47,596:INFO:              optuna: Not installed
2024-06-30 12:58:47,596:INFO:               skopt: Not installed
2024-06-30 12:58:47,596:INFO:              mlflow: Not installed
2024-06-30 12:58:47,596:INFO:              gradio: Not installed
2024-06-30 12:58:47,596:INFO:             fastapi: Not installed
2024-06-30 12:58:47,596:INFO:             uvicorn: Not installed
2024-06-30 12:58:47,596:INFO:              m2cgen: Not installed
2024-06-30 12:58:47,596:INFO:           evidently: Not installed
2024-06-30 12:58:47,596:INFO:               fugue: Not installed
2024-06-30 12:58:47,596:INFO:           streamlit: Not installed
2024-06-30 12:58:47,597:INFO:             prophet: Not installed
2024-06-30 12:58:47,597:INFO:None
2024-06-30 12:58:47,597:INFO:Set up data.
2024-06-30 12:58:49,743:INFO:Set up folding strategy.
2024-06-30 12:58:49,744:INFO:Set up train/test split.
2024-06-30 12:58:52,589:INFO:Set up index.
2024-06-30 12:58:52,661:INFO:Assigning column types.
2024-06-30 12:58:54,385:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-30 12:58:54,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-30 12:58:54,782:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 12:58:54,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:55,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:55,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-30 12:58:55,282:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 12:58:55,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:55,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:55,380:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-30 12:58:55,674:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 12:58:55,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:55,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:56,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-30 12:58:56,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:56,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:56,247:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-30 12:58:56,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:56,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:57,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:57,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 12:58:57,125:INFO:Preparing preprocessing pipeline...
2024-06-30 12:58:57,260:INFO:Set up label encoding.
2024-06-30 12:58:57,260:INFO:Set up date feature engineering.
2024-06-30 12:58:57,261:INFO:Set up simple imputation.
2024-06-30 12:58:58,238:INFO:Set up encoding of ordinal features.
2024-06-30 12:58:58,841:INFO:Set up encoding of categorical features.
2024-06-30 12:58:58,849:INFO:Set up imbalanced handling.
2024-06-30 12:58:58,849:INFO:Set up feature normalization.
2024-06-30 12:59:14,145:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:249: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2024-06-30 12:59:16,805:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:256: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2024-06-30 12:59:26,786:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:256: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2024-06-30 13:00:10,603:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-06-30 13:00:10,648:INFO:Finished creating preprocessing pipeline.
2024-06-30 13:00:10,772:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-06-30 13:00:10,772:INFO:Creating final display dataframe.
2024-06-30 13:00:15,334:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-06-30 13:01:16,472:INFO:Setup _display_container:                     Description             Value
0                    Session id               652
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (755815, 80)
6   Transformed train set shape      (662558, 80)
7    Transformed test set shape       (93257, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method            onehot
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              d097
2024-06-30 13:01:16,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 13:01:16,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 13:01:17,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 13:01:17,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-30 13:01:17,127:INFO:setup() successfully completed in 149.98s...............
2024-06-30 13:01:17,214:INFO:Initializing compare_models()
2024-06-30 13:01:17,214:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-06-30 13:01:17,214:INFO:Checking exceptions
2024-06-30 13:01:18,266:INFO:Preparing display monitor
2024-06-30 13:01:18,472:INFO:Initializing Logistic Regression
2024-06-30 13:01:18,473:INFO:Total runtime is 1.6681353251139323e-05 minutes
2024-06-30 13:01:18,570:INFO:SubProcess create_model() called ==================================
2024-06-30 13:01:18,571:INFO:Initializing create_model()
2024-06-30 13:01:18,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3A29BCA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 13:01:18,571:INFO:Checking exceptions
2024-06-30 13:01:18,571:INFO:Importing libraries
2024-06-30 13:01:18,571:INFO:Copying training dataset
2024-06-30 13:01:21,321:INFO:Defining folds
2024-06-30 13:01:21,321:INFO:Declaring metric variables
2024-06-30 13:01:21,340:INFO:Importing untrained model
2024-06-30 13:01:21,348:INFO:Logistic Regression Imported successfully
2024-06-30 13:01:21,364:INFO:Starting cross validation
2024-06-30 13:01:21,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 13:05:44,382:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:05:47,422:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:05:50,179:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:05:54,466:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:05:56,580:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:05:59,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:06:00,186:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:06:03,393:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:06:05,783:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:06:06,288:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:06:09,391:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:06:12,294:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:19,581:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:22,789:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:23,041:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:26,045:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:26,533:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:29,327:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:30,613:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:31,338:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:33,731:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:34,900:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:37,113:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:10:37,868:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:12:58,213:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:12:59,801:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:13:00,347:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:13:01,678:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:13:01,843:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:13:03,509:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:13:05,858:INFO:Calculating mean and std
2024-06-30 13:13:05,960:INFO:Creating metrics dataframe
2024-06-30 13:13:05,969:INFO:Uploading results into container
2024-06-30 13:13:05,970:INFO:Uploading model into container now
2024-06-30 13:13:05,974:INFO:_master_model_container: 1
2024-06-30 13:13:05,975:INFO:_display_container: 2
2024-06-30 13:13:05,975:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=652, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-30 13:13:05,975:INFO:create_model() successfully completed......................................
2024-06-30 13:13:06,242:INFO:SubProcess create_model() end ==================================
2024-06-30 13:13:06,242:INFO:Creating metrics dataframe
2024-06-30 13:13:06,260:INFO:Initializing Decision Tree Classifier
2024-06-30 13:13:06,260:INFO:Total runtime is 11.796474981307984 minutes
2024-06-30 13:13:06,266:INFO:SubProcess create_model() called ==================================
2024-06-30 13:13:06,267:INFO:Initializing create_model()
2024-06-30 13:13:06,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3A29BCA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 13:13:06,267:INFO:Checking exceptions
2024-06-30 13:13:06,268:INFO:Importing libraries
2024-06-30 13:13:06,268:INFO:Copying training dataset
2024-06-30 13:13:08,582:INFO:Defining folds
2024-06-30 13:13:08,582:INFO:Declaring metric variables
2024-06-30 13:13:08,600:INFO:Importing untrained model
2024-06-30 13:13:08,609:INFO:Decision Tree Classifier Imported successfully
2024-06-30 13:13:08,636:INFO:Starting cross validation
2024-06-30 13:13:08,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 13:18:57,936:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:18:58,654:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:18:58,865:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:00,598:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:01,135:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:01,633:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:03,289:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:04,385:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:04,624:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:05,801:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:09,297:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:19:12,373:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:24:55,050:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:24:58,032:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:24:59,067:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:01,483:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:02,075:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:04,475:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:15,611:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:18,180:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:18,376:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:21,500:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:21,609:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:25:24,518:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:20,713:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:22,098:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:23,754:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:28,978:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:30,262:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:31,457:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:28:33,169:INFO:Calculating mean and std
2024-06-30 13:28:33,261:INFO:Creating metrics dataframe
2024-06-30 13:28:33,270:INFO:Uploading results into container
2024-06-30 13:28:33,272:INFO:Uploading model into container now
2024-06-30 13:28:33,272:INFO:_master_model_container: 2
2024-06-30 13:28:33,273:INFO:_display_container: 2
2024-06-30 13:28:33,273:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=652, splitter='best')
2024-06-30 13:28:33,274:INFO:create_model() successfully completed......................................
2024-06-30 13:28:33,589:INFO:SubProcess create_model() end ==================================
2024-06-30 13:28:33,589:INFO:Creating metrics dataframe
2024-06-30 13:28:33,624:INFO:Initializing Random Forest Classifier
2024-06-30 13:28:33,624:INFO:Total runtime is 27.252538156509402 minutes
2024-06-30 13:28:33,630:INFO:SubProcess create_model() called ==================================
2024-06-30 13:28:33,631:INFO:Initializing create_model()
2024-06-30 13:28:33,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3A29BCA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 13:28:33,631:INFO:Checking exceptions
2024-06-30 13:28:33,631:INFO:Importing libraries
2024-06-30 13:28:33,631:INFO:Copying training dataset
2024-06-30 13:28:35,987:INFO:Defining folds
2024-06-30 13:28:35,987:INFO:Declaring metric variables
2024-06-30 13:28:36,008:INFO:Importing untrained model
2024-06-30 13:28:36,015:INFO:Random Forest Classifier Imported successfully
2024-06-30 13:28:36,041:INFO:Starting cross validation
2024-06-30 13:28:36,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 13:54:23,332:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:23,878:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:24,630:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:26,936:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:27,204:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:27,853:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:30,689:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:30,997:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:31,756:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:32,087:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:35,311:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 13:54:37,395:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:08,339:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:09,865:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:10,763:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:11,628:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:12,629:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:14,520:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:15,628:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:16,397:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:18,311:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:20,715:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:24,060:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:19:26,218:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:43,302:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:46,550:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:48,031:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:48,566:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:49,691:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:51,286:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:32:52,959:INFO:Calculating mean and std
2024-06-30 14:32:52,963:INFO:Creating metrics dataframe
2024-06-30 14:32:53,021:INFO:Uploading results into container
2024-06-30 14:32:53,023:INFO:Uploading model into container now
2024-06-30 14:32:53,024:INFO:_master_model_container: 3
2024-06-30 14:32:53,024:INFO:_display_container: 2
2024-06-30 14:32:53,025:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=652, verbose=0,
                       warm_start=False)
2024-06-30 14:32:53,025:INFO:create_model() successfully completed......................................
2024-06-30 14:32:53,699:INFO:SubProcess create_model() end ==================================
2024-06-30 14:32:53,699:INFO:Creating metrics dataframe
2024-06-30 14:32:53,717:INFO:Initializing Light Gradient Boosting Machine
2024-06-30 14:32:53,718:INFO:Total runtime is 91.58744138479233 minutes
2024-06-30 14:32:53,725:INFO:SubProcess create_model() called ==================================
2024-06-30 14:32:53,726:INFO:Initializing create_model()
2024-06-30 14:32:53,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C3A29BCA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 14:32:53,726:INFO:Checking exceptions
2024-06-30 14:32:53,753:INFO:Importing libraries
2024-06-30 14:32:53,753:INFO:Copying training dataset
2024-06-30 14:32:55,933:INFO:Defining folds
2024-06-30 14:32:55,933:INFO:Declaring metric variables
2024-06-30 14:32:55,951:INFO:Importing untrained model
2024-06-30 14:32:56,005:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-30 14:32:56,073:INFO:Starting cross validation
2024-06-30 14:32:56,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-30 14:37:47,706:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:37:47,802:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:37:49,629:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:37:49,634:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:37:51,276:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:37:51,330:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:39:03,467:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:39:05,932:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:39:08,245:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:39:15,103:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:39:18,335:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:39:21,272:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:42:43,942:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:42:45,943:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:42:46,619:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:42:47,825:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:42:48,369:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:42:50,010:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:44:07,260:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:44:09,929:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:44:12,467:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:44:22,415:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:44:24,947:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:44:27,185:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:36,483:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:37,845:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:39,180:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:47,855:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:48,986:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:50,060:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:45:51,778:INFO:Calculating mean and std
2024-06-30 14:45:51,781:INFO:Creating metrics dataframe
2024-06-30 14:45:51,786:INFO:Uploading results into container
2024-06-30 14:45:51,787:INFO:Uploading model into container now
2024-06-30 14:45:51,788:INFO:_master_model_container: 4
2024-06-30 14:45:51,793:INFO:_display_container: 2
2024-06-30 14:45:51,794:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-30 14:45:51,794:INFO:create_model() successfully completed......................................
2024-06-30 14:45:52,007:INFO:SubProcess create_model() end ==================================
2024-06-30 14:45:52,007:INFO:Creating metrics dataframe
2024-06-30 14:45:52,051:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-06-30 14:45:52,077:INFO:Initializing create_model()
2024-06-30 14:45:52,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-30 14:45:52,077:INFO:Checking exceptions
2024-06-30 14:45:52,080:INFO:Importing libraries
2024-06-30 14:45:52,081:INFO:Copying training dataset
2024-06-30 14:45:54,437:INFO:Defining folds
2024-06-30 14:45:54,437:INFO:Declaring metric variables
2024-06-30 14:45:54,438:INFO:Importing untrained model
2024-06-30 14:45:54,438:INFO:Declaring custom model
2024-06-30 14:45:54,439:INFO:Light Gradient Boosting Machine Imported successfully
2024-06-30 14:45:54,463:INFO:Cross validation set to False
2024-06-30 14:45:54,464:INFO:Fitting Model
2024-06-30 14:47:03,126:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-06-30 14:47:03,130:INFO:[LightGBM] [Info] Number of positive: 331279, number of negative: 331279
2024-06-30 14:47:05,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.853414 seconds.
2024-06-30 14:47:05,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-06-30 14:47:05,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-06-30 14:47:05,354:INFO:[LightGBM] [Info] Total Bins 16687
2024-06-30 14:47:05,356:INFO:[LightGBM] [Info] Number of data points in the train set: 662558, number of used features: 75
2024-06-30 14:47:05,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-06-30 14:47:32,970:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-30 14:47:32,970:INFO:create_model() successfully completed......................................
2024-06-30 14:47:33,583:INFO:_master_model_container: 4
2024-06-30 14:47:33,583:INFO:_display_container: 2
2024-06-30 14:47:33,584:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-06-30 14:47:33,584:INFO:compare_models() successfully completed......................................
2024-06-30 14:47:33,830:INFO:Initializing plot_model()
2024-06-30 14:47:33,830:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-30 14:47:33,830:INFO:Checking exceptions
2024-06-30 14:47:34,506:INFO:Preloading libraries
2024-06-30 14:47:34,539:INFO:Copying training dataset
2024-06-30 14:47:34,539:INFO:Plot type: confusion_matrix
2024-06-30 14:47:48,479:INFO:Fitting Model
2024-06-30 14:47:48,563:INFO:Scoring test/hold-out set
2024-06-30 14:47:50,996:INFO:Visual Rendered Successfully
2024-06-30 14:47:51,529:INFO:plot_model() successfully completed......................................
2024-06-30 14:47:51,623:INFO:Initializing plot_model()
2024-06-30 14:47:51,623:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-30 14:47:51,624:INFO:Checking exceptions
2024-06-30 14:47:52,283:INFO:Preloading libraries
2024-06-30 14:47:52,327:INFO:Copying training dataset
2024-06-30 14:47:52,327:INFO:Plot type: auc
2024-06-30 14:47:58,802:INFO:Fitting Model
2024-06-30 14:47:58,827:INFO:Scoring test/hold-out set
2024-06-30 14:48:04,650:INFO:Visual Rendered Successfully
2024-06-30 14:48:05,065:INFO:plot_model() successfully completed......................................
2024-06-30 14:48:05,166:INFO:Initializing plot_model()
2024-06-30 14:48:05,166:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-06-30 14:48:05,166:INFO:Checking exceptions
2024-06-30 14:48:05,975:INFO:Preloading libraries
2024-06-30 14:48:06,064:INFO:Copying training dataset
2024-06-30 14:48:06,064:INFO:Plot type: feature
2024-06-30 14:48:06,065:WARNING:No coef_ found. Trying feature_importances_
2024-06-30 14:48:10,665:INFO:Visual Rendered Successfully
2024-06-30 14:48:10,894:INFO:plot_model() successfully completed......................................
2024-06-30 14:48:10,966:INFO:Initializing predict_model()
2024-06-30 14:48:10,966:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C396B5BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C385074540>)
2024-06-30 14:48:10,966:INFO:Checking exceptions
2024-06-30 14:48:10,967:INFO:Preloading libraries
2024-06-30 14:48:20,126:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:48:23,883:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:48:27,042:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-06-30 14:48:31,682:INFO:Initializing save_model()
2024-06-30 14:48:31,683:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=652, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=LGBM, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-06-30 14:48:31,711:INFO:Adding model into prep_pipe
2024-06-30 14:48:31,918:INFO:LGBM.pkl saved in current working directory
2024-06-30 14:48:32,081:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=652,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-06-30 14:48:32,081:INFO:save_model() successfully completed......................................
2024-06-30 15:05:53,311:ERROR:
'gradio' is a soft dependency and not included in the pycaret installation. Please run: `pip install gradio` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-06-30 15:41:46,446:ERROR:
'gradio' is a soft dependency and not included in the pycaret installation. Please run: `pip install gradio` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-06-30 15:41:50,707:ERROR:
'gradio' is a soft dependency and not included in the pycaret installation. Please run: `pip install gradio` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-06-30 15:42:22,579:ERROR:
'gradio' is a soft dependency and not included in the pycaret installation. Please run: `pip install gradio` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2024-07-02 05:18:47,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:18:47,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:18:47,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:18:47,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:19:07,462:INFO:Initializing load_model()
2024-07-02 05:19:07,462:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:20:46,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:20:46,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:20:46,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:20:46,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:21:06,583:INFO:Initializing load_model()
2024-07-02 05:21:06,584:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:21:12,057:INFO:Initializing load_model()
2024-07-02 05:21:12,057:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:22:58,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:22:58,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:22:58,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:22:58,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 05:23:08,178:INFO:Initializing load_model()
2024-07-02 05:23:08,178:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:23:08,517:INFO:Initializing load_model()
2024-07-02 05:23:08,517:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:23:24,825:INFO:Initializing load_model()
2024-07-02 05:23:24,825:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:23:24,894:INFO:Initializing load_model()
2024-07-02 05:23:24,894:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:23:30,822:INFO:Initializing load_model()
2024-07-02 05:23:30,823:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:23:30,891:INFO:Initializing load_model()
2024-07-02 05:23:30,891:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:23:31,167:INFO:Initializing predict_model()
2024-07-02 05:23:31,167:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD6DB990>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBC67740>)
2024-07-02 05:23:31,168:INFO:Checking exceptions
2024-07-02 05:23:31,168:INFO:Preloading libraries
2024-07-02 05:23:31,257:INFO:Set up data.
2024-07-02 05:23:31,420:INFO:Set up index.
2024-07-02 05:36:16,105:INFO:Initializing load_model()
2024-07-02 05:36:16,105:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:36:16,159:INFO:Initializing load_model()
2024-07-02 05:36:16,159:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:36:24,230:INFO:Initializing load_model()
2024-07-02 05:36:24,230:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:36:24,295:INFO:Initializing load_model()
2024-07-02 05:36:24,295:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:36:24,537:INFO:Initializing predict_model()
2024-07-02 05:36:24,538:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD61B790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB2B14CC0>)
2024-07-02 05:36:24,538:INFO:Checking exceptions
2024-07-02 05:36:24,538:INFO:Preloading libraries
2024-07-02 05:36:24,538:INFO:Set up data.
2024-07-02 05:36:24,558:INFO:Set up index.
2024-07-02 05:37:31,297:INFO:Initializing load_model()
2024-07-02 05:37:31,297:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:37:31,362:INFO:Initializing load_model()
2024-07-02 05:37:31,363:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:37:35,983:INFO:Initializing load_model()
2024-07-02 05:37:35,983:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:37:36,047:INFO:Initializing load_model()
2024-07-02 05:37:36,047:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:37:36,289:INFO:Initializing predict_model()
2024-07-02 05:37:36,289:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD62D890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F9C0>)
2024-07-02 05:37:36,289:INFO:Checking exceptions
2024-07-02 05:37:36,289:INFO:Preloading libraries
2024-07-02 05:37:36,290:INFO:Set up data.
2024-07-02 05:37:36,304:INFO:Set up index.
2024-07-02 05:41:00,086:INFO:Initializing load_model()
2024-07-02 05:41:00,087:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:41:00,146:INFO:Initializing load_model()
2024-07-02 05:41:00,146:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:41:03,914:INFO:Initializing load_model()
2024-07-02 05:41:03,914:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:41:03,981:INFO:Initializing load_model()
2024-07-02 05:41:03,982:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:41:04,228:INFO:Initializing predict_model()
2024-07-02 05:41:04,228:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD63A110>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F920>)
2024-07-02 05:41:04,229:INFO:Checking exceptions
2024-07-02 05:41:04,229:INFO:Preloading libraries
2024-07-02 05:41:04,229:INFO:Set up data.
2024-07-02 05:41:04,244:INFO:Set up index.
2024-07-02 05:41:57,528:INFO:Initializing load_model()
2024-07-02 05:41:57,528:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:42:01,700:INFO:Initializing load_model()
2024-07-02 05:42:01,700:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:42:01,945:INFO:Initializing predict_model()
2024-07-02 05:42:01,946:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD620550>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F920>)
2024-07-02 05:42:01,946:INFO:Checking exceptions
2024-07-02 05:42:01,946:INFO:Preloading libraries
2024-07-02 05:42:01,946:INFO:Set up data.
2024-07-02 05:42:01,963:INFO:Set up index.
2024-07-02 05:42:48,071:INFO:Initializing load_model()
2024-07-02 05:42:48,072:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:42:50,912:INFO:Initializing load_model()
2024-07-02 05:42:50,913:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:42:51,148:INFO:Initializing predict_model()
2024-07-02 05:42:51,148:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBFCD950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBC67920>)
2024-07-02 05:42:51,148:INFO:Checking exceptions
2024-07-02 05:42:51,148:INFO:Preloading libraries
2024-07-02 05:42:51,149:INFO:Set up data.
2024-07-02 05:42:51,166:INFO:Set up index.
2024-07-02 05:43:01,642:INFO:Initializing load_model()
2024-07-02 05:43:01,642:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:43:07,730:INFO:Initializing load_model()
2024-07-02 05:43:07,730:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:43:13,740:INFO:Initializing load_model()
2024-07-02 05:43:13,740:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:43:18,528:INFO:Initializing load_model()
2024-07-02 05:43:18,528:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:43:23,540:INFO:Initializing load_model()
2024-07-02 05:43:23,540:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:43:23,768:INFO:Initializing predict_model()
2024-07-02 05:43:23,768:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD645850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F420>)
2024-07-02 05:43:23,769:INFO:Checking exceptions
2024-07-02 05:43:23,769:INFO:Preloading libraries
2024-07-02 05:43:23,769:INFO:Set up data.
2024-07-02 05:43:23,789:INFO:Set up index.
2024-07-02 05:45:05,969:INFO:Initializing load_model()
2024-07-02 05:45:05,970:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:45:09,420:INFO:Initializing load_model()
2024-07-02 05:45:09,420:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:45:09,675:INFO:Initializing predict_model()
2024-07-02 05:45:09,675:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DB43F2B90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBC668E0>)
2024-07-02 05:45:09,676:INFO:Checking exceptions
2024-07-02 05:45:09,676:INFO:Preloading libraries
2024-07-02 05:45:09,677:INFO:Set up data.
2024-07-02 05:45:09,706:INFO:Set up index.
2024-07-02 05:46:51,388:INFO:Initializing load_model()
2024-07-02 05:46:51,388:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:46:52,951:INFO:Initializing load_model()
2024-07-02 05:46:52,951:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:46:53,217:INFO:Initializing predict_model()
2024-07-02 05:46:53,217:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD62CC50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC034CC0>)
2024-07-02 05:46:53,218:INFO:Checking exceptions
2024-07-02 05:46:53,218:INFO:Preloading libraries
2024-07-02 05:46:53,218:INFO:Set up data.
2024-07-02 05:46:53,236:INFO:Set up index.
2024-07-02 05:47:34,877:INFO:Initializing load_model()
2024-07-02 05:47:34,877:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:47:38,026:INFO:Initializing load_model()
2024-07-02 05:47:38,027:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:47:48,618:INFO:Initializing load_model()
2024-07-02 05:47:48,618:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:47:48,840:INFO:Initializing predict_model()
2024-07-02 05:47:48,840:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD653650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035B20>)
2024-07-02 05:47:48,840:INFO:Checking exceptions
2024-07-02 05:47:48,840:INFO:Preloading libraries
2024-07-02 05:47:48,841:INFO:Set up data.
2024-07-02 05:47:48,855:INFO:Set up index.
2024-07-02 05:53:15,965:INFO:Initializing load_model()
2024-07-02 05:53:15,966:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:53:21,905:INFO:Initializing load_model()
2024-07-02 05:53:21,905:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:53:22,147:INFO:Initializing predict_model()
2024-07-02 05:53:22,147:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DB442C810>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB4429B20>)
2024-07-02 05:53:22,148:INFO:Checking exceptions
2024-07-02 05:53:22,148:INFO:Preloading libraries
2024-07-02 05:53:22,148:INFO:Set up data.
2024-07-02 05:53:22,174:INFO:Set up index.
2024-07-02 05:56:17,697:INFO:Initializing load_model()
2024-07-02 05:56:17,698:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:56:22,165:INFO:Initializing load_model()
2024-07-02 05:56:22,165:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:56:29,384:INFO:Initializing load_model()
2024-07-02 05:56:29,384:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:56:41,353:INFO:Initializing load_model()
2024-07-02 05:56:41,353:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:56:55,263:INFO:Initializing load_model()
2024-07-02 05:56:55,263:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:57:12,154:INFO:Initializing load_model()
2024-07-02 05:57:12,155:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:57:27,829:INFO:Initializing load_model()
2024-07-02 05:57:27,829:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:58:12,076:INFO:Initializing load_model()
2024-07-02 05:58:12,076:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:58:23,704:INFO:Initializing load_model()
2024-07-02 05:58:23,708:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:58:37,552:INFO:Initializing load_model()
2024-07-02 05:58:37,552:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:58:52,273:INFO:Initializing load_model()
2024-07-02 05:58:52,273:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:59:08,312:INFO:Initializing load_model()
2024-07-02 05:59:08,312:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:59:10,144:INFO:Initializing load_model()
2024-07-02 05:59:10,144:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:59:26,064:INFO:Initializing load_model()
2024-07-02 05:59:26,065:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:59:26,300:INFO:Initializing predict_model()
2024-07-02 05:59:26,300:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBABA590>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6FA60>)
2024-07-02 05:59:26,300:INFO:Checking exceptions
2024-07-02 05:59:26,300:INFO:Preloading libraries
2024-07-02 05:59:26,301:INFO:Set up data.
2024-07-02 05:59:26,317:INFO:Set up index.
2024-07-02 05:59:49,474:INFO:Initializing load_model()
2024-07-02 05:59:49,474:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:59:50,814:INFO:Initializing load_model()
2024-07-02 05:59:50,815:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 05:59:51,024:INFO:Initializing predict_model()
2024-07-02 05:59:51,024:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBA953D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB1F68720>)
2024-07-02 05:59:51,025:INFO:Checking exceptions
2024-07-02 05:59:51,025:INFO:Preloading libraries
2024-07-02 05:59:51,025:INFO:Set up data.
2024-07-02 05:59:51,039:INFO:Set up index.
2024-07-02 06:51:59,993:INFO:Initializing load_model()
2024-07-02 06:51:59,993:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:52:04,856:INFO:Initializing load_model()
2024-07-02 06:52:04,857:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:52:05,113:INFO:Initializing predict_model()
2024-07-02 06:52:05,113:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DB423F0D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035080>)
2024-07-02 06:52:05,113:INFO:Checking exceptions
2024-07-02 06:52:05,113:INFO:Preloading libraries
2024-07-02 06:52:05,113:INFO:Set up data.
2024-07-02 06:52:05,130:INFO:Set up index.
2024-07-02 06:54:22,913:INFO:Initializing load_model()
2024-07-02 06:54:22,913:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:54:27,459:INFO:Initializing load_model()
2024-07-02 06:54:27,459:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:54:27,757:INFO:Initializing predict_model()
2024-07-02 06:54:27,758:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DBC9EC710>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F920>)
2024-07-02 06:54:27,758:INFO:Checking exceptions
2024-07-02 06:54:27,758:INFO:Preloading libraries
2024-07-02 06:54:27,758:INFO:Set up data.
2024-07-02 06:54:27,774:INFO:Set up index.
2024-07-02 06:54:48,758:INFO:Initializing load_model()
2024-07-02 06:54:48,758:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:54:49,109:INFO:Initializing predict_model()
2024-07-02 06:54:49,109:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD614110>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035D00>)
2024-07-02 06:54:49,109:INFO:Checking exceptions
2024-07-02 06:54:49,109:INFO:Preloading libraries
2024-07-02 06:54:49,111:INFO:Set up data.
2024-07-02 06:54:49,143:INFO:Set up index.
2024-07-02 06:55:49,341:INFO:Initializing load_model()
2024-07-02 06:55:49,341:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:55:49,603:INFO:Initializing predict_model()
2024-07-02 06:55:49,603:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD637D10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035D00>)
2024-07-02 06:55:49,603:INFO:Checking exceptions
2024-07-02 06:55:49,603:INFO:Preloading libraries
2024-07-02 06:55:49,604:INFO:Set up data.
2024-07-02 06:55:49,618:INFO:Set up index.
2024-07-02 06:56:06,654:INFO:Initializing load_model()
2024-07-02 06:56:06,654:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:56:06,913:INFO:Initializing predict_model()
2024-07-02 06:56:06,913:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD61A110>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035580>)
2024-07-02 06:56:06,913:INFO:Checking exceptions
2024-07-02 06:56:06,913:INFO:Preloading libraries
2024-07-02 06:56:06,914:INFO:Set up data.
2024-07-02 06:56:06,926:INFO:Set up index.
2024-07-02 06:56:24,128:INFO:Initializing load_model()
2024-07-02 06:56:24,128:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:56:24,381:INFO:Initializing predict_model()
2024-07-02 06:56:24,382:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DB43F0E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC0344A0>)
2024-07-02 06:56:24,382:INFO:Checking exceptions
2024-07-02 06:56:24,382:INFO:Preloading libraries
2024-07-02 06:56:24,382:INFO:Set up data.
2024-07-02 06:56:24,397:INFO:Set up index.
2024-07-02 06:57:35,290:INFO:Initializing load_model()
2024-07-02 06:57:35,291:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:57:35,538:INFO:Initializing predict_model()
2024-07-02 06:57:35,538:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD6E8A50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB1F68720>)
2024-07-02 06:57:35,540:INFO:Checking exceptions
2024-07-02 06:57:35,540:INFO:Preloading libraries
2024-07-02 06:57:35,541:INFO:Set up data.
2024-07-02 06:57:35,555:INFO:Set up index.
2024-07-02 06:58:51,875:INFO:Initializing load_model()
2024-07-02 06:58:51,877:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:58:52,150:INFO:Initializing predict_model()
2024-07-02 06:58:52,150:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBFBF8D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F880>)
2024-07-02 06:58:52,151:INFO:Checking exceptions
2024-07-02 06:58:52,151:INFO:Preloading libraries
2024-07-02 06:58:52,152:INFO:Set up data.
2024-07-02 06:58:52,174:INFO:Set up index.
2024-07-02 06:59:37,054:INFO:Initializing load_model()
2024-07-02 06:59:37,054:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 06:59:37,311:INFO:Initializing predict_model()
2024-07-02 06:59:37,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBA94790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6FCE0>)
2024-07-02 06:59:37,311:INFO:Checking exceptions
2024-07-02 06:59:37,311:INFO:Preloading libraries
2024-07-02 06:59:37,312:INFO:Set up data.
2024-07-02 06:59:37,326:INFO:Set up index.
2024-07-02 07:00:02,244:INFO:Initializing load_model()
2024-07-02 07:00:02,244:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:00:02,487:INFO:Initializing predict_model()
2024-07-02 07:00:02,487:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD64D790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC029800>)
2024-07-02 07:00:02,487:INFO:Checking exceptions
2024-07-02 07:00:02,487:INFO:Preloading libraries
2024-07-02 07:00:02,487:INFO:Set up data.
2024-07-02 07:00:02,501:INFO:Set up index.
2024-07-02 07:00:44,302:INFO:Initializing load_model()
2024-07-02 07:00:44,302:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:00:44,536:INFO:Initializing predict_model()
2024-07-02 07:00:44,537:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD616950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6FCE0>)
2024-07-02 07:00:44,537:INFO:Checking exceptions
2024-07-02 07:00:44,537:INFO:Preloading libraries
2024-07-02 07:00:44,537:INFO:Set up data.
2024-07-02 07:00:44,552:INFO:Set up index.
2024-07-02 07:00:57,535:INFO:Initializing load_model()
2024-07-02 07:00:57,535:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:01:01,031:INFO:Initializing load_model()
2024-07-02 07:01:01,032:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:01:01,280:INFO:Initializing predict_model()
2024-07-02 07:01:01,281:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD634910>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB442A480>)
2024-07-02 07:01:01,281:INFO:Checking exceptions
2024-07-02 07:01:01,281:INFO:Preloading libraries
2024-07-02 07:01:01,282:INFO:Set up data.
2024-07-02 07:01:01,302:INFO:Set up index.
2024-07-02 07:01:26,000:INFO:Initializing load_model()
2024-07-02 07:01:26,001:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:01:27,765:INFO:Initializing load_model()
2024-07-02 07:01:27,765:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:01:28,064:INFO:Initializing predict_model()
2024-07-02 07:01:28,064:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBD64B10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6F7E0>)
2024-07-02 07:01:28,064:INFO:Checking exceptions
2024-07-02 07:01:28,064:INFO:Preloading libraries
2024-07-02 07:01:28,065:INFO:Set up data.
2024-07-02 07:01:28,081:INFO:Set up index.
2024-07-02 07:07:47,041:INFO:Initializing load_model()
2024-07-02 07:07:47,042:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:07:56,784:INFO:Initializing load_model()
2024-07-02 07:07:56,785:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:07:57,097:INFO:Initializing predict_model()
2024-07-02 07:07:57,097:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCC12B010>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035BC0>)
2024-07-02 07:07:57,097:INFO:Checking exceptions
2024-07-02 07:07:57,097:INFO:Preloading libraries
2024-07-02 07:07:57,098:INFO:Set up data.
2024-07-02 07:07:57,114:INFO:Set up index.
2024-07-02 07:11:07,782:INFO:Initializing load_model()
2024-07-02 07:11:07,783:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:11:34,308:INFO:Initializing load_model()
2024-07-02 07:11:34,308:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:15:48,588:INFO:Initializing load_model()
2024-07-02 07:15:48,588:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:16:09,714:INFO:Initializing load_model()
2024-07-02 07:16:09,715:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:16:21,938:INFO:Initializing load_model()
2024-07-02 07:16:21,938:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:16:26,944:INFO:Initializing load_model()
2024-07-02 07:16:26,944:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:16:28,351:INFO:Initializing load_model()
2024-07-02 07:16:28,352:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:16:28,583:INFO:Initializing predict_model()
2024-07-02 07:16:28,584:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCA75CB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6FE20>)
2024-07-02 07:16:28,584:INFO:Checking exceptions
2024-07-02 07:16:28,584:INFO:Preloading libraries
2024-07-02 07:16:28,585:INFO:Set up data.
2024-07-02 07:16:28,596:INFO:Set up index.
2024-07-02 07:17:11,779:INFO:Initializing load_model()
2024-07-02 07:17:11,780:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:15,049:INFO:Initializing load_model()
2024-07-02 07:17:15,049:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:15,316:INFO:Initializing predict_model()
2024-07-02 07:17:15,317:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBAB18D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB4249BC0>)
2024-07-02 07:17:15,317:INFO:Checking exceptions
2024-07-02 07:17:15,317:INFO:Preloading libraries
2024-07-02 07:17:15,317:INFO:Set up data.
2024-07-02 07:17:15,334:INFO:Set up index.
2024-07-02 07:17:32,524:INFO:Initializing load_model()
2024-07-02 07:17:32,524:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:34,097:INFO:Initializing load_model()
2024-07-02 07:17:34,097:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:36,576:INFO:Initializing load_model()
2024-07-02 07:17:36,577:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:42,260:INFO:Initializing load_model()
2024-07-02 07:17:42,260:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:50,785:INFO:Initializing load_model()
2024-07-02 07:17:50,785:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:17:51,011:INFO:Initializing predict_model()
2024-07-02 07:17:51,011:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBFC2C50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DC6E6DC60>)
2024-07-02 07:17:51,011:INFO:Checking exceptions
2024-07-02 07:17:51,011:INFO:Preloading libraries
2024-07-02 07:17:51,012:INFO:Set up data.
2024-07-02 07:17:51,028:INFO:Set up index.
2024-07-02 07:19:04,271:INFO:Initializing load_model()
2024-07-02 07:19:04,271:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:19:06,571:INFO:Initializing load_model()
2024-07-02 07:19:06,571:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:19:06,844:INFO:Initializing predict_model()
2024-07-02 07:19:06,844:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD644310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB4249BC0>)
2024-07-02 07:19:06,845:INFO:Checking exceptions
2024-07-02 07:19:06,845:INFO:Preloading libraries
2024-07-02 07:19:06,845:INFO:Set up data.
2024-07-02 07:19:06,864:INFO:Set up index.
2024-07-02 07:19:15,478:INFO:Initializing load_model()
2024-07-02 07:19:15,479:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:19:17,713:INFO:Initializing load_model()
2024-07-02 07:19:17,713:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:19:17,936:INFO:Initializing predict_model()
2024-07-02 07:19:17,937:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD615650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DB442A520>)
2024-07-02 07:19:17,937:INFO:Checking exceptions
2024-07-02 07:19:17,937:INFO:Preloading libraries
2024-07-02 07:19:17,937:INFO:Set up data.
2024-07-02 07:19:17,958:INFO:Set up index.
2024-07-02 07:19:25,748:INFO:Initializing load_model()
2024-07-02 07:19:25,749:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:19:27,904:INFO:Initializing load_model()
2024-07-02 07:19:27,905:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:19:28,130:INFO:Initializing predict_model()
2024-07-02 07:19:28,130:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCD628950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCA2A23E0>)
2024-07-02 07:19:28,130:INFO:Checking exceptions
2024-07-02 07:19:28,130:INFO:Preloading libraries
2024-07-02 07:19:28,131:INFO:Set up data.
2024-07-02 07:19:28,145:INFO:Set up index.
2024-07-02 07:20:54,964:INFO:Initializing load_model()
2024-07-02 07:20:54,964:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:22:31,884:INFO:Initializing load_model()
2024-07-02 07:22:31,884:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:34:27,060:INFO:Initializing load_model()
2024-07-02 07:34:27,060:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 07:59:26,066:INFO:Initializing load_model()
2024-07-02 07:59:26,067:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:00:28,805:INFO:Initializing load_model()
2024-07-02 08:00:28,806:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:00:54,478:INFO:Initializing load_model()
2024-07-02 08:00:54,478:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:00:54,870:INFO:Initializing predict_model()
2024-07-02 08:00:54,870:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCBA9EF50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCC035300>)
2024-07-02 08:00:54,870:INFO:Checking exceptions
2024-07-02 08:00:54,870:INFO:Preloading libraries
2024-07-02 08:00:54,871:INFO:Set up data.
2024-07-02 08:00:54,885:INFO:Set up index.
2024-07-02 08:01:29,553:INFO:Initializing load_model()
2024-07-02 08:01:29,554:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:02:12,296:INFO:Initializing load_model()
2024-07-02 08:02:12,296:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:02:27,113:INFO:Initializing load_model()
2024-07-02 08:02:27,113:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:11:50,060:INFO:Initializing load_model()
2024-07-02 08:11:50,061:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:11:50,389:INFO:Initializing predict_model()
2024-07-02 08:11:50,389:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCC043BD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBABD1C0>)
2024-07-02 08:11:50,389:INFO:Checking exceptions
2024-07-02 08:11:50,389:INFO:Preloading libraries
2024-07-02 08:11:50,390:INFO:Set up data.
2024-07-02 08:11:50,406:INFO:Set up index.
2024-07-02 08:12:07,152:INFO:Initializing load_model()
2024-07-02 08:12:07,152:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:12:44,924:INFO:Initializing load_model()
2024-07-02 08:12:44,924:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:15:28,695:INFO:Initializing load_model()
2024-07-02 08:15:28,696:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:15:30,399:INFO:Initializing load_model()
2024-07-02 08:15:30,399:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 08:15:30,660:INFO:Initializing predict_model()
2024-07-02 08:15:30,660:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022DCA75AC10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022DCBD6FBA0>)
2024-07-02 08:15:30,661:INFO:Checking exceptions
2024-07-02 08:15:30,661:INFO:Preloading libraries
2024-07-02 08:15:30,662:INFO:Set up data.
2024-07-02 08:15:30,694:INFO:Set up index.
2024-07-02 09:21:46,482:INFO:Initializing load_model()
2024-07-02 09:21:46,491:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 13:56:56,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 13:56:56,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 13:56:56,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 13:56:56,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 14:41:36,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 14:41:36,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 14:41:36,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 14:41:36,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 14:41:40,032:INFO:Initializing load_model()
2024-07-02 14:41:40,032:INFO:Initializing load_model()
2024-07-02 14:41:40,032:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:41:40,032:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:41:41,115:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 14:42:23,864:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 14:42:23,895:INFO:Initializing load_model()
2024-07-02 14:42:23,895:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:42:23,942:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 14:42:23,942:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain_core\_api\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.
  warn_deprecated(

2024-07-02 14:42:25,887:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain_core\_api\deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.
  warn_deprecated(

2024-07-02 14:46:55,181:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 14:46:55,188:INFO:Initializing load_model()
2024-07-02 14:46:55,188:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:46:55,236:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 14:47:35,061:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 14:47:35,064:INFO:Initializing load_model()
2024-07-02 14:47:35,064:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:47:35,104:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 14:50:03,578:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 14:50:03,580:INFO:Initializing load_model()
2024-07-02 14:50:03,580:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:50:03,624:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 14:55:27,248:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 14:55:27,251:INFO:Initializing load_model()
2024-07-02 14:55:27,251:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:55:27,299:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 14:56:46,541:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 14:56:46,542:INFO:Initializing load_model()
2024-07-02 14:56:46,542:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 14:56:46,590:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:01:42,386:WARNING:C:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\langchain\llms\__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import OpenAI`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(

2024-07-02 15:01:42,388:INFO:Initializing load_model()
2024-07-02 15:01:42,388:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:01:42,421:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:05:06,190:INFO:Initializing load_model()
2024-07-02 15:05:06,190:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:05:06,223:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:12:21,520:INFO:Initializing load_model()
2024-07-02 15:12:21,521:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:12:21,572:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:13:00,249:INFO:Initializing load_model()
2024-07-02 15:13:00,250:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:13:00,297:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:13:14,941:INFO:Initializing load_model()
2024-07-02 15:13:14,942:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:13:14,999:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:13:29,126:INFO:Initializing load_model()
2024-07-02 15:13:29,127:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:13:29,182:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:14:56,670:INFO:Initializing load_model()
2024-07-02 15:14:56,670:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:14:56,707:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:15:21,634:INFO:Initializing load_model()
2024-07-02 15:15:21,634:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:15:21,679:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:15:35,624:INFO:Initializing load_model()
2024-07-02 15:15:35,624:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:15:35,677:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:16:05,560:INFO:Initializing load_model()
2024-07-02 15:16:05,560:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:16:05,604:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:17:47,075:INFO:Initializing load_model()
2024-07-02 15:17:47,075:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:17:47,120:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:20:52,503:INFO:Initializing load_model()
2024-07-02 15:20:52,503:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:20:52,544:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:37:56,675:INFO:Initializing load_model()
2024-07-02 15:37:56,675:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:37:56,712:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:39:26,767:INFO:Initializing load_model()
2024-07-02 15:39:26,767:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:39:26,822:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:40:01,912:INFO:Initializing load_model()
2024-07-02 15:40:01,912:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:40:01,944:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:40:02,174:INFO:Initializing predict_model()
2024-07-02 15:40:02,174:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254740A0250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002545F91F4C0>)
2024-07-02 15:40:02,174:INFO:Checking exceptions
2024-07-02 15:40:02,174:INFO:Preloading libraries
2024-07-02 15:40:02,177:INFO:Set up data.
2024-07-02 15:40:02,182:INFO:Set up index.
2024-07-02 15:44:22,509:INFO:Initializing load_model()
2024-07-02 15:44:22,509:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:44:22,566:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:44:32,890:INFO:Initializing load_model()
2024-07-02 15:44:32,891:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:44:32,932:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:44:40,499:INFO:Initializing load_model()
2024-07-02 15:44:40,500:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:44:40,546:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:45:04,050:INFO:Initializing load_model()
2024-07-02 15:45:04,050:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:45:04,112:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:45:16,879:INFO:Initializing load_model()
2024-07-02 15:45:16,883:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:45:16,917:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:45:36,579:INFO:Initializing load_model()
2024-07-02 15:45:36,582:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 15:45:36,654:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 15:51:17,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 15:51:17,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 15:51:17,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 15:51:17,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-02 15:51:25,317:INFO:PyCaret ClassificationExperiment
2024-07-02 15:51:25,317:INFO:Logging name: clf-default-name
2024-07-02 15:51:25,317:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-02 15:51:25,317:INFO:version 3.3.2
2024-07-02 15:51:25,317:INFO:Initializing setup()
2024-07-02 15:51:25,317:INFO:self.USI: 2762
2024-07-02 15:51:25,317:INFO:self._variable_keys: {'gpu_param', 'y_train', 'exp_id', 'is_multiclass', 'data', 'seed', '_ml_usecase', 'pipeline', 'X_test', 'y', 'X_train', 'fold_groups_param', 'y_test', 'log_plots_param', 'html_param', 'n_jobs_param', '_available_plots', 'idx', 'fold_generator', 'target_param', 'gpu_n_jobs_param', 'fix_imbalance', 'logging_param', 'X', 'USI', 'exp_name_log', 'memory', 'fold_shuffle_param'}
2024-07-02 15:51:25,317:INFO:Checking environment
2024-07-02 15:51:25,317:INFO:python_version: 3.11.7
2024-07-02 15:51:25,317:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-07-02 15:51:25,317:INFO:machine: AMD64
2024-07-02 15:51:25,317:INFO:platform: Windows-10-10.0.19045-SP0
2024-07-02 15:51:25,377:INFO:Memory: svmem(total=12756160512, available=4930379776, percent=61.3, used=7825780736, free=4930379776)
2024-07-02 15:51:25,378:INFO:Physical Core: 2
2024-07-02 15:51:25,378:INFO:Logical Core: 4
2024-07-02 15:51:25,378:INFO:Checking libraries
2024-07-02 15:51:25,378:INFO:System:
2024-07-02 15:51:25,379:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-07-02 15:51:25,379:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-07-02 15:51:25,379:INFO:   machine: Windows-10-10.0.19045-SP0
2024-07-02 15:51:25,379:INFO:PyCaret required dependencies:
2024-07-02 15:51:25,675:INFO:                 pip: 24.0
2024-07-02 15:51:25,675:INFO:          setuptools: 69.5.1
2024-07-02 15:51:25,675:INFO:             pycaret: 3.3.2
2024-07-02 15:51:25,675:INFO:             IPython: 8.24.0
2024-07-02 15:51:25,675:INFO:          ipywidgets: 8.1.3
2024-07-02 15:51:25,675:INFO:                tqdm: 4.66.4
2024-07-02 15:51:25,675:INFO:               numpy: 1.26.4
2024-07-02 15:51:25,675:INFO:              pandas: 2.1.4
2024-07-02 15:51:25,675:INFO:              jinja2: 3.1.4
2024-07-02 15:51:25,675:INFO:               scipy: 1.11.4
2024-07-02 15:51:25,675:INFO:              joblib: 1.3.2
2024-07-02 15:51:25,675:INFO:             sklearn: 1.4.2
2024-07-02 15:51:25,675:INFO:                pyod: 2.0.1
2024-07-02 15:51:25,675:INFO:            imblearn: 0.12.3
2024-07-02 15:51:25,675:INFO:   category_encoders: 2.6.3
2024-07-02 15:51:25,675:INFO:            lightgbm: 4.4.0
2024-07-02 15:51:25,675:INFO:               numba: 0.60.0
2024-07-02 15:51:25,675:INFO:            requests: 2.32.3
2024-07-02 15:51:25,675:INFO:          matplotlib: 3.7.5
2024-07-02 15:51:25,675:INFO:          scikitplot: 0.3.7
2024-07-02 15:51:25,675:INFO:         yellowbrick: 1.5
2024-07-02 15:51:25,675:INFO:              plotly: 5.22.0
2024-07-02 15:51:25,675:INFO:    plotly-resampler: Not installed
2024-07-02 15:51:25,675:INFO:             kaleido: 0.2.1
2024-07-02 15:51:25,675:INFO:           schemdraw: 0.15
2024-07-02 15:51:25,675:INFO:         statsmodels: 0.14.2
2024-07-02 15:51:25,675:INFO:              sktime: 0.26.0
2024-07-02 15:51:25,675:INFO:               tbats: 1.1.3
2024-07-02 15:51:25,675:INFO:            pmdarima: 2.0.4
2024-07-02 15:51:25,675:INFO:              psutil: 5.9.8
2024-07-02 15:51:25,675:INFO:          markupsafe: 2.1.5
2024-07-02 15:51:25,675:INFO:             pickle5: Not installed
2024-07-02 15:51:25,675:INFO:         cloudpickle: 3.0.0
2024-07-02 15:51:25,675:INFO:         deprecation: 2.1.0
2024-07-02 15:51:25,675:INFO:              xxhash: 3.4.1
2024-07-02 15:51:25,675:INFO:           wurlitzer: Not installed
2024-07-02 15:51:25,675:INFO:PyCaret optional dependencies:
2024-07-02 15:51:42,983:INFO:                shap: 0.44.1
2024-07-02 15:51:42,983:INFO:           interpret: 0.6.2
2024-07-02 15:51:42,983:INFO:                umap: 0.5.6
2024-07-02 15:51:42,983:INFO:     ydata_profiling: 4.8.3
2024-07-02 15:51:42,983:INFO:  explainerdashboard: 0.4.7
2024-07-02 15:51:42,983:INFO:             autoviz: Not installed
2024-07-02 15:51:42,983:INFO:           fairlearn: 0.7.0
2024-07-02 15:51:42,983:INFO:          deepchecks: Not installed
2024-07-02 15:51:42,983:INFO:             xgboost: Not installed
2024-07-02 15:51:42,983:INFO:            catboost: Not installed
2024-07-02 15:51:42,983:INFO:              kmodes: Not installed
2024-07-02 15:51:42,983:INFO:             mlxtend: Not installed
2024-07-02 15:51:42,983:INFO:       statsforecast: Not installed
2024-07-02 15:51:42,983:INFO:        tune_sklearn: Not installed
2024-07-02 15:51:42,983:INFO:                 ray: Not installed
2024-07-02 15:51:42,983:INFO:            hyperopt: Not installed
2024-07-02 15:51:42,983:INFO:              optuna: Not installed
2024-07-02 15:51:42,983:INFO:               skopt: Not installed
2024-07-02 15:51:42,983:INFO:              mlflow: 2.14.1
2024-07-02 15:51:42,983:INFO:              gradio: 4.37.2
2024-07-02 15:51:42,983:INFO:             fastapi: 0.111.0
2024-07-02 15:51:42,983:INFO:             uvicorn: 0.30.1
2024-07-02 15:51:42,983:INFO:              m2cgen: 0.10.0
2024-07-02 15:51:42,983:INFO:           evidently: 0.4.30
2024-07-02 15:51:42,983:INFO:               fugue: Not installed
2024-07-02 15:51:42,983:INFO:           streamlit: 1.36.0
2024-07-02 15:51:42,983:INFO:             prophet: Not installed
2024-07-02 15:51:42,983:INFO:None
2024-07-02 15:51:42,983:INFO:Set up data.
2024-07-02 15:51:44,412:INFO:Set up folding strategy.
2024-07-02 15:51:44,412:INFO:Set up train/test split.
2024-07-02 15:51:45,668:INFO:Set up index.
2024-07-02 15:51:45,710:INFO:Assigning column types.
2024-07-02 15:51:46,248:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-02 15:51:46,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-02 15:51:46,334:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:51:46,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:46,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:46,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-02 15:51:46,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:51:46,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:46,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:46,856:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-02 15:51:46,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:51:46,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:46,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,028:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:51:47,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,091:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-02 15:51:47,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:51:47,310:INFO:Preparing preprocessing pipeline...
2024-07-02 15:51:47,412:INFO:Set up label encoding.
2024-07-02 15:51:47,412:INFO:Set up date feature engineering.
2024-07-02 15:51:47,413:INFO:Set up simple imputation.
2024-07-02 15:51:47,641:INFO:Set up encoding of ordinal features.
2024-07-02 15:51:47,881:INFO:Set up encoding of categorical features.
2024-07-02 15:51:47,881:INFO:Set up imbalanced handling.
2024-07-02 15:51:47,881:INFO:Set up feature normalization.
2024-07-02 15:52:20,259:INFO:Finished creating preprocessing pipeline.
2024-07-02 15:52:20,306:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-07-02 15:52:20,306:INFO:Creating final display dataframe.
2024-07-02 15:53:23,036:INFO:PyCaret ClassificationExperiment
2024-07-02 15:53:23,036:INFO:Logging name: clf-default-name
2024-07-02 15:53:23,038:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-02 15:53:23,038:INFO:version 3.3.2
2024-07-02 15:53:23,039:INFO:Initializing setup()
2024-07-02 15:53:23,040:INFO:self.USI: 77a9
2024-07-02 15:53:23,040:INFO:self._variable_keys: {'gpu_param', 'y_train', 'exp_id', 'is_multiclass', 'data', 'seed', '_ml_usecase', 'pipeline', 'X_test', 'y', 'X_train', 'fold_groups_param', 'y_test', 'log_plots_param', 'html_param', 'n_jobs_param', '_available_plots', 'idx', 'fold_generator', 'target_param', 'gpu_n_jobs_param', 'fix_imbalance', 'logging_param', 'X', 'USI', 'exp_name_log', 'memory', 'fold_shuffle_param'}
2024-07-02 15:53:23,041:INFO:Checking environment
2024-07-02 15:53:23,041:INFO:python_version: 3.11.7
2024-07-02 15:53:23,042:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2024-07-02 15:53:23,043:INFO:machine: AMD64
2024-07-02 15:53:23,043:INFO:platform: Windows-10-10.0.19045-SP0
2024-07-02 15:53:23,050:INFO:Memory: svmem(total=12756160512, available=3882749952, percent=69.6, used=8873410560, free=3882749952)
2024-07-02 15:53:23,050:INFO:Physical Core: 2
2024-07-02 15:53:23,050:INFO:Logical Core: 4
2024-07-02 15:53:23,050:INFO:Checking libraries
2024-07-02 15:53:23,050:INFO:System:
2024-07-02 15:53:23,050:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2024-07-02 15:53:23,050:INFO:executable: c:\Users\USER\anaconda3\envs\idxparners\python.exe
2024-07-02 15:53:23,064:INFO:   machine: Windows-10-10.0.19045-SP0
2024-07-02 15:53:23,065:INFO:PyCaret required dependencies:
2024-07-02 15:53:23,065:INFO:                 pip: 24.0
2024-07-02 15:53:23,068:INFO:          setuptools: 69.5.1
2024-07-02 15:53:23,068:INFO:             pycaret: 3.3.2
2024-07-02 15:53:23,068:INFO:             IPython: 8.24.0
2024-07-02 15:53:23,069:INFO:          ipywidgets: 8.1.3
2024-07-02 15:53:23,070:INFO:                tqdm: 4.66.4
2024-07-02 15:53:23,070:INFO:               numpy: 1.26.4
2024-07-02 15:53:23,070:INFO:              pandas: 2.1.4
2024-07-02 15:53:23,072:INFO:              jinja2: 3.1.4
2024-07-02 15:53:23,072:INFO:               scipy: 1.11.4
2024-07-02 15:53:23,072:INFO:              joblib: 1.3.2
2024-07-02 15:53:23,073:INFO:             sklearn: 1.4.2
2024-07-02 15:53:23,073:INFO:                pyod: 2.0.1
2024-07-02 15:53:23,074:INFO:            imblearn: 0.12.3
2024-07-02 15:53:23,074:INFO:   category_encoders: 2.6.3
2024-07-02 15:53:23,075:INFO:            lightgbm: 4.4.0
2024-07-02 15:53:23,075:INFO:               numba: 0.60.0
2024-07-02 15:53:23,075:INFO:            requests: 2.32.3
2024-07-02 15:53:23,076:INFO:          matplotlib: 3.7.5
2024-07-02 15:53:23,076:INFO:          scikitplot: 0.3.7
2024-07-02 15:53:23,077:INFO:         yellowbrick: 1.5
2024-07-02 15:53:23,077:INFO:              plotly: 5.22.0
2024-07-02 15:53:23,077:INFO:    plotly-resampler: Not installed
2024-07-02 15:53:23,078:INFO:             kaleido: 0.2.1
2024-07-02 15:53:23,079:INFO:           schemdraw: 0.15
2024-07-02 15:53:23,079:INFO:         statsmodels: 0.14.2
2024-07-02 15:53:23,080:INFO:              sktime: 0.26.0
2024-07-02 15:53:23,081:INFO:               tbats: 1.1.3
2024-07-02 15:53:23,081:INFO:            pmdarima: 2.0.4
2024-07-02 15:53:23,081:INFO:              psutil: 5.9.8
2024-07-02 15:53:23,081:INFO:          markupsafe: 2.1.5
2024-07-02 15:53:23,081:INFO:             pickle5: Not installed
2024-07-02 15:53:23,081:INFO:         cloudpickle: 3.0.0
2024-07-02 15:53:23,081:INFO:         deprecation: 2.1.0
2024-07-02 15:53:23,081:INFO:              xxhash: 3.4.1
2024-07-02 15:53:23,081:INFO:           wurlitzer: Not installed
2024-07-02 15:53:23,081:INFO:PyCaret optional dependencies:
2024-07-02 15:53:23,081:INFO:                shap: 0.44.1
2024-07-02 15:53:23,081:INFO:           interpret: 0.6.2
2024-07-02 15:53:23,081:INFO:                umap: 0.5.6
2024-07-02 15:53:23,081:INFO:     ydata_profiling: 4.8.3
2024-07-02 15:53:23,081:INFO:  explainerdashboard: 0.4.7
2024-07-02 15:53:23,081:INFO:             autoviz: Not installed
2024-07-02 15:53:23,081:INFO:           fairlearn: 0.7.0
2024-07-02 15:53:23,081:INFO:          deepchecks: Not installed
2024-07-02 15:53:23,081:INFO:             xgboost: Not installed
2024-07-02 15:53:23,081:INFO:            catboost: Not installed
2024-07-02 15:53:23,081:INFO:              kmodes: Not installed
2024-07-02 15:53:23,081:INFO:             mlxtend: Not installed
2024-07-02 15:53:23,081:INFO:       statsforecast: Not installed
2024-07-02 15:53:23,081:INFO:        tune_sklearn: Not installed
2024-07-02 15:53:23,081:INFO:                 ray: Not installed
2024-07-02 15:53:23,081:INFO:            hyperopt: Not installed
2024-07-02 15:53:23,081:INFO:              optuna: Not installed
2024-07-02 15:53:23,081:INFO:               skopt: Not installed
2024-07-02 15:53:23,081:INFO:              mlflow: 2.14.1
2024-07-02 15:53:23,081:INFO:              gradio: 4.37.2
2024-07-02 15:53:23,081:INFO:             fastapi: 0.111.0
2024-07-02 15:53:23,081:INFO:             uvicorn: 0.30.1
2024-07-02 15:53:23,081:INFO:              m2cgen: 0.10.0
2024-07-02 15:53:23,081:INFO:           evidently: 0.4.30
2024-07-02 15:53:23,081:INFO:               fugue: Not installed
2024-07-02 15:53:23,081:INFO:           streamlit: 1.36.0
2024-07-02 15:53:23,081:INFO:             prophet: Not installed
2024-07-02 15:53:23,081:INFO:None
2024-07-02 15:53:23,081:INFO:Set up data.
2024-07-02 15:53:24,130:INFO:Set up folding strategy.
2024-07-02 15:53:24,131:INFO:Set up train/test split.
2024-07-02 15:53:24,864:INFO:Set up index.
2024-07-02 15:53:24,898:INFO:Assigning column types.
2024-07-02 15:53:25,367:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-02 15:53:25,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-02 15:53:25,464:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:53:25,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-02 15:53:25,548:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:53:25,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,581:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-02 15:53:25,632:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:53:25,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-02 15:53:25,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,748:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-02 15:53:25,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:53:25,948:INFO:Preparing preprocessing pipeline...
2024-07-02 15:53:25,998:INFO:Set up label encoding.
2024-07-02 15:53:25,998:INFO:Set up date feature engineering.
2024-07-02 15:53:25,998:INFO:Set up simple imputation.
2024-07-02 15:53:26,232:INFO:Set up encoding of ordinal features.
2024-07-02 15:53:26,449:INFO:Set up encoding of categorical features.
2024-07-02 15:53:26,469:INFO:Set up imbalanced handling.
2024-07-02 15:53:26,469:INFO:Set up feature normalization.
2024-07-02 15:53:55,609:INFO:Finished creating preprocessing pipeline.
2024-07-02 15:53:55,659:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFea...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-07-02 15:53:55,659:INFO:Creating final display dataframe.
2024-07-02 15:54:32,004:INFO:Setup _display_container:                     Description             Value
0                    Session id              5537
1                        Target            status
2                   Target type            Binary
3                Target mapping   bad: 0, good: 1
4           Original data shape      (466285, 38)
5        Transformed data shape      (755815, 80)
6   Transformed train set shape      (662558, 80)
7    Transformed test set shape       (93257, 80)
8              Numeric features                26
9                 Date features                 4
10         Categorical features                 7
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation            median
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method            onehot
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            minmax
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              77a9
2024-07-02 15:54:32,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:54:32,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:54:32,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:54:32,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-02 15:54:32,222:INFO:setup() successfully completed in 69.55s...............
2024-07-02 15:54:32,235:INFO:Initializing compare_models()
2024-07-02 15:54:32,235:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-02 15:54:32,235:INFO:Checking exceptions
2024-07-02 15:54:32,671:INFO:Preparing display monitor
2024-07-02 15:54:32,809:INFO:Initializing Logistic Regression
2024-07-02 15:54:32,809:INFO:Total runtime is 0.0 minutes
2024-07-02 15:54:32,813:INFO:SubProcess create_model() called ==================================
2024-07-02 15:54:32,813:INFO:Initializing create_model()
2024-07-02 15:54:32,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013606C71810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-02 15:54:32,814:INFO:Checking exceptions
2024-07-02 15:54:32,814:INFO:Importing libraries
2024-07-02 15:54:32,814:INFO:Copying training dataset
2024-07-02 15:54:33,437:INFO:Defining folds
2024-07-02 15:54:33,437:INFO:Declaring metric variables
2024-07-02 15:54:33,453:INFO:Importing untrained model
2024-07-02 15:54:33,453:INFO:Logistic Regression Imported successfully
2024-07-02 15:54:33,469:INFO:Starting cross validation
2024-07-02 15:54:33,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-02 15:58:49,707:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:50,444:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:50,457:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:50,463:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:50,474:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:51,174:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:51,191:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:51,207:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 15:58:51,208:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:05,803:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:05,793:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,140:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,167:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,177:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,435:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,799:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,809:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:07,824:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:02:08,075:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:42,877:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:43,273:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:43,403:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:43,675:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:43,804:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:44,259:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:03:46,209:INFO:Calculating mean and std
2024-07-02 16:03:46,509:INFO:Creating metrics dataframe
2024-07-02 16:03:46,625:INFO:Uploading results into container
2024-07-02 16:03:46,625:INFO:Uploading model into container now
2024-07-02 16:03:46,625:INFO:_master_model_container: 1
2024-07-02 16:03:46,625:INFO:_display_container: 2
2024-07-02 16:03:46,625:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5537, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-02 16:03:46,625:INFO:create_model() successfully completed......................................
2024-07-02 16:03:58,061:INFO:SubProcess create_model() end ==================================
2024-07-02 16:03:58,061:INFO:Creating metrics dataframe
2024-07-02 16:03:58,378:INFO:Initializing Decision Tree Classifier
2024-07-02 16:03:58,378:INFO:Total runtime is 9.426151049137115 minutes
2024-07-02 16:03:58,378:INFO:SubProcess create_model() called ==================================
2024-07-02 16:03:58,461:INFO:Initializing create_model()
2024-07-02 16:03:58,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013606C71810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-02 16:03:58,461:INFO:Checking exceptions
2024-07-02 16:03:58,461:INFO:Importing libraries
2024-07-02 16:03:58,511:INFO:Copying training dataset
2024-07-02 16:04:20,599:INFO:Defining folds
2024-07-02 16:04:20,599:INFO:Declaring metric variables
2024-07-02 16:04:20,607:INFO:Importing untrained model
2024-07-02 16:04:20,613:INFO:Decision Tree Classifier Imported successfully
2024-07-02 16:04:20,619:INFO:Starting cross validation
2024-07-02 16:04:37,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-02 16:06:33,665:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:34,408:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:34,736:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:35,144:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:35,340:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:35,467:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:36,087:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:36,298:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:36,910:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:36,920:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:37,719:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:06:38,568:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:30,292:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:30,314:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:30,827:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:31,017:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:31,027:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:31,552:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:31,736:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:31,777:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:32,298:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:34,938:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:35,627:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:08:36,222:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:57,699:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:57,834:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:58,101:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:58,251:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:58,482:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:58,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:09:59,484:INFO:Calculating mean and std
2024-07-02 16:09:59,484:INFO:Creating metrics dataframe
2024-07-02 16:09:59,505:INFO:Uploading results into container
2024-07-02 16:09:59,506:INFO:Uploading model into container now
2024-07-02 16:09:59,506:INFO:_master_model_container: 2
2024-07-02 16:09:59,506:INFO:_display_container: 2
2024-07-02 16:09:59,506:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5537, splitter='best')
2024-07-02 16:09:59,506:INFO:create_model() successfully completed......................................
2024-07-02 16:09:59,683:INFO:SubProcess create_model() end ==================================
2024-07-02 16:09:59,683:INFO:Creating metrics dataframe
2024-07-02 16:09:59,700:INFO:Initializing Random Forest Classifier
2024-07-02 16:09:59,700:INFO:Total runtime is 15.448181311289469 minutes
2024-07-02 16:09:59,700:INFO:SubProcess create_model() called ==================================
2024-07-02 16:09:59,700:INFO:Initializing create_model()
2024-07-02 16:09:59,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013606C71810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-02 16:09:59,700:INFO:Checking exceptions
2024-07-02 16:09:59,700:INFO:Importing libraries
2024-07-02 16:09:59,700:INFO:Copying training dataset
2024-07-02 16:10:00,366:INFO:Defining folds
2024-07-02 16:10:00,366:INFO:Declaring metric variables
2024-07-02 16:10:00,384:INFO:Importing untrained model
2024-07-02 16:10:00,384:INFO:Random Forest Classifier Imported successfully
2024-07-02 16:10:00,400:INFO:Starting cross validation
2024-07-02 16:10:00,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-02 16:19:08,551:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:09,721:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:10,981:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:11,252:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:11,621:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:12,119:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:12,703:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:13,388:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:13,798:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:13,920:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:14,795:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:19:15,642:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:15,519:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:15,886:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:16,252:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:16,723:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:17,310:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:17,953:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:19,003:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:20,093:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:20,206:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:20,862:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:20,996:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:28:21,787:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:07,973:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:08,786:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:08,803:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:09,368:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:09,405:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:09,940:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:33:10,918:INFO:Calculating mean and std
2024-07-02 16:33:10,918:INFO:Creating metrics dataframe
2024-07-02 16:33:10,918:INFO:Uploading results into container
2024-07-02 16:33:10,932:INFO:Uploading model into container now
2024-07-02 16:33:10,935:INFO:_master_model_container: 3
2024-07-02 16:33:10,935:INFO:_display_container: 2
2024-07-02 16:33:10,938:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5537, verbose=0,
                       warm_start=False)
2024-07-02 16:33:10,939:INFO:create_model() successfully completed......................................
2024-07-02 16:33:11,302:INFO:SubProcess create_model() end ==================================
2024-07-02 16:33:11,302:INFO:Creating metrics dataframe
2024-07-02 16:33:11,318:INFO:Initializing Light Gradient Boosting Machine
2024-07-02 16:33:11,318:INFO:Total runtime is 38.64182644685109 minutes
2024-07-02 16:33:11,335:INFO:SubProcess create_model() called ==================================
2024-07-02 16:33:11,335:INFO:Initializing create_model()
2024-07-02 16:33:11,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013606C71810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-02 16:33:11,335:INFO:Checking exceptions
2024-07-02 16:33:11,335:INFO:Importing libraries
2024-07-02 16:33:11,335:INFO:Copying training dataset
2024-07-02 16:33:12,238:INFO:Defining folds
2024-07-02 16:33:12,238:INFO:Declaring metric variables
2024-07-02 16:33:12,251:INFO:Importing untrained model
2024-07-02 16:33:12,251:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-02 16:33:12,279:INFO:Starting cross validation
2024-07-02 16:33:12,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-02 16:34:50,085:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:50,240:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:50,294:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:50,853:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:51,006:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:51,053:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:51,619:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:51,777:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:51,819:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:34:59,521:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:35:00,377:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:35:01,239:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:29,087:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:29,087:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:29,152:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:29,860:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:29,875:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:29,919:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:30,619:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:30,658:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:30,685:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:32,242:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:32,919:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:36:33,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:30,788:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:30,823:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:31,360:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:31,396:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:31,776:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:31,824:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:37:32,921:INFO:Calculating mean and std
2024-07-02 16:37:32,923:INFO:Creating metrics dataframe
2024-07-02 16:37:32,923:INFO:Uploading results into container
2024-07-02 16:37:32,923:INFO:Uploading model into container now
2024-07-02 16:37:32,923:INFO:_master_model_container: 4
2024-07-02 16:37:32,923:INFO:_display_container: 2
2024-07-02 16:37:32,932:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-02 16:37:32,932:INFO:create_model() successfully completed......................................
2024-07-02 16:37:33,106:INFO:SubProcess create_model() end ==================================
2024-07-02 16:37:33,106:INFO:Creating metrics dataframe
2024-07-02 16:37:33,324:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-02 16:37:33,359:INFO:Initializing create_model()
2024-07-02 16:37:33,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-02 16:37:33,359:INFO:Checking exceptions
2024-07-02 16:37:33,396:INFO:Importing libraries
2024-07-02 16:37:33,397:INFO:Copying training dataset
2024-07-02 16:37:33,940:INFO:Defining folds
2024-07-02 16:37:33,940:INFO:Declaring metric variables
2024-07-02 16:37:33,940:INFO:Importing untrained model
2024-07-02 16:37:33,940:INFO:Declaring custom model
2024-07-02 16:37:33,940:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-02 16:37:33,961:INFO:Cross validation set to False
2024-07-02 16:37:33,961:INFO:Fitting Model
2024-07-02 16:37:58,998:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-02 16:37:58,998:INFO:[LightGBM] [Info] Number of positive: 331279, number of negative: 331279
2024-07-02 16:37:59,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.186328 seconds.
2024-07-02 16:37:59,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-02 16:37:59,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-02 16:37:59,515:INFO:[LightGBM] [Info] Total Bins 16677
2024-07-02 16:37:59,515:INFO:[LightGBM] [Info] Number of data points in the train set: 662558, number of used features: 75
2024-07-02 16:37:59,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-02 16:38:09,352:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-02 16:38:09,352:INFO:create_model() successfully completed......................................
2024-07-02 16:38:09,624:INFO:_master_model_container: 4
2024-07-02 16:38:09,625:INFO:_display_container: 2
2024-07-02 16:38:09,626:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-02 16:38:09,626:INFO:compare_models() successfully completed......................................
2024-07-02 16:38:09,829:INFO:Initializing plot_model()
2024-07-02 16:38:09,829:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-02 16:38:09,829:INFO:Checking exceptions
2024-07-02 16:38:10,089:INFO:Preloading libraries
2024-07-02 16:38:10,102:INFO:Copying training dataset
2024-07-02 16:38:10,102:INFO:Plot type: confusion_matrix
2024-07-02 16:38:18,259:INFO:Fitting Model
2024-07-02 16:38:18,259:INFO:Scoring test/hold-out set
2024-07-02 16:38:20,272:INFO:Visual Rendered Successfully
2024-07-02 16:38:20,489:INFO:plot_model() successfully completed......................................
2024-07-02 16:38:20,713:INFO:Initializing plot_model()
2024-07-02 16:38:20,713:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-02 16:38:20,713:INFO:Checking exceptions
2024-07-02 16:38:20,948:INFO:Preloading libraries
2024-07-02 16:38:20,966:INFO:Copying training dataset
2024-07-02 16:38:20,966:INFO:Plot type: auc
2024-07-02 16:38:23,886:INFO:Fitting Model
2024-07-02 16:38:23,902:INFO:Scoring test/hold-out set
2024-07-02 16:38:24,942:INFO:Visual Rendered Successfully
2024-07-02 16:38:25,148:INFO:plot_model() successfully completed......................................
2024-07-02 16:38:25,176:INFO:Initializing plot_model()
2024-07-02 16:38:25,176:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-02 16:38:25,176:INFO:Checking exceptions
2024-07-02 16:38:25,383:INFO:Preloading libraries
2024-07-02 16:38:25,398:INFO:Copying training dataset
2024-07-02 16:38:25,398:INFO:Plot type: feature
2024-07-02 16:38:25,398:WARNING:No coef_ found. Trying feature_importances_
2024-07-02 16:38:26,831:INFO:Visual Rendered Successfully
2024-07-02 16:38:27,003:INFO:plot_model() successfully completed......................................
2024-07-02 16:38:27,110:INFO:Initializing predict_model()
2024-07-02 16:38:27,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001362156F240>)
2024-07-02 16:38:27,110:INFO:Checking exceptions
2024-07-02 16:38:27,110:INFO:Preloading libraries
2024-07-02 16:38:30,093:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:30,995:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:31,824:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:33,244:INFO:Initializing predict_model()
2024-07-02 16:38:33,244:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000013633607B00>)
2024-07-02 16:38:33,245:INFO:Checking exceptions
2024-07-02 16:38:33,245:INFO:Preloading libraries
2024-07-02 16:38:35,979:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:36,807:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:37,620:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:39,013:INFO:Initializing predict_model()
2024-07-02 16:38:39,013:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001362156F240>)
2024-07-02 16:38:39,013:INFO:Checking exceptions
2024-07-02 16:38:39,014:INFO:Preloading libraries
2024-07-02 16:38:41,683:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:42,526:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 16:38:43,339:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:43:30,243:INFO:Initializing load_model()
2024-07-02 18:43:30,243:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 18:43:35,899:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 18:47:34,487:INFO:Initializing predict_model()
2024-07-02 18:47:34,487:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000013633607B00>)
2024-07-02 18:47:34,487:INFO:Checking exceptions
2024-07-02 18:47:34,488:INFO:Preloading libraries
2024-07-02 18:47:38,362:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:47:39,212:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:47:40,031:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:48:07,398:INFO:Initializing predict_model()
2024-07-02 18:48:07,398:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000136383479C0>)
2024-07-02 18:48:07,398:INFO:Checking exceptions
2024-07-02 18:48:07,398:INFO:Preloading libraries
2024-07-02 18:48:10,172:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:48:10,990:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:48:11,809:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:54:32,373:INFO:Initializing predict_model()
2024-07-02 18:54:32,373:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001364A83D580>)
2024-07-02 18:54:32,374:INFO:Checking exceptions
2024-07-02 18:54:32,374:INFO:Preloading libraries
2024-07-02 18:54:35,337:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:54:36,171:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:54:37,027:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:58:35,238:INFO:Initializing predict_model()
2024-07-02 18:58:35,238:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013606ED0C50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001364A83D580>)
2024-07-02 18:58:35,239:INFO:Checking exceptions
2024-07-02 18:58:35,240:INFO:Preloading libraries
2024-07-02 18:58:37,889:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:58:38,719:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:58:39,653:WARNING:c:\Users\USER\anaconda3\envs\idxparners\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-07-02 18:59:29,614:INFO:Initializing load_model()
2024-07-02 18:59:29,614:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 18:59:29,660:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 18:59:36,309:INFO:Initializing load_model()
2024-07-02 18:59:36,310:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 18:59:36,365:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 18:59:41,998:INFO:Initializing load_model()
2024-07-02 18:59:41,999:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 18:59:42,045:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 18:59:56,939:INFO:Initializing load_model()
2024-07-02 18:59:56,939:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 18:59:56,979:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:00:06,986:INFO:Initializing load_model()
2024-07-02 19:00:06,987:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:00:07,058:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:00:15,736:INFO:Initializing load_model()
2024-07-02 19:00:15,736:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:00:15,783:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:00:30,201:INFO:Initializing load_model()
2024-07-02 19:00:30,201:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:00:30,259:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:00:46,269:INFO:Initializing load_model()
2024-07-02 19:00:46,269:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:00:46,312:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:00:49,237:INFO:Initializing load_model()
2024-07-02 19:00:49,237:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:00:49,280:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:00:51,081:INFO:Initializing load_model()
2024-07-02 19:00:51,083:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:00:51,134:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:01:07,534:INFO:Initializing load_model()
2024-07-02 19:01:07,535:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:01:07,582:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:01:46,611:INFO:Initializing load_model()
2024-07-02 19:01:46,611:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:01:46,662:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:01:57,615:INFO:Initializing load_model()
2024-07-02 19:01:57,615:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:01:57,657:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:06,550:INFO:Initializing load_model()
2024-07-02 19:02:06,551:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:06,599:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:06,815:INFO:Initializing load_model()
2024-07-02 19:02:06,816:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:06,847:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:21,516:INFO:Initializing load_model()
2024-07-02 19:02:21,516:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:21,544:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:21,988:INFO:Initializing load_model()
2024-07-02 19:02:21,989:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:22,027:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:22,278:INFO:Initializing load_model()
2024-07-02 19:02:22,278:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:22,323:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:22,541:INFO:Initializing load_model()
2024-07-02 19:02:22,542:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:22,586:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:23,796:INFO:Initializing load_model()
2024-07-02 19:02:23,797:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:23,828:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:25,015:INFO:Initializing load_model()
2024-07-02 19:02:25,015:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:25,062:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:25,852:INFO:Initializing load_model()
2024-07-02 19:02:25,852:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:25,898:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:26,419:INFO:Initializing load_model()
2024-07-02 19:02:26,419:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:26,465:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:26,915:INFO:Initializing load_model()
2024-07-02 19:02:26,916:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:26,971:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:34,389:INFO:Initializing load_model()
2024-07-02 19:02:34,389:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:34,435:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:35,291:INFO:Initializing load_model()
2024-07-02 19:02:35,291:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:35,332:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:02:49,232:INFO:Initializing load_model()
2024-07-02 19:02:49,232:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:02:49,271:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:03:00,750:INFO:Initializing load_model()
2024-07-02 19:03:00,751:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:03:00,800:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:03:16,874:INFO:Initializing load_model()
2024-07-02 19:03:16,875:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:03:16,922:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:03:24,451:INFO:Initializing load_model()
2024-07-02 19:03:24,453:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:03:24,518:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:03:33,339:INFO:Initializing load_model()
2024-07-02 19:03:33,341:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:03:33,407:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:03:44,763:INFO:Initializing load_model()
2024-07-02 19:03:44,763:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:03:44,810:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:03:51,415:INFO:Initializing load_model()
2024-07-02 19:03:51,416:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:03:51,469:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:00,675:INFO:Initializing load_model()
2024-07-02 19:04:00,675:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:00,717:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:08,722:INFO:Initializing load_model()
2024-07-02 19:04:08,722:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:08,767:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:16,206:INFO:Initializing load_model()
2024-07-02 19:04:16,206:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:16,248:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:24,257:INFO:Initializing load_model()
2024-07-02 19:04:24,258:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:24,304:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:35,769:INFO:Initializing load_model()
2024-07-02 19:04:35,769:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:35,828:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:46,071:INFO:Initializing load_model()
2024-07-02 19:04:46,071:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:46,116:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:52,631:INFO:Initializing load_model()
2024-07-02 19:04:52,632:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:52,684:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:04:59,887:INFO:Initializing load_model()
2024-07-02 19:04:59,887:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:04:59,936:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:05:02,713:INFO:Initializing load_model()
2024-07-02 19:05:02,713:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:05:02,750:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:05:05,760:INFO:Initializing load_model()
2024-07-02 19:05:05,761:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:05:05,801:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:05:13,356:INFO:Initializing load_model()
2024-07-02 19:05:13,356:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:05:13,386:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:05:14,710:INFO:Initializing load_model()
2024-07-02 19:05:14,710:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:05:14,753:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:05:21,707:INFO:Initializing load_model()
2024-07-02 19:05:21,707:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:05:21,750:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:05:21,929:INFO:Initializing predict_model()
2024-07-02 19:05:21,929:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025476597710>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002545E2FF060>)
2024-07-02 19:05:21,929:INFO:Checking exceptions
2024-07-02 19:05:21,929:INFO:Preloading libraries
2024-07-02 19:05:21,929:INFO:Set up data.
2024-07-02 19:05:21,955:INFO:Set up index.
2024-07-02 19:06:19,830:INFO:Initializing load_model()
2024-07-02 19:06:19,830:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:06:19,872:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:07:00,309:INFO:Initializing load_model()
2024-07-02 19:07:00,309:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:07:00,347:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:07:19,435:INFO:Initializing load_model()
2024-07-02 19:07:19,435:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:07:19,472:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:07:32,547:INFO:Initializing load_model()
2024-07-02 19:07:32,547:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:07:32,599:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:07:36,303:INFO:Initializing load_model()
2024-07-02 19:07:36,304:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:07:36,342:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:07:36,501:INFO:Initializing predict_model()
2024-07-02 19:07:36,501:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002545F8F7150>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002547762CE00>)
2024-07-02 19:07:36,501:INFO:Checking exceptions
2024-07-02 19:07:36,501:INFO:Preloading libraries
2024-07-02 19:07:36,501:INFO:Set up data.
2024-07-02 19:07:36,527:INFO:Set up index.
2024-07-02 19:09:49,970:INFO:Initializing load_model()
2024-07-02 19:09:49,970:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:09:50,009:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:10:44,143:INFO:Initializing load_model()
2024-07-02 19:10:44,143:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:10:44,191:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:11:26,237:INFO:Initializing load_model()
2024-07-02 19:11:26,238:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:11:26,278:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:11:26,450:INFO:Initializing predict_model()
2024-07-02 19:11:26,450:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002547409F490>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002545C2AC720>)
2024-07-02 19:11:26,450:INFO:Checking exceptions
2024-07-02 19:11:26,450:INFO:Preloading libraries
2024-07-02 19:11:26,450:INFO:Set up data.
2024-07-02 19:11:26,474:INFO:Set up index.
2024-07-02 19:13:32,368:INFO:Initializing load_model()
2024-07-02 19:13:32,369:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:13:32,411:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:13:42,945:INFO:Initializing load_model()
2024-07-02 19:13:42,945:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:13:42,988:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:13:43,154:INFO:Initializing predict_model()
2024-07-02 19:13:43,154:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025470B80710>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000254765867A0>)
2024-07-02 19:13:43,155:INFO:Checking exceptions
2024-07-02 19:13:43,156:INFO:Preloading libraries
2024-07-02 19:13:43,156:INFO:Set up data.
2024-07-02 19:13:43,166:INFO:Set up index.
2024-07-02 19:13:47,952:INFO:Initializing load_model()
2024-07-02 19:13:47,953:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:13:48,008:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:13:54,762:INFO:Initializing load_model()
2024-07-02 19:13:54,763:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:13:54,816:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:13:59,214:INFO:Initializing load_model()
2024-07-02 19:13:59,214:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:13:59,262:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:13:59,481:INFO:Initializing load_model()
2024-07-02 19:13:59,482:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:13:59,537:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:13:59,685:INFO:Initializing predict_model()
2024-07-02 19:13:59,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000254765D8C10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025476585260>)
2024-07-02 19:13:59,685:INFO:Checking exceptions
2024-07-02 19:13:59,685:INFO:Preloading libraries
2024-07-02 19:13:59,685:INFO:Set up data.
2024-07-02 19:13:59,703:INFO:Set up index.
2024-07-02 19:14:29,720:INFO:Initializing load_model()
2024-07-02 19:14:29,720:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:14:29,758:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:14:39,099:INFO:Initializing load_model()
2024-07-02 19:14:39,099:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:14:39,156:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-02 19:14:45,539:INFO:Initializing load_model()
2024-07-02 19:14:45,539:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-02 19:14:45,579:INFO:Transformation Pipeline and Model Successfully Loaded
2024-07-04 07:06:09,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:06:09,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:06:09,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:06:09,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:06:31,093:INFO:Initializing load_model()
2024-07-04 07:06:31,093:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-04 07:07:13,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:07:13,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:07:13,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:07:13,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 07:07:17,775:INFO:Initializing load_model()
2024-07-04 07:07:17,775:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-04 07:08:34,241:INFO:Initializing load_model()
2024-07-04 07:08:34,241:INFO:load_model(model_name=LGBM, platform=None, authentication=None, verbose=True)
2024-07-04 07:08:34,516:INFO:Initializing predict_model()
2024-07-04 07:08:34,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E32861BBD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('date_feature_extractor',
                 TransformerWrapper(include=['issue_d', 'earliest_cr_line',
                                             'last_pymnt_d',
                                             'last_credit_pull_d'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['loan_amnt', 'funded...
                                    transformer=OneHotEncoder(cols=['grade',
                                                                    'emp_length',
                                                                    'home_ownership',
                                                                    'verification_status',
                                                                    'purpose'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model', LGBMClassifier(n_jobs=-1, random_state=652))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E32A565080>)
2024-07-04 07:08:34,517:INFO:Checking exceptions
2024-07-04 07:08:34,517:INFO:Preloading libraries
2024-07-04 07:08:34,592:INFO:Set up data.
2024-07-04 07:08:34,817:INFO:Set up index.
